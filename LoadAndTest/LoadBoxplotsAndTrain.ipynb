{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1aJT92Ktdb"
      },
      "source": [
        "# Scrip to load boxplot images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rNXMGV7GVBd"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4ObiYNpMfGW"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install sktime\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4SrxJlTGbj7"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import imageio\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re \n",
        "import math\n",
        "import gc\n",
        "\n",
        "from pathlib import Path \n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "from sktime.datasets import load_from_tsfile_to_dataframe\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI6q1ETnGXBl"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq1ZPiFsGpp9"
      },
      "outputs": [],
      "source": [
        "def pureBlackAndWhiteImageArrayUpdated( imageArray, normalized = True):\n",
        "  aux = imageArray != 0\n",
        "  result = aux.astype(\"uint8\")[:,:,:1]\n",
        "  return result if normalized else (result*255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbfsPGXLOl8h"
      },
      "outputs": [],
      "source": [
        "def array2img ( array, mode = \"L\" ):\n",
        "    \"\"\"\n",
        "    @brief Convert a Matplotlib figure to a PIL Image in RGBA format and return it\n",
        "    @param fig a matplotlib figure\n",
        "    @return a Python Imaging Library ( PIL ) image\n",
        "    \"\"\"\n",
        "    # put the figure pixmap into a numpy array\n",
        "    h, w, d = array.shape\n",
        "    return Image.frombytes( mode, ( w, h ), array.tobytes( ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJBap9i6O2az"
      },
      "outputs": [],
      "source": [
        "def displayImageUniqueValuesMore ( imageArray ):\n",
        "\n",
        "  print(\"ImageArray Shape:\" , imageArray.shape)\n",
        "  img2 = imageArray.reshape(-1, imageArray.shape[2]) # reshape the original image into -1, 3; -1 is placeholder, so lets say you have a \n",
        "                                                    # numpy array with shape (6,2), if you reshape it to (-1, 3), we know the second dim = 3\n",
        "                                                    # first dim = (6*2)/3 = 4, so -1 is replaced with 4\n",
        "  print(\"ImageReshape Shape:\", img2.shape)\n",
        "\n",
        "  counter = np.unique(img2, axis=0) # find unique elemenst\n",
        "  '''\n",
        "  numpy.unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None)[source]\n",
        "  Find the unique elements of an array.\n",
        "\n",
        "  Returns the sorted unique elements of an array. There are three optional outputs in addition to the unique elements:\n",
        "\n",
        "  the indices of the input array that give the unique values\n",
        "  the indices of the unique array that reconstruct the input array\n",
        "  the number of times each unique value comes up in the input array\n",
        "  '''\n",
        "  #print(\"Array of pixels combinations:\\n\", counter)\n",
        "  print(\"Shape of array\", counter.shape) # as, we have separate axis, so the channels are shown in dim 2\n",
        "  print(\"how many pixels:\", counter.shape[0], \"or\", len(set(imageArray.flatten())))\n",
        "  \n",
        "  #binArray=np.bincount(counter.flatten())\n",
        "  count = 0\n",
        "  for value in counter:\n",
        "    print(\"Value: \", value, \"| Occurrences:\", (img2 == value).sum())\n",
        "    count =+ 1\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_order(file):\n",
        "    match = re.compile(r'.*?(\\d+).*?').match(Path(file).name)\n",
        "    if not match:\n",
        "        return math.inf\n",
        "    return int(match.groups()[0])"
      ],
      "metadata": {
        "id": "QZNrzwlgoLuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhSJS8SNL2un"
      },
      "source": [
        "## Run code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XYvQxV91I75"
      },
      "source": [
        "### Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY1TvmGdRJdz",
        "outputId": "2d138179-9673-49c3-e136-794c48b58ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ6g7mV3RLaT"
      },
      "outputs": [],
      "source": [
        "DATA_SET_NAMES = [\n",
        "\"ACSF1\",\n",
        "\"Adiac\",\n",
        "\"ArrowHead\",\n",
        "\"Beef\",\n",
        "\"BeetleFly\",\n",
        "\"BirdChicken\",\n",
        "\"BME\",\n",
        "\"Car\",\n",
        "\"CBF\",\n",
        "\"Chinatown\",\n",
        "\"ChlorineConcentration\",\n",
        "\"CinCECGTorso\",\n",
        "\"Coffee\",\n",
        "\"Computers\",\n",
        "\"Crop\",\n",
        "\"DiatomSizeReduction\",\n",
        "\"DistalPhalanxOutlineAgeGroup\",\n",
        "\"DistalPhalanxOutlineCorrect\",\n",
        "\"DistalPhalanxTW\",\n",
        "\"Earthquakes\",\n",
        "\"ECG200\",\n",
        "\"ECG5000\",\n",
        "\"ECGFiveDays\",\n",
        "\"ElectricDevices\",\n",
        "\"EthanolLevel\",\n",
        "\"FaceAll\",\n",
        "\"FaceFour\",\n",
        "\"FacesUCR\",\n",
        "\"FiftyWords\",\n",
        "\"Fish\",\n",
        "\"FordA\",\n",
        "\"FordB\",\n",
        "\"FreezerRegularTrain\",\n",
        "\"FreezerSmallTrain\",\n",
        "\"GunPoint\",\n",
        "\"GunPointAgeSpan\",\n",
        "\"GunPointMaleVersusFemale\",\n",
        "\"GunPointOldVersusYoung\",\n",
        "\"Ham\",\n",
        "\"Haptics\",\n",
        "\"Herring\",\n",
        "\"HouseTwenty\",\n",
        "\"InlineSkate\",\n",
        "\"InsectEPGRegularTrain\",\n",
        "\"InsectEPGSmallTrain\",\n",
        "\"ItalyPowerDemand\",\n",
        "\"LargeKitchenAppliances\",\n",
        "\"Lightning2\",\n",
        "\"Lightning7\",\n",
        "\"Mallat\",\n",
        "\"Meat\",\n",
        "\"MedicalImages\",\n",
        "\"MiddlePhalanxOutlineAgeGroup\",\n",
        "\"MiddlePhalanxOutlineCorrect\",\n",
        "\"MiddlePhalanxTW\",\n",
        "\"MixedShapesRegularTrain\",\n",
        "\"MixedShapesSmallTrain\",\n",
        "\"MoteStrain\",\n",
        "\"OliveOil\",\n",
        "\"OSULeaf\",\n",
        "\"PhalangesOutlinesCorrect\",\n",
        "\"Phoneme\",\n",
        "\"PigAirwayPressure\",\n",
        "\"PigArtPressure\",\n",
        "\"PigCVP\",\n",
        "\"Plane\",\n",
        "\"ProximalPhalanxOutlineAgeGroup\",\n",
        "\"ProximalPhalanxOutlineCorrect\",\n",
        "\"ProximalPhalanxTW\",\n",
        "\"RefrigerationDevices\",\n",
        "\"Rock\",\n",
        "\"ScreenType\",\n",
        "\"SemgHandGenderCh2\",\n",
        "\"SemgHandMovementCh2\",\n",
        "\"SemgHandSubjectCh2\",\n",
        "\"ShapeletSim\",\n",
        "\"ShapesAll\",\n",
        "\"SmallKitchenAppliances\",\n",
        "\"SmoothSubspace\",\n",
        "\"SonyAIBORobotSurface1\",\n",
        "\"SonyAIBORobotSurface2\",\n",
        "\"StarLightCurves\",\n",
        "\"Strawberry\",\n",
        "\"SwedishLeaf\",\n",
        "\"Symbols\",\n",
        "\"SyntheticControl\",\n",
        "\"ToeSegmentation1\",\n",
        "\"ToeSegmentation2\",\n",
        "\"Trace\",\n",
        "\"TwoLeadECG\",\n",
        "\"TwoPatterns\",\n",
        "\"UMD\",\n",
        "\"UWaveGestureLibraryAll\",\n",
        "\"Wafer\",\n",
        "\"Wine\",\n",
        "\"WordSynonyms\",\n",
        "\"Worms\",\n",
        "\"WormsTwoClass\",\n",
        "\"Yoga\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ktgKArfr4CG",
        "outputId": "42be466f-39b3-4652-b5c3-01a6edefe885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n"
          ]
        }
      ],
      "source": [
        "print(len(DATA_SET_NAMES))\n",
        "index = DATA_SET_NAMES.index(\"Crop\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns=['Dataset',\n",
        "         'Fold 1: Acc','Fold 1: Loss',\n",
        "         'Fold 2: Acc','Fold 2: Loss',\n",
        "         'Fold 3: Acc','Fold 3: Loss',\n",
        "         'Fold 4: Acc','Fold 4: Loss',\n",
        "         'Fold 5: Acc','Fold 5: Loss',\n",
        "         'Average: Acc','Average: Loss',\n",
        "         'Standard Deviation',\n",
        "         'batch_size', 'epochs']\n",
        "df_csv = pd.DataFrame(columns=columns)"
      ],
      "metadata": {
        "id": "3wa9PLPgTIvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import some data zipped"
      ],
      "metadata": {
        "id": "dt2FWTLWTpKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/drive/MyDrive/10_boxplots.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y84o_1A2fFMl",
        "outputId": "ffd2afbc-f8d2-4fbc-db28-c38275098662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwV3R4M9NRGx"
      },
      "source": [
        "### Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktGGvgCJLrkj"
      },
      "outputs": [],
      "source": [
        "#CHOOSE DATA SET NAME AND PATH OF FOLDER OF IMAGES\n",
        "name = \"ArrowHead\"\n",
        "numberOfPlots = 10\n",
        "normalized = False # IF WE WANT 0|1 or 0|255\n",
        "\n",
        "#plots = \"Violinplots\" \n",
        "plots = \"Boxplots\" \n",
        "# pathName = '/content/drive/MyDrive/Tese/'+ plots + '/Imagens/' + str(numberOfPlots) + '_' + plots.lower() + '/'\n",
        "pathName = '/content/' + str(numberOfPlots) + '_' + plots.lower() + '/'\n",
        "\n",
        "_, train_y = load_from_tsfile_to_dataframe(\"drive/MyDrive/Tese/Univariate_ts/\" + name + \"/\" + name + \"_TRAIN.ts\")\n",
        "_, test_y = load_from_tsfile_to_dataframe(\"drive/MyDrive/Tese/Univariate_ts/\" + name + \"/\" + name + \"_TEST.ts\")\n",
        "\n",
        "train_x = np.empty((len(train_y), 288, 432, 1), dtype=np.uint8)\n",
        "test_x = np.empty((len(test_y), 288, 432, 1), dtype=np.uint8)\n",
        "\n",
        "trainOrTest = 'TRAIN'\n",
        "path = pathName + name + '/' + trainOrTest + '/' + '*.png*'\n",
        "\n",
        "# train_x = [pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized) for img_path in sorted(glob.glob(path), key=get_order)]\n",
        "# for img_path in sorted(glob.glob(path), key=get_order):\n",
        "  # print(img_path)\n",
        "  # train_x.append(pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized))\n",
        "  \n",
        "for i, img_path in enumerate(sorted(glob.glob(path), key=get_order)):\n",
        "  train_x[i] = pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized)\n",
        "\n",
        "trainOrTest = 'TEST'\n",
        "path = pathName + name + '/' + trainOrTest + '/' + '*.png*'\n",
        "\n",
        "for i, img_path in enumerate(sorted(glob.glob(path), key=get_order)):\n",
        "  test_x[i] = pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized)\n",
        "\n",
        "\n",
        "# test_x = [pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized) for img_path in sorted(glob.glob(path), key=get_order)]\n",
        "# for img_path in sorted(glob.glob(path), key=get_order):\n",
        "  # print(img_path)\n",
        "  #test_x.append(pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized))\n",
        "\n",
        "\n",
        "\n",
        "# train_x = np.array(train_x)\n",
        "# test_x = np.array(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.nbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3dET2vdGOFD",
        "outputId": "7d8d58e6-5279-4969-f99e-d1f4551a6bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "895795200"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.nbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eq4jD6EFDQ0",
        "outputId": "8bffb2db-fe1e-40ca-f7a4-db3e2889f34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2090188800"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 channels:**\n",
        "\n",
        "train_x.nbytes:\n",
        "2.687.385.600\n",
        "\n",
        "test_x.nbytes: \n",
        " 6.270.566.400\n",
        "\n",
        "**1 channels:**\n",
        "\n",
        "train_x.nbytes:\n",
        "895.795.200\n",
        "\n",
        "test_x.nbytes:\n",
        "2.090.188.800"
      ],
      "metadata": {
        "id": "wm21yA9FFF7C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh166gghZ6Y8"
      },
      "source": [
        "#### Details of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKL9KAINyWp4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f622e57-a5c6-492c-cf49-7c2129c16017"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ArrowHead'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X5sdA6a0-7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fe681a-f295-4455-f416-d01c11343d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageArray Shape: (288, 432, 1)\n",
            "ImageReshape Shape: (124416, 1)\n",
            "Shape of array (2, 1)\n",
            "how many pixels: 2 or 2\n",
            "Value:  [0] | Occurrences: 117793\n",
            "Value:  [255] | Occurrences: 6623\n"
          ]
        }
      ],
      "source": [
        "displayImageUniqueValuesMore(train_x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "hzINJk1AKCvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "GDxbmPaDJSx9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgdUSa9jJMwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvcqqM0vU5HV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f6bd304a-ba1e-43c6-85ff-0f4bc00b9696"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe656edfb10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "image = array2img(train_x[16])\n",
        "plt.axis('off')\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRiSqd15wdp7"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TESTE\n",
        "\n"
      ],
      "metadata": {
        "id": "16m0aw2Envey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions"
      ],
      "metadata": {
        "id": "GAct8l7vr3_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(width, height, channels):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, (1, 1), activation='relu', input_shape=(width, height, channels)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (1, 1), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (1, 1), activation='relu'))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.7)) #Aumentar depois maybe o dropout\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.7))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  # early stopping\n",
        "  callback = EarlyStopping(monitor='loss')\n",
        "  # compile model\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "-xcdhMDSqryq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model2(width, height, channels):\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "  # early stopping\n",
        "  callback = EarlyStopping(monitor='loss', patience=3)\n",
        "  # compile model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "6aFfS1CLqLfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgHz3zRbpog2"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCOb2X37pog7"
      },
      "outputs": [],
      "source": [
        "# This cell is used to fix one hot encoding automatic from keras in some datasets\n",
        "train_y = train_y.astype('uint8')\n",
        "test_y = test_y.astype('uint8')\n",
        "while(min(train_y) > 0):\n",
        "  train_y = train_y - 1\n",
        "while(min(test_y) > 0):\n",
        "  test_y = test_y - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8137734b-72fd-4cc2-cd81-e74fd24884c4",
        "id": "v_xUktQnpog7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (36, 288, 432, 1)  | y =  36\n",
            "Test:   (175, 288, 432, 1)  | y =  175\n",
            "Number of classes:  3\n"
          ]
        }
      ],
      "source": [
        "print(\"Train: \", train_x.shape, \" | y = \", train_y.size)\n",
        "print(\"Test:  \", test_x.shape, \" | y = \", test_y.size)\n",
        "n_classes = np.unique(train_y).size\n",
        "print(\"Number of classes: \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f36415e-a977-4eb3-d124-8362af87ce47",
        "id": "hXFW3tbhpog8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width:  288 | Height:  432 | Channels:  1\n"
          ]
        }
      ],
      "source": [
        "train_length, width, height, channels = train_x.shape[1], train_x.shape[2], train_x.shape[3]\n",
        "print(\"Width: \", width, \"| Height: \", height, \"| Channels: \", channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neJ-11mRpog8"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    # keras.callbacks.ModelCheckpoint(\n",
        "    #     \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    # ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]"
      ],
      "metadata": {
        "id": "3xEdrIXeMyeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "FOuzykNXpqT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configs\n",
        "BATCH_SIZE = 32 if train_length >= 500 else 16 if train_length >= 50 else 8\n",
        "EPOCHS = 100\n",
        "N_SPLIT = 5\n",
        "verbose = 1\n",
        "\n",
        "# Storing the average of all predictions\n",
        "main_pred = []\n",
        "data_kfold = pd.DataFrame()\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "row = []\n",
        "row.append(name)\n",
        "\n",
        "kfold = KFold(n_splits=N_SPLIT, shuffle=True) # , random_state=42)\n",
        "\n",
        "# Variable for keeping count of split we are executing\n",
        "\n",
        "fold_no = 0\n",
        "\n",
        "\n",
        "# K-fold Train and test for each split\n",
        "\n",
        "for train_idx, val_idx in list(kfold.split(train_x, train_y)):\n",
        "\n",
        "    fold_no+=1\n",
        "\n",
        "    # training_set  = datagen.flow(train_idx, train_y, batch_size=64)\n",
        "    training_set  = datagen.flow(train_x[train_idx], train_y[train_idx], batch_size=BATCH_SIZE)\n",
        "    \n",
        "    validation_set = datagen.flow(train_x[val_idx], train_y[val_idx], batch_size=BATCH_SIZE)\n",
        "\n",
        "    model_test = get_model(width, height, channels)\n",
        "    history = model_test.fit( training_set,\n",
        "                              validation_data=validation_set,\n",
        "                              epochs = EPOCHS,\n",
        "                              steps_per_epoch = len(training_set) ,\n",
        "                              callbacks = callbacks,\n",
        "                              verbose = verbose\n",
        "                              )\n",
        "\n",
        "    del(training_set)\n",
        "    del(validation_set)\n",
        "\n",
        "    test_set = datagen.flow(test_x, test_y, batch_size=BATCH_SIZE)\n",
        "\n",
        "    pred = model_test.evaluate(test_set, steps=len(test_set))\n",
        "\n",
        "    del(test_set)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model_test.metrics_names[0]} of {pred[0]}; {model_test.metrics_names[1]} of {pred[1]*100}%')\n",
        "    acc_per_fold.append(pred[1])\n",
        "    loss_per_fold.append(pred[0])\n",
        "\n",
        "    # predicted_class_indices=np.argmax(pred,axis=1)\n",
        "    # data_kfold[fold_no] = predicted_class_indices\n",
        "\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6arV_Kxn0ZU",
        "outputId": "0b6f0904-da93-4d6e-ea9e-232b782990cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 113ms/step - loss: 1.4189 - accuracy: 0.3571 - val_loss: 1.0763 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.5481 - accuracy: 0.3214 - val_loss: 1.0371 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.3988 - accuracy: 0.4286 - val_loss: 1.0465 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 2.0676 - accuracy: 0.2500 - val_loss: 1.0372 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.5245 - accuracy: 0.3214 - val_loss: 1.0677 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1864 - accuracy: 0.5000 - val_loss: 1.0238 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.5249 - accuracy: 0.4643 - val_loss: 0.9771 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.2344 - accuracy: 0.3571 - val_loss: 0.9677 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.8697 - accuracy: 0.6429 - val_loss: 0.9668 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.2625 - accuracy: 0.3929 - val_loss: 1.0030 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.8860 - accuracy: 0.5357 - val_loss: 1.0495 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0582 - accuracy: 0.5000 - val_loss: 1.0373 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9715 - accuracy: 0.4286 - val_loss: 0.9705 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.9607 - accuracy: 0.6071 - val_loss: 0.9314 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9280 - accuracy: 0.5357 - val_loss: 0.8917 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0001 - accuracy: 0.4286 - val_loss: 0.8707 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.1850 - accuracy: 0.3929 - val_loss: 0.8703 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9447 - accuracy: 0.5714 - val_loss: 0.8766 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0826 - accuracy: 0.4643 - val_loss: 0.8835 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8465 - accuracy: 0.5357 - val_loss: 0.8903 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8066 - accuracy: 0.6786 - val_loss: 0.9007 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8082 - accuracy: 0.6786 - val_loss: 0.9143 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9544 - accuracy: 0.5714 - val_loss: 0.9027 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8108 - accuracy: 0.6429 - val_loss: 0.8905 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8779 - accuracy: 0.6071 - val_loss: 0.8746 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.8853 - accuracy: 0.5000 - val_loss: 0.8605 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0123 - accuracy: 0.5000 - val_loss: 0.8317 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.6841 - accuracy: 0.7500 - val_loss: 0.8166 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9009 - accuracy: 0.5000 - val_loss: 0.8226 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.7825 - accuracy: 0.6071 - val_loss: 0.8726 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8636 - accuracy: 0.5357 - val_loss: 0.9269 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.8905 - accuracy: 0.6429 - val_loss: 0.9535 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8817 - accuracy: 0.5714 - val_loss: 0.9480 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.8027 - accuracy: 0.5714 - val_loss: 0.8954 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.8611 - accuracy: 0.5714 - val_loss: 0.8651 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.9136 - accuracy: 0.5357 - val_loss: 0.8096 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.8951 - accuracy: 0.5714 - val_loss: 0.7997 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.7763 - accuracy: 0.6071 - val_loss: 0.7922 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.8705 - accuracy: 0.4643 - val_loss: 0.7750 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.7843 - accuracy: 0.6071 - val_loss: 0.7868 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.7582 - accuracy: 0.6429 - val_loss: 0.7961 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.6424 - accuracy: 0.7143 - val_loss: 0.8149 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.7592 - accuracy: 0.6429 - val_loss: 0.8317 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.5322 - accuracy: 0.8214 - val_loss: 0.8227 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.7234 - accuracy: 0.6071 - val_loss: 0.7656 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.8985 - accuracy: 0.5357 - val_loss: 0.7432 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8553 - accuracy: 0.6071 - val_loss: 0.7243 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8218 - accuracy: 0.7143 - val_loss: 0.7250 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8236 - accuracy: 0.6429 - val_loss: 0.7324 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.7043 - accuracy: 0.7143 - val_loss: 0.7248 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5956 - accuracy: 0.7857 - val_loss: 0.7268 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6396 - accuracy: 0.7143 - val_loss: 0.7393 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.7712 - accuracy: 0.6071 - val_loss: 0.7622 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.7054 - accuracy: 0.5714 - val_loss: 0.7534 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.7428 - accuracy: 0.6071 - val_loss: 0.7116 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6241 - accuracy: 0.7500 - val_loss: 0.7048 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.6860 - accuracy: 0.6429 - val_loss: 0.7036 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5101 - accuracy: 0.8571 - val_loss: 0.6770 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.5833 - accuracy: 0.7857 - val_loss: 0.6681 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5934 - accuracy: 0.7500 - val_loss: 0.6637 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.7930 - accuracy: 0.6786 - val_loss: 0.6575 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.7092 - accuracy: 0.6071 - val_loss: 0.6511 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.7736 - accuracy: 0.5714 - val_loss: 0.6839 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4857 - accuracy: 0.8214 - val_loss: 0.7231 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.7038 - accuracy: 0.5714 - val_loss: 0.7377 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5598 - accuracy: 0.8214 - val_loss: 0.7319 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.7303 - accuracy: 0.6786 - val_loss: 0.7167 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4793 - accuracy: 0.7857 - val_loss: 0.6998 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.6041 - accuracy: 0.7143 - val_loss: 0.6753 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6620 - accuracy: 0.7143 - val_loss: 0.6911 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6151 - accuracy: 0.7143 - val_loss: 0.6913 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5421 - accuracy: 0.7500 - val_loss: 0.7141 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6603 - accuracy: 0.7143 - val_loss: 0.7311 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.6016 - accuracy: 0.7857 - val_loss: 0.7324 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5613 - accuracy: 0.7857 - val_loss: 0.6793 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.7746 - accuracy: 0.6071 - val_loss: 0.6454 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6710 - accuracy: 0.6786 - val_loss: 0.6181 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5361 - accuracy: 0.7500 - val_loss: 0.6085 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5972 - accuracy: 0.7500 - val_loss: 0.5920 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4439 - accuracy: 0.8214 - val_loss: 0.5709 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6143 - accuracy: 0.6786 - val_loss: 0.5794 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4833 - accuracy: 0.8214 - val_loss: 0.5849 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3983 - accuracy: 0.9286 - val_loss: 0.6066 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.6697 - accuracy: 0.6786 - val_loss: 0.6091 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3998 - accuracy: 0.8571 - val_loss: 0.5976 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4398 - accuracy: 0.8571 - val_loss: 0.5957 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3986 - accuracy: 0.8214 - val_loss: 0.6006 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2607 - accuracy: 0.9286 - val_loss: 0.6136 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.6909 - accuracy: 0.6429 - val_loss: 0.6013 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.6025 - accuracy: 0.7143 - val_loss: 0.5793 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5327 - accuracy: 0.6786 - val_loss: 0.5706 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.4595 - accuracy: 0.8214 - val_loss: 0.5638 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.5807 - accuracy: 0.7500 - val_loss: 0.5623 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6077 - accuracy: 0.6429 - val_loss: 0.5265 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.6670 - accuracy: 0.7500 - val_loss: 0.5016 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6506 - accuracy: 0.7500 - val_loss: 0.5082 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5675 - accuracy: 0.7857 - val_loss: 0.5178 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3349 - accuracy: 0.8214 - val_loss: 0.5200 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6071 - accuracy: 0.6786 - val_loss: 0.5195 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4793 - accuracy: 0.8929 - val_loss: 0.5318 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.7121 - accuracy: 0.7486\n",
            "Score for fold 1: loss of 0.712115466594696; accuracy of 74.85714554786682%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.5870 - accuracy: 0.6897 - val_loss: 0.1705 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.7493 - accuracy: 0.5862 - val_loss: 0.1675 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.6314 - accuracy: 0.8276 - val_loss: 0.1674 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4769 - accuracy: 0.7931 - val_loss: 0.1705 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.7838 - accuracy: 0.5862 - val_loss: 0.1853 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4795 - accuracy: 0.7241 - val_loss: 0.2095 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8891 - accuracy: 0.5172 - val_loss: 0.2270 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5869 - accuracy: 0.7586 - val_loss: 0.2204 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6031 - accuracy: 0.8621 - val_loss: 0.2003 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3891 - accuracy: 0.8966 - val_loss: 0.1814 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4549 - accuracy: 0.7586 - val_loss: 0.1677 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5245 - accuracy: 0.7586 - val_loss: 0.1642 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4615 - accuracy: 0.8276 - val_loss: 0.1646 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.6741 - accuracy: 0.6897 - val_loss: 0.1688 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4502 - accuracy: 0.7586 - val_loss: 0.1792 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4279 - accuracy: 0.7931 - val_loss: 0.1862 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4754 - accuracy: 0.7241 - val_loss: 0.2059 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4510 - accuracy: 0.8621 - val_loss: 0.2282 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.7940 - accuracy: 0.5862 - val_loss: 0.2378 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.6986 - accuracy: 0.6897 - val_loss: 0.2362 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3518 - accuracy: 0.8966 - val_loss: 0.2328 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4290 - accuracy: 0.8276 - val_loss: 0.2264 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4176 - accuracy: 0.8621 - val_loss: 0.2127 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4220 - accuracy: 0.8621 - val_loss: 0.2032 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4592 - accuracy: 0.7931 - val_loss: 0.1975 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.5302 - accuracy: 0.7586 - val_loss: 0.1965 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4691 - accuracy: 0.8621 - val_loss: 0.1954 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4523 - accuracy: 0.7931 - val_loss: 0.1899 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5116 - accuracy: 0.7241 - val_loss: 0.1770 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5665 - accuracy: 0.7586 - val_loss: 0.1760 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4372 - accuracy: 0.8276 - val_loss: 0.1810 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.6564 - accuracy: 0.6207 - val_loss: 0.1868 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5466 - accuracy: 0.8621 - val_loss: 0.1879 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5598 - accuracy: 0.6897 - val_loss: 0.1796 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.3952 - accuracy: 0.8621 - val_loss: 0.1664 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4683 - accuracy: 0.8276 - val_loss: 0.1540 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3354 - accuracy: 0.8966 - val_loss: 0.1435 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3575 - accuracy: 0.8621 - val_loss: 0.1328 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3337 - accuracy: 0.8621 - val_loss: 0.1277 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.6009 - accuracy: 0.7586 - val_loss: 0.1254 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.4980 - accuracy: 0.7241 - val_loss: 0.1147 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3579 - accuracy: 0.8276 - val_loss: 0.1104 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5458 - accuracy: 0.7241 - val_loss: 0.1064 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5183 - accuracy: 0.8276 - val_loss: 0.1015 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3232 - accuracy: 0.8621 - val_loss: 0.0966 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4936 - accuracy: 0.7241 - val_loss: 0.1020 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3331 - accuracy: 0.8621 - val_loss: 0.1016 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1798 - accuracy: 0.9655 - val_loss: 0.1029 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5242 - accuracy: 0.7241 - val_loss: 0.1216 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.2836 - accuracy: 0.8621 - val_loss: 0.1295 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5301 - accuracy: 0.7931 - val_loss: 0.1241 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.2132 - accuracy: 0.9655 - val_loss: 0.1210 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3643 - accuracy: 0.8276 - val_loss: 0.1210 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5157 - accuracy: 0.7586 - val_loss: 0.1219 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4528 - accuracy: 0.7586 - val_loss: 0.1241 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.3051 - accuracy: 0.8621 - val_loss: 0.1296 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3442 - accuracy: 0.8621 - val_loss: 0.1281 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2579 - accuracy: 0.8621 - val_loss: 0.1199 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3029 - accuracy: 0.8621 - val_loss: 0.1109 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2824 - accuracy: 0.8966 - val_loss: 0.1016 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1725 - accuracy: 0.9655 - val_loss: 0.0930 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3977 - accuracy: 0.8276 - val_loss: 0.0886 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.5141 - accuracy: 0.7931 - val_loss: 0.0889 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2289 - accuracy: 0.8966 - val_loss: 0.0886 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3733 - accuracy: 0.8276 - val_loss: 0.0884 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2241 - accuracy: 0.9310 - val_loss: 0.0861 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3662 - accuracy: 0.8621 - val_loss: 0.0816 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4390 - accuracy: 0.7586 - val_loss: 0.0799 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5164 - accuracy: 0.7241 - val_loss: 0.0875 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3899 - accuracy: 0.8276 - val_loss: 0.0945 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2426 - accuracy: 0.9310 - val_loss: 0.0982 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2341 - accuracy: 0.9310 - val_loss: 0.0908 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.3240 - accuracy: 0.8966 - val_loss: 0.0814 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5387 - accuracy: 0.8276 - val_loss: 0.0750 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6473 - accuracy: 0.7931 - val_loss: 0.0722 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.2004 - accuracy: 0.8966 - val_loss: 0.0722 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5646 - accuracy: 0.7931 - val_loss: 0.0725 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3094 - accuracy: 0.8621 - val_loss: 0.0726 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3901 - accuracy: 0.8621 - val_loss: 0.0711 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.3736 - accuracy: 0.7931 - val_loss: 0.0720 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3739 - accuracy: 0.8276 - val_loss: 0.0736 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1750 - accuracy: 0.9310 - val_loss: 0.0762 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3977 - accuracy: 0.7931 - val_loss: 0.0776 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4422 - accuracy: 0.7586 - val_loss: 0.0775 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2914 - accuracy: 0.8276 - val_loss: 0.0835 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5696 - accuracy: 0.7586 - val_loss: 0.0932 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4922 - accuracy: 0.7586 - val_loss: 0.1120 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.4741 - accuracy: 0.7586 - val_loss: 0.1353 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2963 - accuracy: 0.8621 - val_loss: 0.1486 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4212 - accuracy: 0.9310 - val_loss: 0.1508 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2510 - accuracy: 0.8621 - val_loss: 0.1451 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2097 - accuracy: 0.9310 - val_loss: 0.1367 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.5566 - accuracy: 0.7931 - val_loss: 0.1253 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.3619 - accuracy: 0.8276 - val_loss: 0.1319 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2566 - accuracy: 0.9310 - val_loss: 0.1409 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2486 - accuracy: 0.9310 - val_loss: 0.1518 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3500 - accuracy: 0.7586 - val_loss: 0.1607 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3124 - accuracy: 0.8621 - val_loss: 0.1636 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4063 - accuracy: 0.8621 - val_loss: 0.1652 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2494 - accuracy: 0.8621 - val_loss: 0.1689 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.7029\n",
            "Score for fold 2: loss of 0.6811813116073608; accuracy of 70.28571367263794%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.4150 - accuracy: 0.8276 - val_loss: 0.0749 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3208 - accuracy: 0.7931 - val_loss: 0.0712 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2577 - accuracy: 0.8966 - val_loss: 0.0641 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3180 - accuracy: 0.8621 - val_loss: 0.0571 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2649 - accuracy: 0.8621 - val_loss: 0.0475 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2505 - accuracy: 0.8966 - val_loss: 0.0410 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4020 - accuracy: 0.7931 - val_loss: 0.0361 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2866 - accuracy: 0.8621 - val_loss: 0.0331 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4537 - accuracy: 0.7586 - val_loss: 0.0345 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.3018 - accuracy: 0.8966 - val_loss: 0.0382 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2703 - accuracy: 0.8966 - val_loss: 0.0414 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2717 - accuracy: 0.8621 - val_loss: 0.0391 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2350 - accuracy: 0.8966 - val_loss: 0.0336 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2180 - accuracy: 0.9655 - val_loss: 0.0295 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4404 - accuracy: 0.8276 - val_loss: 0.0303 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3774 - accuracy: 0.7931 - val_loss: 0.0376 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2113 - accuracy: 0.8621 - val_loss: 0.0491 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.2310 - accuracy: 0.8966 - val_loss: 0.0490 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2404 - accuracy: 0.8966 - val_loss: 0.0446 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3116 - accuracy: 0.8276 - val_loss: 0.0397 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3207 - accuracy: 0.8276 - val_loss: 0.0355 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3637 - accuracy: 0.8621 - val_loss: 0.0361 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2452 - accuracy: 0.9310 - val_loss: 0.0359 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2072 - accuracy: 0.8966 - val_loss: 0.0343 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2536 - accuracy: 0.8966 - val_loss: 0.0327 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2933 - accuracy: 0.8966 - val_loss: 0.0308 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2176 - accuracy: 0.9310 - val_loss: 0.0298 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1673 - accuracy: 0.8966 - val_loss: 0.0283 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.4400 - accuracy: 0.7931 - val_loss: 0.0261 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2470 - accuracy: 0.9310 - val_loss: 0.0253 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2143 - accuracy: 0.8621 - val_loss: 0.0238 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1418 - accuracy: 0.9655 - val_loss: 0.0222 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1685 - accuracy: 0.9310 - val_loss: 0.0195 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3537 - accuracy: 0.8621 - val_loss: 0.0175 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2567 - accuracy: 0.8966 - val_loss: 0.0169 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.1782 - accuracy: 0.8966 - val_loss: 0.0171 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.3282 - accuracy: 0.8621 - val_loss: 0.0180 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.1704 - accuracy: 0.8966 - val_loss: 0.0193 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2207 - accuracy: 0.8621 - val_loss: 0.0204 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4021 - accuracy: 0.8621 - val_loss: 0.0206 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1226 - accuracy: 0.9310 - val_loss: 0.0204 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.2663 - accuracy: 0.8621 - val_loss: 0.0191 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2097 - accuracy: 0.8966 - val_loss: 0.0181 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1427 - accuracy: 0.9310 - val_loss: 0.0175 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3625 - accuracy: 0.7931 - val_loss: 0.0166 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1533 - accuracy: 0.9655 - val_loss: 0.0158 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1900 - accuracy: 0.9655 - val_loss: 0.0156 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3045 - accuracy: 0.8621 - val_loss: 0.0161 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.1195 - accuracy: 0.9655 - val_loss: 0.0161 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2937 - accuracy: 0.7931 - val_loss: 0.0154 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2965 - accuracy: 0.8966 - val_loss: 0.0149 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3683 - accuracy: 0.8276 - val_loss: 0.0148 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1248 - accuracy: 0.9655 - val_loss: 0.0154 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3043 - accuracy: 0.8276 - val_loss: 0.0170 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.2531 - accuracy: 0.8966 - val_loss: 0.0194 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3051 - accuracy: 0.8276 - val_loss: 0.0220 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1506 - accuracy: 0.9310 - val_loss: 0.0268 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1077 - accuracy: 0.9655 - val_loss: 0.0305 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4378 - accuracy: 0.7931 - val_loss: 0.0302 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2346 - accuracy: 0.8621 - val_loss: 0.0271 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3408 - accuracy: 0.8966 - val_loss: 0.0271 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.2225 - accuracy: 0.9310 - val_loss: 0.0260 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2575 - accuracy: 0.8966 - val_loss: 0.0278 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1426 - accuracy: 0.9655 - val_loss: 0.0282 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4773 - accuracy: 0.8621 - val_loss: 0.0266 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1158 - accuracy: 0.9310 - val_loss: 0.0283 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1393 - accuracy: 0.9655 - val_loss: 0.0289 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4425 - accuracy: 0.7586 - val_loss: 0.0260 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2333 - accuracy: 0.9310 - val_loss: 0.0247 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2744 - accuracy: 0.8276 - val_loss: 0.0259 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1728 - accuracy: 0.9310 - val_loss: 0.0267 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2474 - accuracy: 0.8621 - val_loss: 0.0280 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1600 - accuracy: 0.9310 - val_loss: 0.0335 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3028 - accuracy: 0.8276 - val_loss: 0.0387 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1083 - accuracy: 0.9655 - val_loss: 0.0399 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2069 - accuracy: 0.9310 - val_loss: 0.0349 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2552 - accuracy: 0.8621 - val_loss: 0.0305 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1401 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1738 - accuracy: 0.9655 - val_loss: 0.0228 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3423 - accuracy: 0.7931 - val_loss: 0.0242 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.1584 - accuracy: 0.8966 - val_loss: 0.0263 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.3479 - accuracy: 0.7586 - val_loss: 0.0268 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1832 - accuracy: 0.9310 - val_loss: 0.0240 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1526 - accuracy: 0.9655 - val_loss: 0.0218 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1891 - accuracy: 0.8966 - val_loss: 0.0198 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2255 - accuracy: 0.8621 - val_loss: 0.0184 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3185 - accuracy: 0.8621 - val_loss: 0.0156 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2251 - accuracy: 0.8966 - val_loss: 0.0143 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1108 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1181 - accuracy: 0.9655 - val_loss: 0.0136 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1646 - accuracy: 0.9655 - val_loss: 0.0148 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0829 - accuracy: 0.9655 - val_loss: 0.0156 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1025 - accuracy: 0.9310 - val_loss: 0.0159 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2051 - accuracy: 0.8966 - val_loss: 0.0147 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.2158 - accuracy: 0.8621 - val_loss: 0.0140 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4770 - accuracy: 0.7586 - val_loss: 0.0154 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.3275 - accuracy: 0.7931 - val_loss: 0.0183 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3017 - accuracy: 0.9310 - val_loss: 0.0214 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.7116 - accuracy: 0.7200\n",
            "Score for fold 3: loss of 0.7116196751594543; accuracy of 72.00000286102295%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.3701 - accuracy: 0.7931 - val_loss: 7.0082e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0573 - accuracy: 0.9655 - val_loss: 7.0566e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1804 - accuracy: 0.8621 - val_loss: 7.0958e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2140 - accuracy: 0.8966 - val_loss: 6.8852e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2847 - accuracy: 0.8621 - val_loss: 6.5582e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.3409 - accuracy: 0.8276 - val_loss: 6.0287e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2161 - accuracy: 0.9310 - val_loss: 5.4585e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 4.9247e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1894 - accuracy: 0.8966 - val_loss: 4.4040e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0860 - accuracy: 0.9310 - val_loss: 3.8965e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3105 - accuracy: 0.9310 - val_loss: 3.7369e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1778 - accuracy: 0.9310 - val_loss: 3.5542e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1505 - accuracy: 0.8966 - val_loss: 3.5306e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 3.6217e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2926 - accuracy: 0.8276 - val_loss: 4.0393e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.1656 - accuracy: 0.8276 - val_loss: 4.6658e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1171 - accuracy: 0.9655 - val_loss: 5.4818e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.3094 - accuracy: 0.8276 - val_loss: 6.0761e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0959 - accuracy: 0.9310 - val_loss: 6.6909e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2028 - accuracy: 0.8966 - val_loss: 6.8293e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1475 - accuracy: 0.9655 - val_loss: 6.9556e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.3466 - accuracy: 0.8276 - val_loss: 6.6007e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2801 - accuracy: 0.8621 - val_loss: 6.2140e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.3469 - accuracy: 0.8276 - val_loss: 6.8736e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 8.2934e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.5459 - accuracy: 0.7931 - val_loss: 8.0095e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1415 - accuracy: 0.9655 - val_loss: 6.8153e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2917 - accuracy: 0.8966 - val_loss: 5.6057e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 4.6506e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1118 - accuracy: 0.9655 - val_loss: 4.1192e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1580 - accuracy: 0.9310 - val_loss: 3.5382e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 2.9235e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.2083 - accuracy: 0.9310 - val_loss: 2.6317e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5004 - accuracy: 0.7586 - val_loss: 2.4684e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.4772 - accuracy: 0.8276 - val_loss: 2.9906e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2726 - accuracy: 0.8966 - val_loss: 3.3834e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1088 - accuracy: 0.9655 - val_loss: 3.8405e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3173 - accuracy: 0.8621 - val_loss: 4.4042e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1942 - accuracy: 0.8966 - val_loss: 4.7669e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1630 - accuracy: 0.8966 - val_loss: 4.7098e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1726 - accuracy: 0.8621 - val_loss: 5.0068e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1268 - accuracy: 0.9310 - val_loss: 5.0727e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1326 - accuracy: 0.8966 - val_loss: 4.6972e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1333 - accuracy: 0.9310 - val_loss: 4.4426e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1901 - accuracy: 0.9655 - val_loss: 4.1556e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1722 - accuracy: 0.8966 - val_loss: 3.7283e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2259 - accuracy: 0.8966 - val_loss: 3.4120e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1647 - accuracy: 0.8966 - val_loss: 3.0674e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3901 - accuracy: 0.8621 - val_loss: 3.3198e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1723 - accuracy: 0.8966 - val_loss: 3.3330e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1324 - accuracy: 0.9655 - val_loss: 3.1751e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1813 - accuracy: 0.8966 - val_loss: 2.9625e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2218 - accuracy: 0.8621 - val_loss: 2.7127e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2646 - accuracy: 0.8966 - val_loss: 2.6813e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2263 - accuracy: 0.8621 - val_loss: 2.4959e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1239 - accuracy: 0.9655 - val_loss: 2.2968e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1724 - accuracy: 0.8621 - val_loss: 1.9967e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1026 - accuracy: 0.9655 - val_loss: 1.8409e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.1096 - accuracy: 0.9310 - val_loss: 1.8178e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1812 - accuracy: 0.9310 - val_loss: 2.0079e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2255 - accuracy: 0.9310 - val_loss: 2.3148e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 2.4576e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2698 - accuracy: 0.9310 - val_loss: 2.5965e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.3205 - accuracy: 0.8621 - val_loss: 3.1637e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2577 - accuracy: 0.9310 - val_loss: 3.1963e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1292 - accuracy: 0.9655 - val_loss: 3.4894e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1821 - accuracy: 0.9310 - val_loss: 3.7476e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2508 - accuracy: 0.8621 - val_loss: 3.6448e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.2363 - accuracy: 0.8966 - val_loss: 3.3649e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2169 - accuracy: 0.9310 - val_loss: 3.3764e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.1989 - accuracy: 0.9310 - val_loss: 3.7931e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1871 - accuracy: 0.9310 - val_loss: 4.4074e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2111 - accuracy: 0.9310 - val_loss: 5.1695e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1169 - accuracy: 1.0000 - val_loss: 5.4220e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2523 - accuracy: 0.9310 - val_loss: 5.0118e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 4.4097e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.2779 - accuracy: 0.9310 - val_loss: 4.1097e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.4364 - accuracy: 0.8966 - val_loss: 4.2989e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.0918 - accuracy: 0.9310 - val_loss: 4.5305e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0767 - accuracy: 0.9655 - val_loss: 4.8579e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2221 - accuracy: 0.9310 - val_loss: 4.7850e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.4191 - accuracy: 0.8621 - val_loss: 4.6955e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1416 - accuracy: 0.9655 - val_loss: 4.7931e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.1011 - accuracy: 0.9310 - val_loss: 4.7173e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2422 - accuracy: 0.8621 - val_loss: 5.2508e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1184 - accuracy: 1.0000 - val_loss: 5.9897e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1252 - accuracy: 0.9655 - val_loss: 5.8406e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.1671 - accuracy: 0.9655 - val_loss: 4.7267e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.1322 - accuracy: 0.9310 - val_loss: 3.9888e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 3.3656e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2062 - accuracy: 0.8966 - val_loss: 2.7178e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2921 - accuracy: 0.8276 - val_loss: 2.4028e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1729 - accuracy: 0.8621 - val_loss: 2.1361e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1117 - accuracy: 0.9310 - val_loss: 1.8591e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1304 - accuracy: 0.9310 - val_loss: 1.7395e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.4562 - accuracy: 0.7931 - val_loss: 1.6443e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.2009 - accuracy: 0.9310 - val_loss: 1.6906e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1286 - accuracy: 0.9655 - val_loss: 1.5316e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.0544 - accuracy: 0.9655 - val_loss: 1.3227e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.4249 - accuracy: 0.8621 - val_loss: 1.2928e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.7486\n",
            "Score for fold 4: loss of 0.680374026298523; accuracy of 74.85714554786682%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 1.8721e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2422 - accuracy: 0.8966 - val_loss: 1.8377e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1333 - accuracy: 0.9310 - val_loss: 1.8472e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2321 - accuracy: 0.9310 - val_loss: 1.8417e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.2306 - accuracy: 0.8966 - val_loss: 1.8924e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1089 - accuracy: 0.9655 - val_loss: 1.7930e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0711 - accuracy: 0.9655 - val_loss: 1.6825e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1484 - accuracy: 0.9310 - val_loss: 1.8085e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.1303 - accuracy: 1.0000 - val_loss: 2.0918e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.1331 - accuracy: 0.9655 - val_loss: 2.0579e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3788 - accuracy: 0.7931 - val_loss: 2.1117e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2154 - accuracy: 0.9310 - val_loss: 2.0673e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.3452 - accuracy: 0.8276 - val_loss: 1.7150e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1316 - accuracy: 0.9655 - val_loss: 1.7621e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1314 - accuracy: 0.8966 - val_loss: 1.8808e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.2582 - accuracy: 0.9310 - val_loss: 2.0975e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1659 - accuracy: 0.9655 - val_loss: 2.1466e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1384e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.3313 - accuracy: 0.8621 - val_loss: 2.3693e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2720 - accuracy: 0.8621 - val_loss: 2.5032e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1730 - accuracy: 0.9310 - val_loss: 2.5404e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1721 - accuracy: 0.9655 - val_loss: 2.7582e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2568 - accuracy: 0.9310 - val_loss: 3.1165e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.0746 - accuracy: 0.9655 - val_loss: 3.2270e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1418 - accuracy: 0.9310 - val_loss: 3.3112e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1244 - accuracy: 0.9655 - val_loss: 3.3580e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.2135 - accuracy: 0.8621 - val_loss: 3.4864e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.3091 - accuracy: 0.8966 - val_loss: 3.6729e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1675 - accuracy: 0.9655 - val_loss: 3.5640e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1715 - accuracy: 0.9655 - val_loss: 3.2864e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.2104 - accuracy: 0.8966 - val_loss: 3.4709e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2961 - accuracy: 0.8621 - val_loss: 4.0888e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1258 - accuracy: 0.8966 - val_loss: 4.4543e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.2629 - accuracy: 0.8966 - val_loss: 4.7606e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1679 - accuracy: 0.9655 - val_loss: 4.7891e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1094 - accuracy: 0.9655 - val_loss: 4.6228e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2115 - accuracy: 0.8966 - val_loss: 4.5862e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 4.3669e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1387 - accuracy: 0.8966 - val_loss: 4.2877e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 4.2737e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.1235 - accuracy: 0.9310 - val_loss: 4.0502e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1625 - accuracy: 0.9310 - val_loss: 3.8327e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.1671 - accuracy: 0.9655 - val_loss: 3.4570e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.1864 - accuracy: 0.8966 - val_loss: 3.1922e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3166 - accuracy: 0.8276 - val_loss: 2.7159e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.1131 - accuracy: 0.9655 - val_loss: 2.5327e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 2.3037e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1916 - accuracy: 0.9310 - val_loss: 2.1264e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2511 - accuracy: 0.8966 - val_loss: 1.8756e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.5886e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1918 - accuracy: 0.9655 - val_loss: 1.3180e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.1039e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3356 - accuracy: 0.8276 - val_loss: 1.0446e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1263 - accuracy: 0.9655 - val_loss: 1.1075e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1816 - accuracy: 0.9310 - val_loss: 1.1398e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1852 - accuracy: 0.9310 - val_loss: 1.1514e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0987 - accuracy: 0.9310 - val_loss: 1.1201e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.1216 - accuracy: 0.9310 - val_loss: 1.0674e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.3069 - accuracy: 0.8621 - val_loss: 1.2510e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1422 - accuracy: 0.9310 - val_loss: 1.2953e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1979 - accuracy: 0.8966 - val_loss: 1.3744e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1422 - accuracy: 0.9655 - val_loss: 1.7012e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.0756 - accuracy: 0.9655 - val_loss: 1.7173e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0971 - accuracy: 0.9655 - val_loss: 1.8827e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2288 - accuracy: 0.9310 - val_loss: 1.7798e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.2233 - accuracy: 0.9310 - val_loss: 1.5735e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1293 - accuracy: 0.9310 - val_loss: 1.6453e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 1.8130e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.8362e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 1.7439e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1465 - accuracy: 0.8966 - val_loss: 1.6058e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3710 - accuracy: 0.8276 - val_loss: 1.8096e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1789 - accuracy: 0.9310 - val_loss: 2.2158e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2083 - accuracy: 0.9310 - val_loss: 2.4696e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.2211 - accuracy: 0.8966 - val_loss: 2.3756e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1720 - accuracy: 0.9310 - val_loss: 2.2478e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0996 - accuracy: 0.9655 - val_loss: 2.1085e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1549 - accuracy: 0.9310 - val_loss: 1.8976e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1960 - accuracy: 0.9655 - val_loss: 1.6106e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1490 - accuracy: 0.9310 - val_loss: 1.4270e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1266 - accuracy: 0.9310 - val_loss: 1.2217e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1217 - accuracy: 0.9310 - val_loss: 1.1034e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 1.0458e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 9.7499e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.2807 - accuracy: 0.8966 - val_loss: 9.4519e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1112 - accuracy: 0.9655 - val_loss: 9.0552e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1218 - accuracy: 0.8966 - val_loss: 8.3401e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1614 - accuracy: 0.9310 - val_loss: 7.9382e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0929 - accuracy: 0.9310 - val_loss: 7.7867e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1583 - accuracy: 0.8966 - val_loss: 7.6659e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.1207 - accuracy: 0.9655 - val_loss: 7.5228e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1283 - accuracy: 0.9310 - val_loss: 7.4888e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.0937 - accuracy: 0.9655 - val_loss: 7.2998e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1814 - accuracy: 0.8966 - val_loss: 7.2216e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.1578 - accuracy: 0.9310 - val_loss: 8.4476e-05 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2205 - accuracy: 0.9310 - val_loss: 1.2121e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 1.5330e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.1419 - accuracy: 0.9655 - val_loss: 1.8381e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.1720 - accuracy: 0.8966 - val_loss: 2.0152e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1912 - accuracy: 0.8966 - val_loss: 2.1006e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.8068 - accuracy: 0.7200\n",
            "Score for fold 5: loss of 0.8067720532417297; accuracy of 72.00000286102295%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i] * 100}%')\n",
        "  row.append(loss_per_fold[i])\n",
        "  row.append(acc_per_fold[i])\n",
        "\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold) * 100} (+- {np.std(acc_per_fold) * 100})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n",
        "\n",
        "row.append(np.mean(acc_per_fold))\n",
        "row.append(np.std(acc_per_fold))\n",
        "row.append(np.mean(loss_per_fold))\n",
        "row.append(BATCH_SIZE)\n",
        "row.append(EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NruadTK6IZ5d",
        "outputId": "5f24069a-c0ed-40f6-b39d-5448ab74d15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.712115466594696 - Accuracy: 74.85714554786682%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.6811813116073608 - Accuracy: 70.28571367263794%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.7116196751594543 - Accuracy: 72.00000286102295%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.680374026298523 - Accuracy: 74.85714554786682%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.8067720532417297 - Accuracy: 72.00000286102295%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 72.8000020980835 (+- 1.7925022840095512)\n",
            "> Loss: 0.7184125065803528\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_length = 5000\n",
        "test = "
      ],
      "metadata": {
        "id": "YU4N8BKG8yzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWv1qtA-86Bu",
        "outputId": "d13f917d-8ec6-40a4-bbe5-78d7f07e5c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Data"
      ],
      "metadata": {
        "id": "TUN6bmf8NSl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_iterator = zip(columns, row)\n",
        "a_dictionary = dict(zip_iterator)\n",
        "print(a_dictionary)\n",
        "test = df_csv\n",
        "print(test, \"\\n ------------------------\")\n",
        "test = test.append(a_dictionary, ignore_index=True)\n",
        "\n",
        "print(test)"
      ],
      "metadata": {
        "id": "PysNy9NmNQIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.to_csv('teste.csv', index = False, header= True)"
      ],
      "metadata": {
        "id": "psddAm3KaoZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwDA8if62yKn"
      },
      "source": [
        "### CNN - Small version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOosbeXk-kQ-"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW8V-ze9kKwz"
      },
      "outputs": [],
      "source": [
        "# This cell is used to fix one hot encoding automatic from keras in some datasets\n",
        "train_y = train_y.astype('uint8')\n",
        "test_y = test_y.astype('uint8')\n",
        "while(min(train_y) > 0):\n",
        "  train_y = train_y - 1\n",
        "while(min(test_y) > 0):\n",
        "  test_y = test_y - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_damj87UXQtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8d5b9f-6820-44f3-8eb2-bd7e0547571a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[254   0 254 ... 254   0 254]\n"
          ]
        }
      ],
      "source": [
        "print(\"Train: \", train_x.shape, \" | y = \", train_y.size)\n",
        "print(\"Test:  \", test_x.shape, \" | y = \", test_y.size)\n",
        "n_classes = np.unique(train_y).size\n",
        "print(\"Number of classes: \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZAmtIMU_EvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b4d5ab-5105-4f82-9a94-a6eafa2132b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width:  288 | Height:  432 | Channels:  3\n"
          ]
        }
      ],
      "source": [
        "width, height, channels = train_x.shape[1], train_x.shape[2], train_x.shape[3]\n",
        "print(\"Width: \", width, \"| Height: \", height, \"| Channels: \", channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paT1-UlA9eNR"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(train_x, train_y, batch_size=64) #DEPOIS SUSBTITUIR AO TRAVEZ POR TRAIN_Y e colocar no modelo aquilo que o nuno disse (ver notes)\n",
        "test_iterator = datagen.flow(test_x, test_y, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# confirm the scaling works\n",
        "batchX, batchy = train_iterator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "CYRTyDDp25nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "metadata": {
        "id": "yLQJK8vNIy0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "# early stopping\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "history = model.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=30)"
      ],
      "metadata": {
        "id": "Ti48E_tq25nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "print('Test accuracy:')\n",
        "_, acc = model.evaluate(test_iterator, steps=len(test_iterator))\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "metadata": {
        "id": "Nr7iZmHa25nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### History"
      ],
      "metadata": {
        "id": "Rn2gyM0925nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F4KM2iSJ25nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN - Plotting Time - Test"
      ],
      "metadata": {
        "id": "iHTw4UuMTRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare Date TEST\n"
      ],
      "metadata": {
        "id": "tBbhg5qmwKjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is used to fix one hot encoding automatic from keras in some datasets\n",
        "train_y = train_y.astype('uint8')\n",
        "test_y = test_y.astype('uint8')\n",
        "while(min(train_y) > 0):\n",
        "  train_y = train_y - 1\n",
        "while(min(test_y) > 0):\n",
        "  test_y = test_y - 1"
      ],
      "metadata": {
        "id": "jTFMlo-8wUxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train: \", train_x.shape, \" | y = \", train_y.size)\n",
        "print(\"Test:  \", test_x.shape, \" | y = \", test_y.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRpMmVW3xn9L",
        "outputId": "b7bf8c4a-7a19-41f7-c422-8e917b411aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (200, 288, 432, 1)  | y =  200\n",
            "Test:   (242, 288, 432, 1)  | y =  242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], train_x.shape[2], 1))\n",
        "# test_x = test_x.reshape((test_x.shape[0], test_x.shape[1], test_x.shape[2], 1))\n",
        "train_x = train_x[:,:,:,:1]\n",
        "test_x = test_x[:,:,:,:1]\n",
        "n_classes = np.unique(train_y).size\n",
        "print(\"Number of classes: \", n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RevEgQHAwJRL",
        "outputId": "31f44dd2-3c0b-4162-cdff-7a5e3e97ec6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.permutation(len(train_x))\n",
        "train_x = train_x[idx]\n",
        "train_y = train_y[idx]"
      ],
      "metadata": {
        "id": "RWrL_8TUwhV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width, height, channels = train_x.shape[1], train_x.shape[2], train_x.shape[3]\n",
        "print(\"Width: \", width, \"| Height: \", height, \"| Channels: \", channels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN7ngSZQyPEC",
        "outputId": "37d9be57-cf79-48e0-e04d-e96b76f28053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width:  288 | Height:  432 | Channels:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myXVzoM8ADUn"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUaLJI1YD5aR"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH1j1jG29MCx",
        "outputId": "13e3ac80-8f73-44e1-93cd-032c2d32cc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.9241 - sparse_categorical_accuracy: 0.1688 - val_loss: 1.7594 - val_sparse_categorical_accuracy: 0.2750 - lr: 1.0000e-04\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.8415 - sparse_categorical_accuracy: 0.2125 - val_loss: 1.7454 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.8245 - sparse_categorical_accuracy: 0.2000 - val_loss: 1.7352 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.7676 - sparse_categorical_accuracy: 0.2250 - val_loss: 1.7303 - val_sparse_categorical_accuracy: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 1.7345 - sparse_categorical_accuracy: 0.2625 - val_loss: 1.7310 - val_sparse_categorical_accuracy: 0.2750 - lr: 1.0000e-04\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.7637 - sparse_categorical_accuracy: 0.2688 - val_loss: 1.7241 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.7160 - sparse_categorical_accuracy: 0.2438 - val_loss: 1.7240 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.7132 - sparse_categorical_accuracy: 0.2625 - val_loss: 1.7228 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.7182 - sparse_categorical_accuracy: 0.2625 - val_loss: 1.7126 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.6352 - sparse_categorical_accuracy: 0.3438 - val_loss: 1.6958 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6727 - sparse_categorical_accuracy: 0.2313 - val_loss: 1.6802 - val_sparse_categorical_accuracy: 0.2750 - lr: 1.0000e-04\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.6415 - sparse_categorical_accuracy: 0.3063 - val_loss: 1.6734 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 1.6628 - sparse_categorical_accuracy: 0.3063 - val_loss: 1.6836 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 1.6440 - sparse_categorical_accuracy: 0.2750 - val_loss: 1.6887 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 1.6472 - sparse_categorical_accuracy: 0.2688 - val_loss: 1.6813 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6138 - sparse_categorical_accuracy: 0.3375 - val_loss: 1.6668 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.6227 - sparse_categorical_accuracy: 0.3250 - val_loss: 1.6561 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6270 - sparse_categorical_accuracy: 0.3250 - val_loss: 1.6532 - val_sparse_categorical_accuracy: 0.3500 - lr: 1.0000e-04\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6468 - sparse_categorical_accuracy: 0.3187 - val_loss: 1.6496 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5920 - sparse_categorical_accuracy: 0.3063 - val_loss: 1.6458 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5191 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.6408 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5135 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.6309 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.5831 - sparse_categorical_accuracy: 0.3187 - val_loss: 1.6162 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5021 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.6014 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5033 - sparse_categorical_accuracy: 0.3875 - val_loss: 1.5775 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.5141 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.5690 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.4511 - sparse_categorical_accuracy: 0.4563 - val_loss: 1.5662 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.4494 - sparse_categorical_accuracy: 0.3750 - val_loss: 1.5476 - val_sparse_categorical_accuracy: 0.3500 - lr: 1.0000e-04\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.4655 - sparse_categorical_accuracy: 0.3875 - val_loss: 1.5335 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 1.5088 - sparse_categorical_accuracy: 0.3688 - val_loss: 1.5510 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 1.4694 - sparse_categorical_accuracy: 0.4187 - val_loss: 1.5464 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 1.4579 - sparse_categorical_accuracy: 0.3688 - val_loss: 1.5351 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.3448 - sparse_categorical_accuracy: 0.5188 - val_loss: 1.5055 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.4025 - sparse_categorical_accuracy: 0.4313 - val_loss: 1.4875 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 27s 7s/step - loss: 1.4793 - sparse_categorical_accuracy: 0.3375 - val_loss: 1.4867 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 1.3287 - sparse_categorical_accuracy: 0.3938 - val_loss: 1.4947 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.4727 - sparse_categorical_accuracy: 0.3625 - val_loss: 1.4951 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 1.3839 - sparse_categorical_accuracy: 0.4125 - val_loss: 1.4979 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 29s 7s/step - loss: 1.3453 - sparse_categorical_accuracy: 0.4938 - val_loss: 1.4780 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 35s 9s/step - loss: 1.3167 - sparse_categorical_accuracy: 0.4750 - val_loss: 1.4457 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 35s 9s/step - loss: 1.3951 - sparse_categorical_accuracy: 0.4437 - val_loss: 1.4378 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 1.2821 - sparse_categorical_accuracy: 0.4812 - val_loss: 1.4425 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 29s 7s/step - loss: 1.3096 - sparse_categorical_accuracy: 0.4938 - val_loss: 1.4216 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 1.2583 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.4294 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.2812 - sparse_categorical_accuracy: 0.4812 - val_loss: 1.4568 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.2505 - sparse_categorical_accuracy: 0.4563 - val_loss: 1.4259 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.2624 - sparse_categorical_accuracy: 0.4750 - val_loss: 1.4172 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 33s 8s/step - loss: 1.2154 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.4145 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 1.1342 - sparse_categorical_accuracy: 0.5688 - val_loss: 1.4284 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 33s 8s/step - loss: 1.1032 - sparse_categorical_accuracy: 0.5750 - val_loss: 1.4025 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 1.0604 - sparse_categorical_accuracy: 0.6000 - val_loss: 1.4139 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 1.1611 - sparse_categorical_accuracy: 0.5188 - val_loss: 1.4113 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.1869 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.4140 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 1.2136 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.4173 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 27s 7s/step - loss: 1.0664 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.4016 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 36s 9s/step - loss: 1.0145 - sparse_categorical_accuracy: 0.6438 - val_loss: 1.3896 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.1318 - sparse_categorical_accuracy: 0.5625 - val_loss: 1.3892 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 35s 9s/step - loss: 1.1228 - sparse_categorical_accuracy: 0.5688 - val_loss: 1.3796 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 36s 9s/step - loss: 1.0267 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.3524 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 34s 8s/step - loss: 1.0836 - sparse_categorical_accuracy: 0.5938 - val_loss: 1.3317 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.9577 - sparse_categorical_accuracy: 0.6000 - val_loss: 1.3641 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.0716 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.3962 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 1.0361 - sparse_categorical_accuracy: 0.6000 - val_loss: 1.3738 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.9706 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3337 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.1014 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.3262 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.9086 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3485 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.0086 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3603 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 1.0156 - sparse_categorical_accuracy: 0.5437 - val_loss: 1.3619 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.9425 - sparse_categorical_accuracy: 0.6562 - val_loss: 1.3623 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.9341 - sparse_categorical_accuracy: 0.6187 - val_loss: 1.3699 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.9600 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3453 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 26s 6s/step - loss: 0.9424 - sparse_categorical_accuracy: 0.6625 - val_loss: 1.3175 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.0018 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.3081 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.9420 - sparse_categorical_accuracy: 0.6125 - val_loss: 1.3193 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.9182 - sparse_categorical_accuracy: 0.6187 - val_loss: 1.3483 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8678 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3570 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8885 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.3571 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.9167 - sparse_categorical_accuracy: 0.6250 - val_loss: 1.3349 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.9097 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3445 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 29s 7s/step - loss: 0.8593 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3049 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 33s 8s/step - loss: 0.8662 - sparse_categorical_accuracy: 0.6562 - val_loss: 1.3007 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.8913 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3305 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.8868 - sparse_categorical_accuracy: 0.6187 - val_loss: 1.3175 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.9068 - sparse_categorical_accuracy: 0.6313 - val_loss: 1.3150 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8793 - sparse_categorical_accuracy: 0.6125 - val_loss: 1.3198 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.7014 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.3507 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8270 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3683 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7734 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.3474 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8736 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3059 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.7952 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.2685 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8509 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.3118 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8002 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3988 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8350 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.4247 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7009 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.4373 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.8135 - sparse_categorical_accuracy: 0.6938 - val_loss: 1.3635 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7216 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3086 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7627 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.2981 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7379 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.3289 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.6605 - sparse_categorical_accuracy: 0.7812 - val_loss: 1.3270 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8579 - sparse_categorical_accuracy: 0.6313 - val_loss: 1.2982 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8002 - sparse_categorical_accuracy: 0.6938 - val_loss: 1.3041 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3436 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.7307 - sparse_categorical_accuracy: 0.7125 - val_loss: 1.3157 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8221 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.3204 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6794 - sparse_categorical_accuracy: 0.6875 - val_loss: 1.3537 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6419 - sparse_categorical_accuracy: 0.7500 - val_loss: 1.3997 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7412 - sparse_categorical_accuracy: 0.7125 - val_loss: 1.4253 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7196 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.4171 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.3913 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7688 - val_loss: 1.4075 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7859 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3455 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.6875 - val_loss: 1.3273 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8062 - val_loss: 1.3361 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.5929 - sparse_categorical_accuracy: 0.7688 - val_loss: 1.3606 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7944 - sparse_categorical_accuracy: 0.6625 - val_loss: 1.3715 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6829 - sparse_categorical_accuracy: 0.7500 - val_loss: 1.4011 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6832 - sparse_categorical_accuracy: 0.7500 - val_loss: 1.3791 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.7250 - val_loss: 1.3599 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7221 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.4168 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8161 - sparse_categorical_accuracy: 0.6438 - val_loss: 1.3251 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.5804 - sparse_categorical_accuracy: 0.8000 - val_loss: 1.3252 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7142 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.3972 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.7083 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.4381 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6407 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.3889 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3857 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.3924 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.5894 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.4147 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.7265 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.4179 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6501 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.4335 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6178 - sparse_categorical_accuracy: 0.7750 - val_loss: 1.3844 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.5697 - sparse_categorical_accuracy: 0.7375 - val_loss: 1.3489 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6627 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3600 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.8375 - val_loss: 1.4064 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.6975 - sparse_categorical_accuracy: 0.7125 - val_loss: 1.4406 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.4955 - sparse_categorical_accuracy: 0.7875 - val_loss: 1.4709 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6435 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.4614 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6692 - sparse_categorical_accuracy: 0.7625 - val_loss: 1.4565 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.6017 - sparse_categorical_accuracy: 0.7563 - val_loss: 1.3905 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.7750 - val_loss: 1.3579 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.5258 - sparse_categorical_accuracy: 0.8188 - val_loss: 1.4181 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 140: early stopping\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "# model.add(InputLayer(input_shape=(width, height, channels)))\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.7)) #Aumentar depois maybe o dropout\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer = opt,\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    metrics = [\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_x,\n",
        "    train_y,\n",
        "    batch_size=32,\n",
        "    # batch_size=64,\n",
        "    epochs=500,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wi2UZZbQXTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5816c36c-9979-49fd-858b-b2f13b31b5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6227 - sparse_categorical_accuracy: 0.4545\n",
            "Test accuracy 0.4545454680919647\n",
            "Test loss 1.622735619544983\n"
          ]
        }
      ],
      "source": [
        "# model = keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkZ9FkeRFIFn"
      },
      "source": [
        "#### History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "D6TZROKLCyug",
        "outputId": "ccc99b71-1318-43e5-a61b-3024e468bae7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEZCAYAAAB4hzlwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d3hc1Zn4/3klzWjUq+Ui2ZabbFzA4EIHU4INCZAsX0JNQsoSsmlsks2SbDYh9ZfsLkk2nZDNZkMSCCEQSgDTQ3VsAwZ3uVvF6pY0KqNp5/fHuXfmzmhGmpE0rufzPPNodOt7R6PznrceUUphMBgMBgNA1tEWwGAwGAzHDkYpGAwGgyGCUQoGg8FgiGCUgsFgMBgiGKVgMBgMhghGKRgMBoMhglEKhggi8hsR+VaKx+4XkUszLZNhdETkJhF5egKuo0Rk7kTIZDh+MUrBYBgnInKLiLxytO6vlPq9Uuqyo3V/w4mFUQqG4xIRyTnaMhwLnGyfw8n2vEcDoxSOMyy3zb+IyDsi0i8i/yMik0XkSRHxisizIlLmOP4qEdkqIt0i8qKInOLYd7qIvGmd90fAE3ev94jIJuvc10Tk1BRlvEJEtlnXbRKRL1jbV4lIo4h8WUQ6rGe5yXHeu0XkLRHpFZEGEbnTsa/Wcm98VEQOAs+LiEdEficinZaMG0RksnV8ifXZHLJk+JaIZKcg+z+KyHZL9m0icoa1/Q4R2ePY/j5r+ynAL4CzRaRPRLqt7bki8l8iclBEWkXkFyKS57jPFy3ZmkXkY07XjSX7b0WkXUQOiMhXRCTL2neLiLwqIj8QkU7gznhLRUQWicgzItJl3fvL1vaVIvK69VkdEpGfiIg7lb9pKn8ja/951nel29p/i7U9T0Tusp6nR0ResbatEpHGuGtEXJMicqeIPGj9nXuBW0Z7jkTPLyJTRGRARCocx51hfcaudD6DEx6llHkdRy9gP7AOmAxUA23Am8Dp6EH9eeBr1rF1QD/wLsAFfBHYDbit1wHgn619/w8IAN+yzj3duvaZQDbwIeveuQ45Lk0i4yHgfOt9GXCG9X4VEAS+D+QCF1ryzXfsX4KerJwKtALvtfbVAgr4LVAA5AEfBx4D8i0ZlwHF1vEPA3dbx1YB64GPj/LZXgs0ASsAAeYCMx37plmyXWfJPdXadwvwSty1fgA8CpQDRZac/5+1bw3QAiyyZP+d9Wxzrf2/BR6xzqsF6oGPOu4VBD4N5FifQ+T+1jmHgM+jvw9FwJnWvmXAWdZ5tcB24HaHzBEZRviMRvobzQS8wA3o71QFsNTa91PgRfR3Nhs4x/oOrAIaE3zHL7Xe34n+Xr7XumfeSM8xyvM/AXwi7m/046P9P32svY66AOaV5h9M/8Pc5Pj9z8DPHb9/GviL9f7fgQcc+7LQg94q4AKgGRDH/teIKoWfA9+Mu/dO4EKHHMmUwkH0gF0ct32VNaAVOLY9APx7kuv8EPiB9b7WGrRmO/Z/xJL51LjzJgNDQJ5j2w3AC6N8tmuBz6b4d9gEXG29vwWHUkArlH5gjmPb2cA+6/2vsRSE9ftc69nmWgOmH1jo2P9x4EXHvQ7GyRK5v/Wcb6X4DLcDDzt+H1UpjPI3+pLzenHfu0HgtAT7VjG6Ungp1ecY6fnRyvxV6302WjGvTOd5T4aXcR8dn7Q63g8m+L3Qej8NbQ0AoJQKAw3o2do0oElZ/yEWBxzvZwKft0z0bsstMt06bzSuAa4ADojI30TkbMe+w0qp/rh7TgMQkTNF5AXLpO8BbgMq467d4Hh/L3ogv99yw/yH5QqYiZ6pHnLIfjfaYhiJ6cCeRDtE5IMSdaV1A4sTyGYzCW0BvOE4/ilrO9bzOp/D+b7Skt35tziA/pslOj6dZ6gTkcdFpMVyxXxnhGdIyCh/o2T3rkTP2hPKlQIxzzvKcyR9frT1tVBEZqGt5x6l1PoxynTCYpTCiU0zeoAEQEQE/U/ThDaxq61tNjMc7xuAbyulSh2vfKXUfaPdVCm1QSl1NXoQ/gvaGrApE5GCuHs2W+//gHa5TFdKlaB99U75QM9m7fsElFJfV0otRLsj3gN80JJ9CKh0yF6slFo0iugNwJz4jSIyE7gH+BRQoZQqBbY4ZItvNdyBVs6LHPcvUUrZyvoQUOM4fnrcuQEcfzf0Z9SU6DNI8gyzk+z7ObADmKeUKga+zPDPdzRG+hsl/PzQz+RLsq8frUABEB33mRR3TPzzjvQcSZ9fKeVDfxdvBj6AnlQY4jBK4cTmAeDdInKJNYP+PHqwfA14He3K+YyIuETkH4CVjnPvAW6zZoYiIgVWkLFopBuKiFt03nyJUioA9ALhuMO+bh13Pnog/5O1vQjoUkr5RGQlcOMo97pIRJZYA0kvejANK6UOAU8Dd4lIsYhkicgcEblwlM/rV8AXRGSZ9cxzLYVQgB6Y2q37fhhtKdi0AjV2sNOyyO4BfiAiVdY51SKy2jr+AeDDInKKiOSj3XxY54as/d8WkSLr/p9Dxx1S4XFgqojcLjrYXSQiZ1r7iqzPqU9EFgCfSPGaTkb6G/0euFRE3i8iOSJSISJLrc/j18D3RWSaiGSLyNkikouOl3is75YL+Ao61jCaDMmeY6TnBx2vuQW4CqMUEmKUwgmMUmonelb0Y/Rs7UrgSqWUXynlB/4B/Q/Shfa3PuQ4dyPwj8BPgMPoAPUtKd76A8B+y7S/DbjJsa/Ful4zehC5TSm1w9r3T8A3RMQLfJVYCyMRU4AH0QPEduBvRP/RP4gOpm+z7vcgMHWkiyml/gR8Gz0b9qKtnHKl1DbgLrQibUUHWl91nPo8sBVoEZEOa9u/oj+zddbn8Cww37rPk8CPgBfsY6xzhqyfn0bPoPcCr1jy/HqUz8J+Bi/aNXIl+rPeBVxk7f4CehD3opXWH1O5ZhxJ/0ZKqYNot+Hn0d+pTcBpjntvBjZY+74HZCmleqxr/gptDfUDMdlICUj6HKM8P0qpV9GTlDeVUk4XncFCYl3KBkPmEJFVwO+UUjWjHXsyITqtdQs6syt4tOU50RGR54E/KKV+dbRlORYxloLBcBQQkfdZ7o0y9Kz5MaMQMo+IrADOYGxW0kmBUQqGkwrRRWR9CV6/OMKifBxdB7IHCDE2/35GEF3smOgzumn0s49dROT/0G682y03kyEBxn1kMBgMhgjGUjAYDAZDhOO6uVRlZaWqra092mIYDAbDccUbb7zRoZSKrwcBjnOlUFtby8aNG4+2GAaDwXBcISJJ03GN+8hgMBgMEYxSMBgMBkMEoxQMBoPBEOG4jikkIhAI0NjYiM/nO9qiZBSPx0NNTQ0ul1kfxGAwTBwnnFJobGykqKiI2tpaYhuAnjgopejs7KSxsZFZs2YdbXEMBsMJxAnnPvL5fFRUVJywCgFARKioqDjhrSGDwXDkOeGUAnBCKwSbk+EZDQbDkeeEVAoGg8FwLNM94Oext5tHP/AoYJTCBNPd3c3PfvaztM+74oor6O7uzoBEBoPhWOPht5r49H1v0e4dGv3gI4xRChNMMqUQDI7cFfmJJ56gtLQ0U2IZDIZjiO6BAAA9g4GjLMlwTrjso6PNHXfcwZ49e1i6dCkulwuPx0NZWRk7duygvr6e9773vTQ0NODz+fjsZz/LrbfeCkRbdvT19XH55Zdz3nnn8dprr1FdXc0jjzxCXl7eUX4yg8EwUfT6tDLw+oxSOKJ8/bGtbGvundBrLpxWzNeuTL7++3e/+122bNnCpk2bePHFF3n3u9/Nli1bIqmjv/71rykvL2dwcJAVK1ZwzTXXUFFREXONXbt2cd9993HPPffw/ve/nz//+c/cfPPNE/ocBoPh6NE7qD0HXt+xt66ScR9lmJUrV8bUEvzoRz/itNNO46yzzqKhoYFdu3YNO2fWrFksXboUgGXLlrF///4jJa7BYDgCRC2FsSmFQCg8keLEcEJbCiPN6I8UBQUFkfcvvvgizz77LK+//jr5+fmsWrUqYa1Bbm5u5H12djaDg4NHRFaDwXBk6B0cu/uoZzDAsm8+w9evXsRNZ86caNGMpTDRFBUV4fUmXumvp6eHsrIy8vPz2bFjB+vWrTvC0hkMhmOBXstC6B2DUtjd5iUYVkwp9ky0WMAJbikcDSoqKjj33HNZvHgxeXl5TJ48ObJvzZo1/OIXv+CUU05h/vz5nHXWWUdRUoPBcLSIWgrpu492tvQBUDe5aEJlsjliSkFE1gD/DWQDv1JKfTdu/wzg/4BS65g7lFJPHCn5JpI//OEPCbfn5uby5JNPJtxnxw0qKyvZsmVLZPsXvvCFCZfPYDgR2dPex5xJhUdbjJQYT0yhvtVLvjub6tLMZCQeEfeRiGQDPwUuBxYCN4jIwrjDvgI8oJQ6HbgeSL8CzGAwnJTsbPFyyV1/46X69qMtyqiEw4q+obG7j3a1eZlXVUhWVmZa3RypmMJKYLdSaq9Syg/cD1wdd4wCiq33JcCxWQNuMBiOOQ716GSMjQcOj+s6+zv62dmSOCY4UXiHgihlvR+j+2hehlxHcOSUQjXQ4Pi90drm5E7gZhFpBJ4APp3oQiJyq4hsFJGN7e3H/qzAYDBkHjtwu7WpZ1zX+c4T2/nCn96eCJGS0uuoYk43++hwv5+OviHmnwBKIRVuAH6jlKoBrgDuFZFh8imlfqmUWq6UWj5p0qQjLqTBYDj2sAfazeNUCt2DAdq8mW1Jb7uMRKJFbKlS36qtmHmTMxc7OVJKoQmY7vi9xtrm5KPAAwBKqdcBD1B5RKQzGAzHNfZA2+Ydoq137IP6gD9IV78fZft3MoCtCCYXefAOpWcp2EohU5lHcOSUwgZgnojMEhE3OpD8aNwxB4FLAETkFLRSMP4hg8EwKk7f/JbmsVsL/UMhAqFoIDgT2AqsuiwvIrdSim//dRvbD43clqe+tY+i3BymlmSmRgGOkFJQSgWBTwFrge3oLKOtIvINEbnKOuzzwD+KyNvAfcAtKpPq+hihsPD4SKEzGI5legcDFLizAdjSNPZ+Z/2WMjjcn7lGdbarq7pUKwWlFO3eIe55eR+PjrLGQn2rl3mTCzO6yFbKdQoi8jC6juCvSqm0PzGr5uCJuG1fdbzfBpyb7nUNBsOxw7//ZQtLqkt4/4rpox88gfT6gky2KnzHE1cY8IcA6BrwM6Mif0Jki8cOileX5REKKwYDIdqsdRUOdg0kPU8pRX2rlzWLp2RELpt0LIWXga8CLSLycxE5J0MyHdfccccd/PSnP438fuedd/Ktb32LSy65hDPOOIMlS5bwyCOPHEUJDYbM4AuEuG/9Qf6268h7fXsHAxTluVhcXTLmDCSlFP1+PWB39Wdu8ZvewQAiMM0qPusdDEaC240jKIWOPj+HBwLMq8pcPAHSsBSUUt8Hvi8ii4CbgftExA/cC/xeKbUnQzKOnSfvgJbNE3vNKUvg8u8m3X3ddddx++2388lPfhKABx54gLVr1/KZz3yG4uJiOjo6OOuss7jqqqvMOsuGE4qdLbonT38G/fHJ6PUFKPbksKS6hEffbqazb4iKwtzRT3TgC4Qj9QNdE+A+Ukqx+ocv8bHzZsdYTr2+AIW5OZTkuQCdltrWO7qlYMdKMhlkhjHEFJRSW5VSX0IrhgHga8CbIvKsiJw20QIeb5x++um0tbXR3NzM22+/TVlZGVOmTOHLX/4yp556KpdeeilNTU20trYebVENhgnFdttkUin0DwXxBULDtvcOBijOc7GoWte/bhnDOiq2lQC6HmC8dPX7qW/t47kdsf/rvYNBij0uijx6Tt7rC9JqKYXDA4GktQsPv9lEsSeH5bVl45ZtJNLqfSQi89HK4EbAthLeg84S+ifgL8CspBc40owwo88k1157LQ8++CAtLS1cd911/P73v6e9vZ033ngDl8tFbW1twpbZBsPxzJaIUhg+aE8Ut/zveqaW5PGjG06P2d7r0wPtomklAOw41MuFdenVMQ045O4aGL9SaLFSY+MD370+rcCKLaXg9cXWRjR0DbJwmivmnK5+P09taeHGM2fgcWWPW7aRSNlSEJGNwKtAOXCjUuoUpdR3lFINSimf5V4yoF1I999/Pw8++CDXXnstPT09VFVV4XK5eOGFFzhw4MDRFtFgmHBs94Zzxj2RtPb62LD/MPs6+oft05aCdsnk5mTRNYaZvjMNdSIshZYePdA3dQ/GXK93ULu6ijy2+yhIm3eIHKuXke1C6ugbYr/1rA+92Yg/FOb6lZkP4KfjPvouME0p9Uml1N8THaCUOnashKPIokWL8Hq9VFdXM3XqVG666SY2btzIkiVL+O1vf8uCBQuOtogGw4QyFAxFegZlyn30wo42ADr7YoPAvkCIoWCYYmuQLc130T2QfkxgwKHMOidCKTiK6Jy1E72+IMV5UfeRrRQWVWsrp8FSCl96aDPv+sHfeGBjA/dvaGDp9FIWTCkm06TjPuoFaoF6e4PlTpqhlHpmguU67tm8ORrgrqys5PXXX094XF9f35ESyWDIGLta+wiEFNWleWOapafCc5ZS6LAqju1EDbsArNgK3JbmuekeTF+GfisdNTcna8IsBRFQSsdbzp+n3Vm9gwGKpxZHlFivL0Bbr49z5lSyr72Pg10DhMOKdXs7yRLhiw++A8D3rlkybplSIR1L4adAfPtAr7XdYDCcxNhB5jNnlTMYCBEKT2zdqS8Q4pVdHbizs/AHw5EBHKIVwraPvmSsloJl4dSU5U1MTKHHx5RiD9PL89jqiCvomEIO+e5ssrOE3sEA7d4hqopzmVGRT8PhAXa2evH6gnzzvYv50NkzmVtVyHtOnTZumVIhHUuhSil1KG7bISCzlRQGg+GYZ0tTD0WeHE6ZWgxvNdHvD0ZmwqmytbmHDfu6uOXc4V7odXs7GQyEeM+pU3n8nUN09g1RmGtl71gVwlFLwRWT2vnq7g4e2KibNE8rzeOLq+cnTAe3Fc308nzebuhOS/ZEtPT6mFzsYVqpJ6I07bUUij0uRITC3BwOdg0QDCuqinKZUZ7PjhYvG/Z3AXD27Arev/zIFgKmYynsFZGL47atAvZNnDgTw0nQHeOkeEbD8cOWph4WTyuhwBqoB8aQgfT7vx/kzse2JVx45oUdbeS5siOz5Y4+R+DWdh8liSn89vX9PLm5hXV7O/n5i3vYmiRd1Y4p1JTl0T0YGLe1c6jHx9QSD4umlXCwa4CegUBkLQVbgRV5ctjdpl3Ik4s9TC/Lp7FrkL/v7WJKsYeassysrjYS6SiFO4GHROQuEfknEbkL+DO6yvmYwePx0NnZeUIPmkopOjs78Xgy1xTLcPzTeHiAT/7+zZgAaiYIhMJsb/GyuLqYglydLjmWhnJNh/VCOVsT9C56fmcb586tZFqp/s53xWXzAJTkaYVUmu+mx7FmQWefn+W1ZTz+6fMRiQas47FTaWvK8lEKulN0IT23vZUvPfQO4Tgl0tqjLYUlVgB5a3NPRFY7yFzkcUWyqaqKcpleno8/FOaFnW2smFV+VApc06lofkRELgM+ArwbvWjOaqXUhkwJNxZqampobGzkRF+Ax+PxUFNTc7TFMBzD/H1vF3/dfIhbzq1lRW15xu6zv6MffzDMwmnFEZfOWBRRc7elFJp7OHtORWR731CQhq5Bblg5I1Kl7MxAisYU9Oy7JM/FYCCELxDC48qms9/P4uoSJhXlclpNKc/taOPTl8wbdv8Bf5AsIdKB9PCAP6Wq6IfebOKvmw9x+vSySOVy31AQ71CQqSUeFltKYXNTDyX5rhhZizw5DAXDAFQVeSK9lwb8IVZmuEgtGWkVryml1gPrMyTLhOByuZg1y2TGGgx2Zaw92GaKnfbCL1VFkUygdC0FpVREzviGdoes7dWleVQUuIHYlFF7fQLbJWO3j+gdDOBxZdPRNxQ575IFVXz/2XravUNMKood8PuGghS4c6go0NtTbXVhr3Hwvad2sHrRFEryXZEahSklHsoL3FSX5rGpoZtTa0otWfXQ64y7VBXnEnZ4OJZnUJGPRFptLkRkqYh8WkS+brW9/oaIfCNTwhkMhrFjD8xN41QK4bAa5hpxUt/aR5bA3KrCiKWQblVzz2AgEujdEqcUGh1KwePKpsCdTWdMTCGAOzuL3Bw9nJVas/HuwQD+YBivLxhRChefUoVS8OLO4S6kgaEQ+bnZlFvHxqfWDgWHP5M/GGZfRz8XL6ji8ICfHzyrM/YjSsHq3Hrxgiqe39FGw2EdALeVgZ0xVezJwePKZlppHiL690wuuTkS6VQ034quaL4Y+FdgCXoNhLmZEc1gMIwHe9Zu++rHyof+dz1feWRL0v27Wr3MrCjA48om34oppOs+shXXgilF7O3oj7E0bAvC7ipaUZhLp6OLqV3NbPvfS/P0oN49EIgM7LYbaOHUYqYUe3g+QVyh368thURKobXXx2lff5oHNjTEnLOvo59gWHH10mnceOYMfvv6fpq6BznUo2WeYrmirl85naFgmN++vh+IWjN2bKHKUh7unCyml+WzclY5WVlHp2FmOpbCF4E1Sqn3AYPWz/8HZG41CoPBMGa81sA6HveRUopNB7t5ZVdH0mN2tnqZV6UXi7IthXTdR83dema9etEUlIJtjgyh5u5BsrMksl5CRaE7zlKITX+NWAoDepF7IDLQiwgXLajipfp2/JYv32bAry0F+/zDjkDz63s68QXCfOfJ7TGFbfUO19mHz51FWMHz21tptaqZbZkXTSvh1JqSSB+kaEzBZR0XdWXd/YFlfOPqxSl/dhNNOkqhSin1svU+LCJZSqkngSszIJfBYBgntqVgD7hjoWdQp1HaKZXxDAVDHOgcYP4U7eooiLiP0rQULLfK6kW67MnpQmo6PMiUYg/Z1sy5oiA3Lqag11KwsWfh3YNRS6Gy0B3Zf+kpVfT7Q7wct+5D/1CQfHdOxEXltBQ27O/C48rC6wvyX0/vjGyvb/WSnSXMnlTA7MoCaivyeW5HG4d6fJTlu2Ka112/YkbkfWEk+8iyFIqimYSnTC2OWEVHg3SUQqOI1Frv64GrReR8dLdUg8FwjNFnBZqbugfHnKLtLAKz+/d4fYGI5bC3vZ9QWDHP8n/nW4NgfEwhFFa8sKONQCh2dm7T3OMjNyeLU6YWMakoN0YpNHf7qHYMkhUF7mHZR7ZvHqKWQs9AIOJmcmYRnT9vEpWFbu6PcwUN+EORJT3LCtwxFsGG/V2cOauCD549kz+sPxiRr77Vy8yKfDyubESEixdM5rU9nezr6GdKSezAftXSaeS7synKzYkoODs4XlWU3toPmSQdpfAfwCnW+28AvwOeB74+0UIZDIbxY7tw+oaCkQKvdIlRCtZA+MuX9nLz//yd7Yd6I+6TusnafZSVJeS7s4dZCg+92ciHf7OBW/53fUKLo6l7kOrSPESEJdUlMQ3kmroHqXYUcVUUuumy+h9BdC0Fm0Jr0O0ZDETcTLb7CLTf/pplNTy/o402R9O6fn8wYulUFLgj1shha12ElbPKuf3SOkrzXPz4+V2ADrLXOVZCu+SUKvzBMK/v7Yyktjrlun7FDGZXRddlty2F+Eyoo0lKSkF0BOcl4BkAy21UBpQppX6eOfEMBsNY8fqCkRnpWOMKDV36vIoCdyRV9NntOkh7//qD1Ld6yckSZldGB7qC3Jxh7bOf295GUW4O6/d18b6fvxozGIN2Edkuk8XTitnd1seAP0gwFKal1xcpWgM96w+GVSQVNT6mICKU5LnoHvTT2e/HlS0xlgRoV04orPjTG42Rbf1WSipYloIVU3jjwGEAls8soyTPxbXLp/Pc9jYaugY40NlP3ZSoUlhRW05hbg5KReMJTr7y7lN4+BPRlYyjMYVjpxA1JaWgtEreDIQd2/xKKdPi02A4RvH6gsyqLADGnoF0sGuA8gI3y2vL2NrcS3P3INsP9ZLnyubht5p4p7GH2soC3DnRoaTAnR3jPhoKav/9VUunce9Hz2Rvez9/frMp5j7N3YORgf/UmlLCCt5p7KHNO0QorKguzY8ca6eXdliuITv7yElpnm510dk3REVB7rDK4FmVBZw9u4L7NxyMpNvaKakA5fnuSExhw/4u3NlZnDZd1xhcv2I6wbDie0/tIKyiVhJoK+T8eZUAwywF0JaUM6towZQiFkwpYql17WOBdNxHbwF1Y72RiKwRkZ0isltE7kiw/wcissl61YvI+DtSGQzHEUopvvvkjohLZrx4fYFIrntzz1gthQGml+ezpLqEfR39PLKpGYB/e/cp9PqCvLyrI2ZQBMtScLiP1u/rot8f4uIFVZw1u4KasrwY99BQMESbdygy8C+bqSt5N+7vcqSjOi0Fq4Ctzz9sLQWbknxXxH3kdB05uX7ldBq6Bnltj26LY6ekgrYUOvqG8PoCrN/fxZKakkjQePakQs6cVc7j7+j+oPFrJl+8oAqI1iiMxORiD0/dfgHTy/NHPfZIkY5SeBF4SkTuFJGPishH7NdoJ4pINrrF9uXAQuAGEVnoPEYp9c9KqaVKqaXAj4GH0pDNYDjuaen18Yu/7eGv78Q3I04fpXQ3ztrKfNzZWWMuYGs4PMCM8vzIAjC/enkvMyvyuenMGRErJH5QLMjNiUlJfW57G7k5WZwzR8+gl1SXxASS7UIve+AvK3BTN7mQDfsPR+SODTTbFcdDw9ZSsLEthY5+f0SJxHPZQp3ptKnhMEPBMGFFxFJYNX8SwZDimp+/xpamnmFtQm5YqTOJXNlCbUVB7HUXTeGKJVM4Z24FxyPpKIVz0R1RL0Sv0/wB63VzCueuBHYrpfYqpfzA/cDVIxx/A3BfGrIZDMc9BzujyzCOlwF/iLDS+fDTSj1J3UePvd3M5x7YlHBfMBSm6fAg08vyIk3dOvv9XLygChHhOqvPzzCl4M6O9PBRSvHcjlbOnVtJnpXZs7i6hAOdA5GmdZGB3xFMXl5bzpsHDkdWIXOmaNqDfEeff9haCjal+Xqhna7+ISqT9C/Kc2dTWeimqXswYtnYlsL58ybxfx9ZSUuPj0BIsSKuD9GaxVMoyXMxK851Bjol9mc3LaOm7NiZ/adDOg3xLhrHfarRDfRsGoEzEx0oIjOBWejMpkT7bwVuBZgxY0aiQ7FOLFMAACAASURBVAyG4xI706fdO36lYM/UizwuppXmJQ00r93awuPvHOIzF8+jtjJ2xnuox0cwrJhRnk9lYS5TSzwc6vFxyYLJANx45gy6BwJcWDcp5ryC3BwOWApuT3sfDV2DfPyCOZH9ix1dQ8+ZUxlRWE5rYGVtOX/4+0Ge39FGab4rkhUEUJYfdR/Fr6VgU2JZCqGwSuo+Aq1smrp9ESWW747WFZw7t5KHP3kuj73dzHlWnMDG48rme9csOSpdTDNNOm0uspK9Jlim64EHlVIJm6copX6plFqulFo+adKkRIcYDMclDV0TZynYzfAKPTmWUkhcwGYri0RtH+w+PTMsf/fi6hIK3NmsnKVdKcUeF3dcviBmwAY927aV0os7dYGY7WcHnV0E0RbZtmxTHIHZFdY93jzYzbS4fH93ThYleS66+occaynEylCS58LrCzLgDyV1H4FWRM3dg5FsqcK4Z5kzqZDbL60jNyd72LlrFk+NFNudSKQzoAfRLS0SvUajCXAuH1RjbUvE9RjXkeEkpMGaMbdPiFKwLYUcqkvzaPX6EhaONY2kFCwlZQdB77h8Afd8aPkwd0k8Bbk5kZn3vo5+yvJdce6fXKaVRFcja+4epKooN2bgrS7Ni1gO1QkWmqkocNPR77AU4gLNdgEbQGVB8hqAaaV5NB2Ouo/yc9NqHH1Cko5SmAXMdrzOBR7DcuWMwgZgnojMEhE3euB/NP4gEVmArn9IvMq9wXACY7uPOrzjbxIQUQq5WikoFQ3o2viDYdq8Q7hzsvj7vs6IdeGUJztLIqmVcyYVRoLFI1GYm02/Pxhph52oZcNiq0AtFFZsauhOmH2z3PLjVyc4v6LQTePhQR56sxERhrmInEphNPfRYCBEo6WQC9zDLYKTjZSVglLqQNxrHfAhdMfU0c4NAp8C1gLbgQeUUlut1ttXOQ69HrhfncjLphmOa7Y09Uz4ovQ2tlIYDITS7h0Uj+2+sd1HMLyFdkuPD6XgylOnEQgpXtnVQTis2Li/i0AoTEOXrjLOyU7PQ5xvFW8N+EPDWlTYLLZSXH/9yj52tnr50Dm1w46xM36c6ag2FQW5vN3Qzd/q2/naexYOWwzH7pQKjOo+AtjVqkuu8t3GUhjvJ1AMpOTYV0o9ATwRt+2rcb/fOU55DIaM0dLj48qfvMJ//b/TuGbZxK56N+gP0e4dYnZlAXs7+mn3Dg3z1aeDPesv8rgoyXORJfCfa3dy9weWRbJxbCVx5WlTeWZbC09saeHxzYf46zuHOHduBR1efySekA7OpnhN3YMxq6jZLKkuQSn47lM7OHNWOVeeOnXYMefNrSQnS1gwpXjYvpkV+RS4s/nxjadzsRX4dlLidB+NsHpaRCm0eS3ZjaWQ8rdORO4FnFOkfOACdA8kg+GEp7N/CKV0Y7iJVgqNVlD39Bll7O3op6NvaFg2UDrY7qPC3BxK8lz85MYz+Oc/buK9P32V3330TGorCyJB5pkVBVw4v4rH3m5GBK45o4ZH324iEFKcMTP9JSELrYH1UI+PvqFgUkvB5s6rFiXM4qmtLGDDv10a4wqy+cLq+Xxi1RxK8xNbAaV5qbqPtBWyq81YCjbp2IW7gT2O1zrgRqXUpzMhmMFwrGEHT21Xw0Riu47OmKnbHYw3A8mpFACuWDKVBz5+Nl39fu5+aQ8QtRSmlni4dlkNk4pyufvmZdz1/tP4/cfOYnp5HuckmOWPhj2w2pXZiWIKk4pyObWmhI9fMJtTpg63BGzKCtwJFYYrOyupQgAi+zyurJg003jKC9x4XFmRFNr47KOTkXTqFEw3VMNJje2nn6g2FE7sTJ8zZuiZ+XhrFfR6w9mRhngAp00v5YwZZTFZP5WFuXhc2VxQN4kN/3Zp5NiVs8p5+YsXj+ne9sBqz74TZQ8BPPLJc8d0/VSwU1QT9T1yIiJMK81jb3s/IlqJnOykU6fwIxE5J27bOSLyw4kXy2A49rCDv23eIboHJnYZkYNdg+S7s5lXVUiWQHvf+K7v9QUiHTidLKouZmeLF38wbLWrnvjunPbMPGopJL6HiGSs+CsnO4ui3JwRg8w2tnurwJ1zQhajpUs6avEGYGPctjeAGydOHIPh2GXA0fmzPkUXUjAU5osPvs3rezpHPO5g1wDTy/LJyc6i3GrGNh76hoKR1b2cLKkuIRBS1Ld6h61TMFFELIXWPtzZWSPWCWSSknxXpKPqSNjFcSO5mU4m0lEKKsHx2Wlew2A4bnE2eduZogvp3nUHeGBjI3/d3DzicXY3UtDZMuN1H3l9wcgCLk7sHkabm3p0DUHJxCsFO/uoyWqHfbQWoP/4hXO48cyZox5nK8bxZHudSKQzoL8MfMtua2H9vNPabjCc8ESqXt3Z7IpTCg+/1cjH/i/WkO7oG+L7z9QD0cVqEqGUinQjBR2ETWYpPLKpiSv+++VIDCIZXl8wYdB0Rnk+RZ4cXt7Vji8QzshawAWODJ6judbwB86aybsWDk9XjceW0VgKmnSUwmeBS4FDIrIeaAbeBZjsI8NJQb8/hDs7i/lTioYFm9ft6eLZ7a0xM/z/eGoHg/4Qi6YVjziId/b7GfCHmFGuByenpRAOKzr6hrSCeXonn71/E9sO9XLvugMjyto3FBzW+gG0H3/xtJJIT6KMKAVHrv/RVAqpYsc8Ckw6KpBe9lGjiJyBboM9Hd31dL1SKvFK3AbDCUb/UJCC3GzmTy7i6W2tMfvsNtBbmnu4aH4V+zr6eWBjI7deMJssEX79yj5CYRWTDWSzv6MfgBkVtvtIxxSUUvzbXzZz3/pog+H3L6+hs8/Pn99o5AuXzU/ah8jrCyRNr1xcXczre3WMoyYDMYWc7Cxyc7IYCoYT1igca9RYi/uYwjVNOtlHS4FqpdQ6pdSfrDYX1SJyWubEMxjGhu6DP7HzlX5/kHx3DvMmF9HV749x8USUQqNO93xtTwcAN66cwfTyPPyhMK29iTuVvnlQrwG8pFrXKEwqysUXCNM7GOSv7xzirNnlfPPqRfzyA8v43jWncvPZM+ns9/NMnGJy0udLHGiG2MKxTM3kbf/88aAUJpfkImKa4dmk4z76HRBvj7qBeydOHINh/PQNBbn4rhf5w98PTuh1+4e0n95e4rK+JepCcloKABv2dVFZmMvMivxIrCCZC2nD/sPMqixgUpHO0rHbMjy19RC9viAfOruWD5xdy2WLpiAiXDBvEtWledy/IfHzhcKKfn8oYaAZosFmjyuLsgTVwhOBPes+HtxHuTnZ1FYUMLlo4tNzj0fSUQozlFJ7nRuUUnuA2gmVyGAYJ9uaexnwh9hnuWXGSs9AgLesWTxAv7Wwu70msTOuEFEK1hoBG/YfZuWsMkQkohQOJlAKdgO65Y52ErZSeGBjI65sGbbAS3aWcO3yGl7e1ZFQ0USa4SWZ+dZWFFBodU/NVF6+7Z/PRMprJvjjrWfxucvGvAT9CUU6SsGOKUSwfh85185gOMLY6/+Od12Cn724m+t+uS7SFbXfry2FSUW5FOXmxCidXl8AV7bQ1D3IlqYemroHHV0+88iSxJbCnvY+Dg8EIovKABGL4Y0Dh1k5qzxhEdr7l08nS+CPGxqG7fP6Eq8xYJOVJZwzpyJiMWQC2300teT4mH1XFXtMiwuLdD6FHwCPiMh/oHsfzQG+AHw7E4IZDGPFVgod48z139TQjT8YpncwQFmBm/6hIJOLPIgIlUW5dA3owTcUVnh9QVbOKmf9vi5+89p+INr62ZWdxdSSvISWwvr9XYBeftLG2dUzUQdQ0Ipm1fwqHtjYwO2XziMnO4vX93TiD4WZXKzPTxZTAPjZTWeQlcHq3YLcHCoL3XhcJnh7vJFO9tE9ItINfJRo9tHnlVIPZko4g2Es2L19xlMVHA4rtjVrV1B3RClo9xFAWb6Lw/26FYU9Mz9nTgXr93Xx6KZmCnNzYhq9zSjPj6ys5mTj/sOR2INNeYGbLIGwgkscy1jGc/2K6dy6o43nd7SxbGYZH793I1lZwk9u0AZ9spgCkPYaCely5qzyjLTQMGSetOwlpdSfgD9lSBaDYdwM+IPsadctKMZTFXygawCv5ZvXfY4KIu4j0AO3vbawHU+oKdNB5YNdA5w1pyIm/XRGeT7P7xy+5OX6fV2R2INNdpZQXpBLcV7OiO2zL15QRVVRLvdvaOD5HW2R9YoffEO7lI6mO+STF809avc2jI+0vjUiMhldp1AJRL7FSqlfT7BcBsOY2H6ol7CC02pKeLuxh6FgKOGi66NhWxsQHfR1nYL+lynLd0eCyvb+kjwXS6pLONg1wMra2HUIppfn0e4dYtAfIs+qnG3uHqSpe5CPnT9r2P1vPHMGM0dZ4CYnO4trl9fw8xf3oICPnTeLtdtaePydQwAJYxEGw2ikU6fwXnQs4RvA3ehK5ruBD2RGNIMhfeyBetV87XbpHGO30a1xSsEfDBMIqcgavuUFbroG/CilYpSCXQOw3BEjACJ9jRoOR+MKD7/VBERjD04+9666lBbyuW75DMJKxyE+e+k8rl8xg6AVGB/JfWQwJCMdx+K3gA8rpU4H+q2ft6I7pRoMxwSbm3qoLHRHBuexupA2N/VECq+6BwKRvkcFDveRPxhmwB+id1DvK8lz8Q9nVPPJi+awLG7FMmetQiis+P+e2M5/rt3JqvmTWDjCIjOjMaMin6++ZyH/fd1Sijwurl1WE3FbGaVgGAvp1inExxP+D/jgBMpjMIyLLU09LK4uodLqoz+WYLNSii1NPZw7V6861j0QiOT+R9xHVkvmrn5/jKUwudjDv6xegCsukGtbCjtavNz2uze4+6W9fOCsmfzqg8vH3UX0I+fN4py5upahqtjDJQuqcGULeSbzxzAG0lEKbVZMAWC/iJyNTktN6ZsnImtEZKeI7BaRO5Ic834R2SYiW0XkD2nIZjDgC4TY1dbH4mklkVz/eKUQDit6rWyhZDR0DdLrC7J0ehmFuTl0D/ojS3HaRVnl+YmVQjIqCtzku7O56+mdPLe9lTuvXMg337s4I1lAX7tqET+58QyzYIxhTKTzjbwHOM96/wPgBeBt4GejnSgi2cBPgcuBhcANIrIw7ph5wJeAc5VSi4Db05DNYGBXax+hsGLRtOJIrn+8++i+DQc56zvPRZrQJcIOMi+uLqYkz0VPjKVgpaTalsKAVgqubBlxKUcRYW5VIfnuHP7nlhXccu7w4PJEUV2ax+pFUzJ2fcOJTTp1Ct9zvP+tiLwIFCilttvbRaRGKdWY4PSVwG67TYaI3A9cDWxzHPOPwE+VUoetewzP3zOc1Oxt72NysSfpYijNPboOoKYsH48rm6LcHDriAs3r9nYx4A/xzce38T+3rAC0y2luVWGk0GpLcw85WcL8KUWU5rvoGYzGFOw0T3tFr8OWpVCS5xp1Zv7TG88gJ1uYmoGFbQyGiWLMtqtS6qBTIVhsS3gwVKOL3WwarW1O6oA6EXlVRNaJyJpEFxKRW0Vko4hsbG9vH5PshuOPvqEg7/7RK9zz8t6kx7RZVkGVVdE7qSh3WKuLrU095LmyeW5HG89ua+Vbj2/jPT9+hT+/GZ3L7GzxMreqkNycbErzXXQPBhjw2wvsDI8p9A4GKB7BdWQzvTzfKATDMc9EpyeMx4mZA8wDVgE1wEsiskQp1e08SCn1S+CXAMuXL1fjuJ/hOOKVXe0MBkIjrmDW3usjS6Kz+PhlLb2+AHs7+vnMJfP46zvN3Pa7NyLpm42OauOWHl+ku2dpnpsdPb30Wesz25ZCsSeH7CzRSsEXGDGeYDAcT0x0lCvZIN2Ebo1hU2Ntc9IIPKqUCiil9gH1aCVhMPDcdu1NHCmbqM07REVhbiR4G7+s5VarbcXpM0r55nsXU5CbwzeuXsS0Ek/MWgdtXh9VVqC6xHIf2ZaCHVMQEcry3RweiLqPDIYTgcw2QImyAZgnIrNExA1cDzwad8xf0FYCIlKJdicl9xUYThrCYcULVouIkeoOWnujgznoFcycx9uN8hZPK+GcOZVs+uq7+ODZtVQVeyLHBUNhOvv9VBXrvj0lea6EKamgLZKufqMUDCcWR0QpKKWCwKeAtcB24AGl1FYR+YaIXGUdthboFJFt6Mymf1FKdR4J+QzHNu809dDR56fYkzOqpRCrFHLx+oL4Atr1s6WphynFnki6qh0YrirKpa1XX7ejz49SRK5TmuciGFa09Q6RnSXkOpa/LCtwcbg/QM9gIGmbaoPheGOilULSmIJS6gmlVJ1Sao5S6tvWtq8qpR613iul1OeUUguVUkuUUvdPsGyG45Tnt7eSJXDladPo7PcTDif2UrZ5h5hcHO3MaQ/+nVY3081NPSyuHl49XFWcS6vXZ11D/4woBWtlsubuQQrc2TEZRuUFbjr6h+g1loLhBGKilcLC0Q8xGNLjOas19NyqQkJhxeGB4f2MgqEwHX3DLQXQLqf+oSB7O/pj1ie2mVzkoXsgwFAwRKtlMUyOuI900Lqpe3BYKmxZvpvGw4OE1ciFawbD8cSI2Uci0kDy4HEEpdQM6+fwZaAMhnHw6u4Otjb38q9rFkQG+Y4+PxWOhWhAWwNKwSSHpVBpVzV7hwiEwihFwtXG7BTWdu9Q1FIojrUUmroHYxa/gWj/IzBKwXDiMFpK6s1HRAqDIQH3rz/IV/6yhXlVhVy7vIbdbXqdhI6+IeZTFHOsHRNwWgrOVhd2d9JElkKVtWB7a+8Qbb1DiEStDFspdA8EhrWyLrdSX4GU6hQMhuOBEZWCUupvR0oQg8HJa7s7uOOhzVxQN4mf3Hg6xR6dBQSJM5DsGb4zpmDXK+xo8bJhfxdVRbkx+21s5dHu9dHmHaI83x1paOe0AOLdR06lYCwFw4lCuovsLAXOZ/giO1+dYLkMJznbDumagh9ff3oks2dSYeImd0AkFuC0FDyubIo9Ofzmtf3k5mTxoxtOT3gvW1G0eYdo6/VF0lFBF6/ZJIop2BilYDhRSFkpiMit6EZ4T6Mb2z0JXAY8khnRDCczh3p85LuzKc6LfkWL83JwZ2cNa10BUUsh3u9fXZZPbt8Qv/rgck6bXprwXhUFbrKzhNZe37C0Vo8rC3dOFv5gOLLAjk2s+8isXWA4MUjnm/xFYI1S6mUROayUep+IXI4uRDMYJpSWHh9Tij0xKaAiMqwgzabNO0R5gRt3TmxC3T0fXEa+OydmAI8nK0tft61XB5oXTInGK0SE0jwXbd4h4z4ynBSkk5JapZR62XofFpEspdSTwJUZkMtwktPS62NKSWL/f3znU0C7fYpyh22vKcsfUSHYTC720NLro6PPPyzuYAebC5O4j7KzZNg+g+F4JR2l0Cgitdb7euBqETkfGNsiuAbDCLT0JFYKlYW5dCSxFKoSBJFTpaool+2HvITCKpKOamPHFewOqTZ57mzyrLjFcb+gzeBhePNeUGPsMbnhV/Dsnfp16O3UztnxV+jYNbb7nYwEBmH9PRAKZvQ26Uxv/gM4BdgPfAN4EHADn5l4sQwnM+GworVXu4/iqSzM5R2rh5GTtt4h6iYXDdueKpOKPHT06f5K8RZHiWUp2M3wnJQXuHFlH+cKAeDt++GpO2D6Spg0P71ze5rgr58HyQYVhsaNcMvjI58TDsODH4HZF8GNpnlBSrx9PzzxBaiYC3MuythtUrYUlFK/sdxFWD/LgDKl1M8zJZzh5KSjf4hgWDE1ifuoK67VRTisaO8bYnLxcPdRqjjPjbc47HhBIhdReYH7xIgn2DP2zt3pn2uf84GH4bzb4eDr4BuuuGPobYSgD/b9DQK+kY81aOrX6p9j+RulQcpKQUQuE5E6+3ellB+YJiLvyohkhpOWlp7hNQc2lYXuYa0uOvv92u1TNB73kcfxPt59pAf9/ARK4X2nV/Pe0+PXizoOsQea8SiFijlQtwbCQdjzfGrnBAZg/yvp3/NkIzCoFShA556M3iqdmMJPAW/ctj5ru8EwYdhKIdEqZXbrCmdaanwTu7GQqBLaJhpoHu4++sh5s/hwBtdbPmLYA82YlMIeyMmDomlQswLyyqKz2tHul5UD9U+lf8+Tjf2vaAWalXPsWAro7KNDcdsOAWaFcMOE0mIteDO5ZPggHylg80YthfhlOMeCbZWU5bvIzYkd/EusLKMC9wmaYeQf0O4cGNsstHO3thKysiArG+ZdBruehnBo5HNcBfrY+rVjD3CfLNQ/Ff28jiGlsFdELo7btgrYN3HiGAzaUsjJEioLhg/ylUWxVc1KKZ7fbgeIx+E+shRKomuUW0qh6ERdM6HLWssqt2Ts7qOKOdHf61bDQCc0vTH6OXVroOcgtMUv926IoJRWnHMugsmLoPsABDOX9JmOUrgTeEhE7hKRfxKRu4A/A6bFhSFl7GUtR6Klx8fkYg9ZWcOzepztsH2BEJ++7y3uXXeAG1ZOp6bM4W7yDySefSoFQ33DNlcUuBFJbG1cckoV37tmCadMHWN2k79fZ9uMB6X0M6XLULzHNwG2Iph7MfS1gq839euHAnB4v86IsZlzic5E2vygVjj2y8ruityzYq6e+ULqLqSgP/mA6O9PXW6bga6ofMlSPUe7bjgEXfv0Nfo7Eh8zktzJCAX0Nfc8Dz0NWtlWzNUZXt0H0rtWGqSTffQIuq1FAfBu6+dqa7vBMCrr9nZy6p1Ps69j5H+yQ0lqFACKPTm4c7LYfqiX6365jr9uPsSXLl/Ad963JForEPTDDxbB+l8Ov8DG/4HvL4TB7pjNOdlZTCvJi1UsFh5XNtetmDG2WoTAIPzwVHjtv9M/18n6X8IPFqaXqVO/Fv5j9uguIVspzFutf3alsQru4QOgQrFKIa8UZp4D6++GH50eff1XHbRu1X+f7oP6nOKpMOXU0QPTNn+8CR762PDt7fXw3Rmw/9XUZe9r198FW76n/nX4Mftfhe/O1IovGc9/E360VF/jrvn62eL5w/vhL59IXTaARz6lr/m7fwBEK1D7c86gCymtRXaUUuuVUrcppd5t/dyQKcEMR55gKBxpT50JXtjZRjCs2NRweMTjWpNUM4NuOzGpMJeH3mqivsXLL25exscvnBM7YPe1wGAXbPnz8AtseQiGehIOQr/58Ao+f1maOfqjse9lGOjQ9x0PW/6sC8xGGpyGnfMQhPywY5Sagc49UDQVpp5m/Z7GgNNlKRynUgC4+qfwvrujr6t+rLdvf1w/gwpHz5l6GrTvTO1+jRth55PDrb1Dm3TW09aHU5d919MQHIR3fRNmngfbHxtu0TVthHAADr2T+BpKwda/QPVyuPw/tQw7nxx+TNMbulgvMJiabEE/7HxCW13vuxs+9BgUTYHy2Xr/0VIKIvJvjvffSPbKmHSGI8oTW1pY/cOXItk8E82GfV0A1LcmVzxKKW0pjFCdPKM8nynFHv5029msXpQgz8Hbqn82rId+xzLfA11wcJ1+nyA7Zt7komEN9caN7RZpeQd6m8d2jf5O/SyQ+mAQDulBD1LIBLJcOeWzAEkv2BxJR41TCmUz4bTro68zPqgzk+qfGn5OxVzobxu9tmGgSyv7kD+anhkvRzpB6/qntDI859Navr5WrVwSXTfZ5965Gw7vg6U3wJm3QsW84a6w/nYY6tUKaN/Lia8Tz8HX9TkrPqo/v1nn6+355ZBfcVQthRrH++lJXjUJzjMch7T1+giFVSQldCLxBUJstiqRd7Um93P3+oIMBkIJC9dsfnHzMp753AUJF8wBwGsnySnY/Wx0+57ntaujcv7o2TETgVL6PpWW9WEP0umy+xkiCyCmOhg0btQDaOV8rQgHupIfawd9XXlQMj29Aadzt05BzS8f/di61dD8JhywXDwV1qw34hIZzc3l2B8/8Noypxq0DvphzwtaJhGYeykgwxVoJFU3iWy2HLbrrW61Th91WjLOzzPV2En9WsjOhVkXDt9XPiejtQojKgWl1CcARCQLuBe4TSn14bjXRzImneGI0j+kB0l7ofuJZFNDN4GQojTfxc4RlMJIhWs2JfmukTOB+ixLwVUQ+09Y/xTkV8IF/6IHzMaNaT1D2rRt0wHCsz8JJTNGn7Eno34tFE7Wsqc6YO9aq4O9q7+jFWEyn709+47M2uekrxTirYRk1K3RP9+8V89288qi94TUYx+TF0P907EWQeduqFqk36cy8B58DfzeqEwFFbrFRzJlk+wzqV+r71s6Xf9et0ZbMntfTCJ3ipbMrrXaOsgtHL6vYu7RjykopcLAI0qp4Z3IUkRE1ojIThHZLSJ3JNh/i4i0i8gm65UgmmTIJP1WZlBngi6k48V2HV1zRg0NXYNJs5AO9Wif60iWwqh4W0CyYOHVsPs5ncURCmqrYd5lMO9desDMdNGUff261fq198XUfco2oYB+hnmXQeW81GeI9Wt1sHfORVqZJFNInXExgYq5eluqLpjOPakrhcmLoLhax3Sc55TZbqtRBrrO3frvtvJWHTeyG+8ppeWoPU/HJ1KxyCIz8Qui2+pWa/dRr2Vp+nqtCUYS2Qa74cBr+jybGWfp1F7nd6tzN2S5YMXHdD1I27aRZevYrc+Ztzrx/oo52hpOkEU3EaQTaH5JRM4ay01EJBtd+Xw5sBC4QUQWJjj0j0qppdbrV2O5l2Hs9A/ZSmHMuj8p6/d3MX9yEStqtZthV5K4QqtVuJYs0JwSfS16Zr3gCj0AHVwHjRt0oLbusmh2zFhn7qlSvxamna4DhHVrxtbS4eA6/Qx1a1KfxXc3QOsWPVjZxWS7n0mccpnIvz/Ukzy10om/H3qbYmsURkIkOoA6lYLLo2faqSiFslqYfwUxrp6+VvD36WvWrYGGv4/sLgM9aM+6ANwF0W221WArFTuIPn2lThYYjEuQ2POctsLs8wCyXTq1d9fT0aB15x4dIJ5/efTeI7HLeq66yxLvtz+7rsy4kNIp0TwAPCkijwANRJycKS3HuRLYrZTaCyAi3a3HtwAAIABJREFU9wNXA6OoTMORxFYKXRPsPgoeWMdlB3/IzqVfpm6yNofrW72xK6G98RvY/CDnHB7gzpwKqoqsf6AhLzx8mw5CisD5n4fZq0a+oddSCrNXQbYbHv20PjcrB+ZY9Zd1q+Hpr+gB1Db9JxI7OLzKMoprzwNXvu4mWjpDzygv/sro16l/Sj/D7FXQuQv6f6c/C0+SeApEBxWnn/vtP2jFOPPs2GM7d+nZd+lM/XvEv78LCiclvn7zJnj2a9GZaqqWAugBdOOvhyuSVFwitlVSOAlqluvPZtW/xvZeqlkGf/se/PYq8CReaU/XFeyFs/4pdnvVQh1T2fU0LPtQ1Iqad5lWNJ179fVt6p+GvHItS/wzbn1YWx3VZ0RdbEVT9CTh9Z/peIZNjgeu/oneD/q5Jp2iFWAinGmpdsbYBJKOpZAH/AWtDGpIL9BcjVYkNo3WtniuEZF3RORBEUn4nyoit4rIRhHZ2N7enob4htHos2IKiRaxGQ/9L/6QD8iTnDdVMbOiAHdOFrviU1/X3wNt25H+Dm7JeRp37369vX6tTqkMDOjB6PUUWm15W/U/WG6Rjh8UT9NZJud/PjqYzjxH/0y193+62MFhuzjL5YELvwglNTq3/7Ufp1bQVr8Wai3fcqoB2fq12iVTOU//Puei5D2GDrwGkxdCjrUQ0dRTre0j5PtvfxT2vQQ5uTD3XVq+VJm9Ck6/GU65Knb7aG6rcFjPjO3PwA5ae1tjrZ2pp8NpN0JusU57TfQS0XIvel/sPWxLZs8Luh6kcze6PsDq+RmvtA5tghlna2vMydx3EbFkbAVkK8HzPqdbk9uyhEP6u7L5Qb3f1zPcJRVP+WyoXqbdXxkgZUtBKfXhjEgQ5THgPqXUkIh8HPg/IL6tBkqpXwK/BFi+fLlpmDKB2H7+zv7U3UeHega57d43+O/rT6e2smD4AUE/eQd1+uDyosNkZwlzJxWys8URbA6HoWsv/tNv4UOv1vGc63Y9CzvrNv2PlV8BH30G1n5ZWxT+AXDnJxeqryU6o7vwi/oVT6aLgOzg8NSl0W3n/bN+bfxfePx28DZrJZGMzj16xr7yH+Nk3qNnoInwD+gBe9mH9SAHWhHa7rJ3fT167ECXngGf//notsIqmHaGPvaCf0ki126dAfPhJ0b+DBKRk6trGOKpmKsDv/3tWoZ4vIf0xMAeXOvWwPPf0rP6zt16gCyp0f2X3jeObv7zVusFgw68oq9bOh0mLdAxKqe7xh7sEw3ezqD10ht04Nn+2y28Sr+c/Oxsfew5n9IJAeFgrEsqHnc+/GOKxX5jIK3iNRGZJyJfFZG7rZ/zUjy1CW1V2NRY2yIopTodgexfAcswHFHG4j56u6GHtxt7+M1r+xPu9+78G+6Qbs9QOaSNxbrJhbFpqdY//K7gZPaEqhgomav/SUJBPYuad5mejdWttnrwv5RcoFDAGlhG6dPoKYGCqswoBWdwOCvBv1iqCsn2mdvWRioB2X0v6c8ofrCqWwPt22OL33Y/p2er8QNQ3RqdmZUsrpBOcDlVIhlII9QDQPS+kxfroPWutdqtUz57+Ix9LMw6X3d8rV8bfc6cXO3yc8rW0xA72MdjB60PvBYrd7JjD76uA9f1a3VWVs2K8T/LGElnPYUrgTeABUAXMB/YKCJXjXiiZgMwT0RmiYgbuB54NO76Ux2/XgWYDllHmH6/lZKahvvIbkz38FtN+ALD8/7feeGPDCkX4Sx35J9q3uQimnt8eH0BfZC1/ZWuEoo9OeQuvFwHZPe+YAWHrQFu5rngLhw5UGf31ymaPLrwtstionEGh5PdF0ZXCrvW6llqudWaO5WAbP1T+jOaeW7sdluW+qdjj82v1JZBzLGrAQW7nhl+/XDYGixTDC6nymifSbxScLp62rZOnDyuPO3i2vmUFSCeE72vU7ZkRXs29ue97mcjH2cfG7ay43Y9o91P2UevI286lsJ3gKuVUjcqpb6klLoJHSz+zmgnKqWCwKeAtejB/gGl1FarItpWKp8Rka0i8jZ6ic9b0nkQw/ixLYWOviFUiimJtlLoGQzw1JaWmH1bGrupaf8bB0tWkFUxO/KPZC+bGalstrY/0pDPBXWTyJ5/uW4t8PRXYoPDObnaPz5SrnefJcNolgKkn5OfKs7gcCKKpugaipEUkq9X992Jn/GPFJCNdNO8OBojiJw3R59rK1Q7Rbdu9XBrZuppOgaTSPl6m3Vl7kQrhZLp+jNLqhT26EB9kWPuWLdGZx3FN+QbL3WrdRGcM3U2PuYRn8objx20btkM7qLELjEbew2Kl/5TZzmNFE84AqSjFGqA+BrtV0ixolkp9YRSqk4pNUcp9W1r21eVUo9a77+klFqklDpNKXWRUmpHGrIZJoA+SykMBcMM+FOr9m33DlGa72JGeT73rY9tBPbg0y8wU9qoOeu9MVWYC6ZopbC12Wpr0LmHUE4e2/vzueSUKph+pnbvtO/QvnBnpk3dGj0wtWxOLJDd4qIoFaWQYnuFdHEGhxMhoqt5R1JIe1/QijHe2hgpINuyWX82ySyUujWw/2WdNdS4HnzdiQcgsZqv7Xl+eGfP0WbIYyUrW7uAkilKO47hVGCzLtCunomWx/mZOJWCvy9aGNm5WwezC5JkaMWk386JxncSYacNt+/QmWBzLxn/M4yDdJTCJuDzcds+Z203HOcopQj5B7mp4A2uznqFgU0PJW8l7KCjb4iqolyuWzGdv+/rYm97NKuookkHw/IWXqH/Mbr2QjhETVkeM8rzeXGnlT3WuZvO3BpEsriwrkqbznOtjI/4Ac72r7/+E3jnAWh+K3a/3eIiJaWQpJL28AF9bedr51MjF3T1d8A7f9JZVJ27Rg4UwugpmPVrdUplzcrh59kB2UTnQDRbJp661doP/vJd8Pdf6IKq2UkWgK9bo3vvHHw9dnumlAJYEwfHZ6KUdne984Cuu7DbYti48mC21QZiIi2X4mm6c6vzuvGN6Dp3620jDfb2dyAV2WwFMuPsaKX3USIdx9UngMdE5LPo9NLpwABwZSYEMxxZhoJhbpCn+ffQ78ENPAl4FJx23YjndfT5qSzM5dplNfzX0zt5/J1DfOaSeXT0DbHcv5HO4nlUlE7Xg0hoCHoakbKZXLygivvWH2TQH8LTuZvtQ1NYNrOM8gLL7bH4H3Tq4/wrYm9YWAUzzoF3/qhfucXwL3ui7hK7ArVgBHPdJlk2z8O36TYI8dzyBNSeO3w7wDNfg02/0+////bOPEyuusr7n1PdXb3vS9bOniYJCbIkYVMImwmKgKMojo6Mog6Ogo4zjiKvjqMz74z76IiK4gKvKLIooAJB2RGBhD1rp7MnJOklve/ddd4/fvdWV1VXdXcl1WvO53nq6apb9946fZ/uOvd3lu8JpMNJI3AKWx5wd+KxoR5wwmkL1gyOLUcmZGNDEtUPu1LFRKGKOWe7O9tnvu1eL14LWQXx911wvqvoqV4/8MUL8cM4qaL8JJdH6W515cQHNsCvrhp4f0YckYPl73LJ9fIlqbVl+bvcDUbRHM827/yHXnU9Jw01gx12LPPe4q73rJVD7wdODTWzEE6+8vjsTgHJzFPYBiwF3gt8C3gPsFRVLSE8BWjr7uOStJc4nDmfC7q/RXdWOVQ/NOxxda3dlOdnUlGQxUnT8tmwx3WSbtu9n1WBbXTOv9jtGJNIvGhpBd19If664xA07uG1rnLefUZEJHLJ292XvZ9kjeQD98L1L8Hl33d3s5E19a2HIbdsZIm6eNU8HUdh/3Nw5sfdZ1z/Enz8WXdXneh6hPrdF/KSy9z+n9k68GWSiNJFrhs23rCU3k4X066I0/SfKCHbVufkmYdaoaRlwCc3Dvxe77k98b7BXFeJE08LaLhwyLGy8EKXcPV1g7Y/6MIp1z0DN7wM53568DErroJ/qR6ZIF8ynHMDfOrVgYqmwlkDQoq9Xa7pcbjVUkaWO8eZ1w3/edlF8JnNTgpjnEl2nkKfqj6tqnep6jOq2jtahhljS2dzAytlO/sr1rBbZ3Cw/C0DukFDUN/WHZabXjmvmJf2NtLXH6Jt83rSJUTxqd5CMqbxavX8EnKDabzy+quI9vNGYCaXnTIz+uSJ7mKDOe6Lafm7XDdopFxF25GRhY4gfjVPzZ9dmeaKq7zk7EKn2TPv3MSyGAdfcgnCk9/p9h8qqegzVLWNP+QmXtghUULWb5YbLkmZXTTwe2UMIyVStc7V5tfHVN2MRugIBusGVT/ickrTV3glp3G+rkTcqiLVBALREhjgKaD+xcmgoyO7DsHc+HbHIzN/dJxtkiRTkrpfRPbFeewQkcdF5HoRmaKTzac+svNR0iVExzwXj95WcE78mHIE7d19dPT0h53CqnkltPf0s+1wK0UHHqOZfHIXeHJZeRWuCsP7MstMT+PNi8vYv8MljCsXn0JuZpJ/PsEcl2ysjoj3tx4aWeWRT2xsv/pht+SfeVr0flXroL46/lQyX5HUr5IaCUMNSxmqsiVRQtafDeDHwlNB7KjMvh6Xbxktp5CW4ZKs1Y+4iqLazeNeiRNF1TqX/H/hJ+51qiuwJgjJrBS+BzQC/w58BPgK0AD8HPgNrox02PJUY2KSvefPNGg+gdlnkBtM49WM09wd6RCicX45anm+cwqr57sl/IZddSxte45t+WcNLL9FBpWAXrRkGiVdrmLp/LNjNHlGStVaN+TEP2/rkZH1KPhEVvP093pKqnHKNP0vp8g6f5/qh91dbjIhjKGGpURq+cQjNiHb1wM1jw3MBkgVxXNdCMvXUmqKM3oz1VStcxVhT3594PVEwa+K2+xN0TOnwN8Dl6rqT1X1EU/F9DLg/ar6I+/5+0bBRuMYeGZHPTf9LkHZZiyhfgoOPMEToVPJycqkJC/Ika40lygbgVMoy3OJ0hmF2cwqymb3K09QSBstc2JK62LuytcsKWeBHKZZCli2cG5yv6CPL/pW/bCL7bfXJpcEjazm2f+8K0+Nd3dasgDKqgbH2JsPulLQY7mjTdQ817DTrXYShUUiKrmAwbMBUknVWteV29U8fG1+Klh0sZOUeOUOd81H87OSxa+KC/W5QoahRAknMck4hRlArN5xO+AHgquBBLKExljz0KZD3PH8vrhdxoM4sIGMniYe7T+NvMx0SnMz3aCdqnWuvDJB7Xhdq6thjxxhuXp+CdOOPEmvppF/cpzGq6Z90OecSUV+FmvKmpGymBnLyVBU6YacVK93ZaEacppDIyWymqd6vUsoL0xUpulP1YqQ6AjLHB/DF3KistTh4vali1xpabOnMRlvNkCq8Lttdz42YGvJgqGPOR5ySweqeqrWTYgYexThMtMJ5KxSTDJO4ffA/SJysYgsEZGLgXu97QBnA3tSbN/Y0NsJP3oL7Hpy+H0nCbWt7ou3fiSzEXY8QkjSeTp0CrmZaZTlBZ1Sqn/3e/Nq+GrFwOOX7wKgrs3/ch9wCivnFXNB4FU2hk5iybyYvsbSRYDCf80On2tW00YKZi49vl+2aq1ryvqON3kr2ZUCwG3vcMql885NfIfux5QjZY+r1zvZ6bKq5O32h6XENs/5FT7D2RyeSxxnNkCqmL3KyUPfcy386Ysu5JXqSp9Y/L87P6cxkVh0kVvJTNHQESTXp/APwJeBW3CrgzeAu3G5BYBdwNtTadyYUbfdVRQceiW6JnsSM+AUephdPISiKMCRLTTnzqO1M4fcYDoluUE3T7l4Lrzju3B0d8SJt7iyvKb91Ld2I8JAbwGwek4Bc+UAdwUv5+ycmPr7k9bBmhujp4+JwClXH98ve+Z1LnfR3+tq6BPd6cejaC5c+nVoecO9Xv6uxPv6MeXq9U7psqfDlU+efs2x3dFWekn4XU8OKGd2NrpKpuFWCuBWcEXz4s8GSBWBNHjnjwaE3WJnB4wGq651jjnefOLxJqcErvrFwOjPKUgy0tldwOe9R7z3D8fbPinw77hGabzdeFDrTTCrax3BSqGhhqNZTsQ2NzOd0rxMGtp6UFXkjL+P3rd+h3MKO9ZT33YmxTlB0tMGFpyLgo2IJEhGZuYPDJ1JJfnTRjawJh4icOY/jGzftAwX896x3gnD7Xk6viLpSIl1MuAUP2FopxBZyeWXDI9mlY4/TnSsyCockAufiCy7YrwtGFWSlc6+RER+KiK/916vFJEk6vAmKH7MvGdqOIVQSMPOYNjwUX8fNO6mNlhJMC1AMD1AaW6QvpDS0hlH5qJ0kWv6ql7vGtci8gkA4mnOv21NEoNXJhNV61xS+tDL7ss8I9d1uB4LfuLSdzIwMhmJyEqu6oe9wfHDNMsZxghJpk/heuCHwA7Az2h1Av8xCnaNLf4/4hRxCo0dPfSFXN1+/XArhaa9EOrjcPpscjJd+WipV00Ud9iOiPti3PUkra3NlOXHhIi8a1lSGW8E9xTAr47Z/rCnSHqBU289VqrWOifjazg11LjzJxrF6FO6yFU97fvrxKrlNyY9yawUPg1crKr/DfhzBLfh5ipMbqZY+Kg2whEMu1LwmrH2B2aSG3TRxNJc9yXXkGjYTtVa6O9mbvPGqMojd1CN60rNLTs24yc6OSWuOmbjT6HlwPGXgfpOxi91bahxeY54ekiRlC5yziTUZ07BSCnJOIV8BuYs+3KRGUBqB/qONapTLnx0xMsnwECFUEI8h7iPmeR6KwU/cdyQ6Fhv2M1pXc8PCh+FB7BMtFLCVFK1Fjoa3PPjrZDJKXG5hUinMJJyR3+fcZ7SZUw9knEKTzE4yXwD8HicfScP7fVumAZAT/v42pIi/JXCrKJs6r1eAkIhePb7buRfJA01kFXIkb7csMyEHz462p5A9yg9SN/8NVwiz3Ploe/AI18cWGWNxqjGiYa/Oph5WnLd0wnPt9ZVv/3hn5yUxoicglcS6Y8qNYwUkYxTuB54p4jsAfJFZDtOKfUzo2HYmOGHjtIyo5uSJjF+knnpjPyB8FHtFnjkJnj97uidvTvT9p5+8jynUOyVkjZ2JF4EHl38HvpJY3Htenj2e7Dlfk/dcwTqkZOdiqWuk3rltak538nvhMI5sPk+JwU+Eg2l8iVOkvn0D6bGBsPwSKYk9ZCIrAJWAXNxoaQXVDU09JETHK9ahmknp34C1zhR29JFQVY6s4tzeH6Xk7Km1asYjhB0u2vDfi47tJ2cxefRvrc/rGGUlZFGTjCNo4lyCsC+srfw7u4fctvfruL8P5zvwh8zT8OpR07dxh7Ahcbef1fqzlc8D/5phJIkPsEc+OijqbPBMDySqT66Xx0vqOrdqvqcqoZE5LejaeCo01DjhqJULJtCOYVuKgqyKM/PpLW7z0ld+BPJImQVfvbEFnI6D0HJQtq6+6JUSktygzQO4RTCukf5md4A9cfcagSmvlMwjClMMuGjRG2ia1Jgx/jRUOPq7rOLplD1URcV+Zlhobr6tu6BgfaeU+jtDxFocp3KoZKFdPT0hcNH4JxCwuojBkJU5XmZAwPUX/KGtpSYUzCMycqw4SMR8WUsghHPfRYAcUZHxT3POuC7QBpwq1faGm+/dwH3AKtUdeNIzn1c+InRYB70truE7EiHYkxQalu7WTWvJBwOqmvtZrY/0L5xL/T1cKCplznqVg8NWZW0dx8lJzjw51CcExwyp7C/sZNgesCVpM4/zw272f2kE6NLNBzHMIwJz0i+/Sq9RyDieSUwG5dXuCrxoQ4RSQNuBi4FlgHvE5FB3U0ikg98Cnh+hPYfH6HQQAmlLybWO7krkFSV2tZub6XgnEJ9W89A+MgbAbm7vo0F4rZt6ymnpz9EXuZAFUtJbnDInMKuunbml+YSCIg37MYfoD7Fk8yGMcUZdqWgqh8CEJFnVfUnx/g5q4EaVd3lnetO4ApgS8x+XwW+Bnz2GD8nOVoOuGHyvnonuBDSaIz36zjqKktGMju4vcHVn/srlp6OwRLLwdy4sfvm5iYy+topj3IK3W5MZWaBm6bWUMOuupOYL4c4okW8VudqBZLJKeyub2NxRcR1qlrr5Bosn2AYk5oRx0l8hyAi+SIyX0QW+I8RHD6LgcY3gAPetjAicjpQqap/HKlNx42v/lmywAmMwej0KvS0w/dOhWe+PbJ9v3sKvHDLwLb7PwG3vCX68b+nu0HtMaT/7qP8Ivg1Kgqywv0Gda3dbiLZHG+6WcNOdte3szT9IHuYyaaDruoqNxjtFNp7+uPOY+jrD7HvaAfzyyOkmqvWupGUU1g90jBOBJKpPloqIi8DzUCN99jhPY4LEQkA3wb+eQT7fkxENorIxrq6uuP74M5G9zOndCB81DMKvQq7nnTlrlvuH37fhhqXtN18n3vd1+00dk56O7z3Dve46jZXMbX1D9HHdrWQs/8JVgWqmZ3WRGZ6GoXZGdS3drlEc8USp43fUEPDkQMsYxfbsk9n0xueU8iMzinAQK/CvoaOsPLqwaZOevuV+WURTqFwNlz3DMSqqhqGMalIJqP6Q1z3cgnQAhTjZitcM4JjD+LyED6zvW0++cBy4AmvOe4s4AERGSTerqo/VtWVqrqyvLw8CfPj0N3ifmYVQGaeez4aKwVfwuDIJmjaP/S+fpjowAsujLTnGZfnOOMaWHqZe5x8pbvrjx2VuetxAiHXhVzZ8AzgRmV2ttS5SV1508PTvmbVP0MA5WDFeew/6uYb5ETlFDIAwnmFf/jli3zu3tfcx9S7a7SgLGaoy7RlkJE18utiGMaEIxmn8Cbgc6raBIiqNuNi/18dwbEbgMVe2CkIXA084L+pqs2qWqaq81R1HvAccPmoVx/5zWpZhQMrhVSXpaq6+QPTVrjXO9YPvb+vw6QhN0R+xyOusmdejBR11Vqo3QxN+1BVHnz9EE2v/J7u9HwOainFBx4DoDw/k1Czqzx6tjad3qIFhBpqOKP7BdqCFWTMPCV8yuiSVJePaGzvJRRSdta18cLuo/T1h9hd55zCvFinYBjGpCcZp9CFE8ADqBeROd7xpcMdqKp9wCeB9cBW4C5V3SwiXxGRy5O0OXV0tQDi8gnhnEKKncLh11zlz1kfD88hGJKGGsif6QaDVz8E2x9ylT3BmOlpnv5O//aHuem+TXzijo30bX+E5wKn8xRnkL7nKejtoiwvk0C761H4znOtPN9SQqD1EOcHXqVh5hrmlw8ki6NzCt5KoaOHurZuevpCtPf0s+1wK7vr28nPSqc0dxglT8MwJh3JOIWncVpH4PoIHgKeBB4bycGq+qCqVqnqQlX9T2/bl1T1gTj7rhmTHoXuFldpFAhEhI9S7BSq1wPihMu8OQRDhqgaaqBsMVS9Fbb9EZr2srP4zfz2pQPR+5UuQksW8Prjd/Or5/fxxVO7KJNm7m1bzqvZZ7mQ095nKMvLJK3DrRRqKeLBN5xzyZVuOGkt88sGnE1uRPjIzykcbetm39GO8PYXdh9ld307C8pykamshGoYJyjJVB+9R1V/4b38AvBfwE+A94+CXWNDV4sr04TRCx9VPwyzzoC88vAcAnY/FX9f1QHp5Kp1Lg8A3HxwAf92/2b6QzqwrwgtlReytPNlPntBJR+uqEYlwLTT307Fmy52s4qr11Oen0lxv0uoX33BKl5udwu7Ls2gbMVbmV+WFz5lZKK5KCeICBzt6GVfg3MKmekBNu51TmG+hY4MY0qSTPVRpohkAKhqSFV/CfwUiDOzcZLQ3TLQfRschZVCW50rG/Wllr05BFEhpDdegXuuhb4ep9Hf1eycwoI1kBaEaSvY1lFIa3cf2w63RJ1+X9l5ZEovH9ryIXj+FqTyLG5697l85tI3uZBT9cOU5wapkEa60nL5yEXLac1xYxtfDKwgN6+A4pwMCrNdqCgyp5AWEIqyM2hs72F/YwcicPGyafx1ZwMHmzqjnIlhGFOHZMJHfwLOiNl2Oi5PMDnpah5YKQTS3N11Kp3CEU/5cs5Z7md6EGavdHkGn21/gE33wN5noufzZubDJV+FC28Kz0fYsPto1Om3BpdzZ98apHgezD0bzouo6K1aC037uLD0KKtKu8konEFGWoB3rFrEN3uv4pGSDwAgIswvyyUgbiUQSXFukKMdPew72sGMgizOXVhGY4erborqUTAMY8qQjFNYwWD5iRdwVUmTk65mV3nkE8xNbfjIryQqWzywzSsJRb1QkO8IqtdHOAWvK/is6+hbtDY8K3nD3sao0x9o6efG/o+R/nd3w9/+xo129PFGNJYdepzlBV2kFcwA4OpVlXy//530zl4d3nVBWS55memDcgQlOUGOtvWw/2gHlSU5rJpXHHWMYRhTjxHPU8A1rU0DDkdsmwZMXrGg7hYojxgxHcxL7UqhocadMy9iOlfpIueMOhrcHGPfEWx/CDKyXVNa0dzw7vVtPahCekDYsPsoqhr+8j7Y2Mm0/Cwy0uL49oKZMP0UqH7EVT9VOicwtzSX7159KitmDTjDf7xgEWuXTx90iuLcIPuPdtDU0cubF5exqCKP4pwMGjt6rRzVMKYoyawU7gV+JSLLRSRHRFYAtwMpnDYyxkQmmsFVIKWyea2hZvC8Yl8wzl8tNOx0OkdNe51jKJ4fpY9U2+q6iM9dVEZta3Ql0BtNncwsGqJZrGod7H8OWt6IckxXnDqLBeUDOYFFFXmsPXmwUyjNDXKouYvDLV3MKclBRFg9v4QZhVlR+QfDMKYOyTiFm3A9Bi8ArbgGs23AjaNg1+ijGp1oBndXn8qRnPGGsPuhoYYadwff2wFnfMhtq9s2aP/aFhc6evspLvyzYc9ACOmN5k5mFcf0L0RStc41wYV6IX/wl/5wFOcGae50OYQ5Je5zvnz5ydx6zaBGc8MwpgjJlKR2qeongFxgOpCnqterare/j4i8bxRsHB16OyHUF71SCKZwpdDXDU37BjuFwjkQyHBOwQ8dLTh/oOM5RmX0SMRKoTA7I5xsDoWUQ01dQ68UZp4GuZ4USP6MpH+FkpyB5rTqMXxAAAAXkElEQVRKzynMKMzm5JmFiQ4xDGOSk/Q0GW8kZ52qapy3b4mzbWIS1j2KSTSnKqfQuMfdpcc6hbR0N5M30imULgonhuOtFESgIj+TlXOL2bDHOYX6tm56+kPMLspObEMg4JrmIDqvMUKKcyOdwhCfYxjGlCHVI8YmT4trpO6RT2Ze6qqPYiuJIild5HIJDTshPdvJWpx8JaRlupLVCGpbuynNDZKRFmDV/BJ21bdT19rNwSYnYjdzKKcAsOIq9xmRFVAjxJexyMoIuLGbhmFMeVKdLYy3epiYdHkrhajwUf4xhY+e39UAwJkLImSgfKcQb15x6ULY9biTmy5d6O7op6+Amw65fokIalu6KM93IaJV80oAeHHvUfq87uZhncLCC+ALBweddyT4KwU/yWwYxtRncg8jPh66/ZVCpFPIdfMU4kbGEvNfD23j6+u3R29sqIGcMsguGnxA6SLo64K9f41eScT54vZHawKsmFVIZnqAF3Y38oa3UphVPIKwzjE4BBjIKVQOlcw2DGNKceI6hXgrhcw8lwfo7UzqVHWt3TTFDrlv2Jl4XrG/vad12JnGta1dYacQTA9wamURG/Yc5WBjJ/mZ6RRkZQx5/PFQ7Cml+klmwzCmPql2CvtSfL7RI26iOflBO6pKfVs3zZ0xElDxylF9IrZv7alIeO7+kFLf1sO0goEKo9XzS9j8RjPVR9qGDx0dJ3mZ6XzgrDlcdkrylUuGYUxOknIKIrJERL4oIjdHvA5PaVHV5ak2cNToipi65hN2CiPvVWjt7qO7L0RLZy/hgqzuVmg7kniIff50OsV90f/vq0p33+A5yAAN7d30h5SKgoEk78p5JYQUnt/dMLLQ0XEgIvzHlStY6eUyDMOY+iSjknoV8BQwC/g7b3Mebrby5KOrGSQw4AhgYKZCbAVSfx/098Z91De1kU4fPf39dPeF3P6+5lGilYII+3B33882FXPr07vp7Q9FS2Mz0Ljmh48ATp9TREAgpAzdo2AYhnEMJFN99BXgElV9VUTe6217lckqiOcP2ImsqvFnKkSGj166HR64PuFpFgA1WXBX3/k0d15MVkZadP9BHPpDSnXfdCozj7J62SK+sX4731i/nWB6gJvetpRrzpkHuFwFEK4+AsjPymDZzAI2HWwZ9fCRYRgnHsk4hQrA13zWiJ+Tpww1kq4WyIzpzI03knPPXyC7BM7+x7in2X64jZ5N93F2YAvNnb0u/t+wExAomR/3mPq2br7ZdxWZZxXy9QtOYeXG/fT0hXhhTyP/9sBmdta18aXLlnGkxXUzTyuI7hFYObeETQdbmGVOwTCMFJOMU3gRFza6PWLb1TgtpMlHrO4RxB/J2VDjegjO+2zc0zz37B4aX9vHDWm/46XWNpiW744prHSqp3E43NzFXp1OYP5KinKCfOw8l3voDylfe3gbP35qF7mZ6WRnuFLS8vxop3DOwlJ+8ewem35mGEbKScYp3AA8IiLXArkish6oAt46KpaNNl0t0ZVHMHgkpyo07IDl7054mrrWbvaFZhBIV3rrdsKiGQPqqAk41OxWANMLo3MCaQHhC29bSkNbD7c+vYvV80soyskgMz26z+CSZdO47xPncsrsOD0QhmEYx0EygnjbgCXAzcD/AX4OrFDVHaNk2+jS3RzdowCDR3J2HB0Yj5mA+rZudqtXshkphz3EMX5YKNYp+Hz+0iVkpafxl5qGqCSzj4hwaqU5BMMwUk9SJamq2qGqd6nqN3Bho7KRHisi60Rku4jUiMjn47x/nYi8LiKviMgzIrIsGduSpitO+CjWKQyTMAbnFDrz3VCcjKZd0F4P3c0821TEzY/X8JOndtHRE93DcKi5i4w0iVIhjaQ8P5NPX1IFENWjYBiGMdokU5L6axE5x3v+IWAzsNkLJw13bBpuhXEpsAx4X5wv/V+p6gpVPRX4OqNd6toVZ6WQHoS04ED46KhfWpo4FFTX2k1FeQV1WkhW6+6wI7llc4BvrN/Ofz64lftfeSPqmMPNnUwryCIQSKwn9MGz53L6nCJOm1OccB/DMIxUk8xK4SJgo/f8M8DFwGpg0F1/HFYDNaq6S1V7gDuBKyJ3UNWWiJe5jGZVk6prMItdKUD0SM6GmkHjMWOpb+themEWe5lJfvvesFPYrdPZ8pW1lOUFwzMQfA63dDEjQejIJyMtwL0fP4fPeCsGwzCMsSAZpxBU1R4RmQWUqOpfVHUzbk7zcMwC9ke8PuBti0JEPiEiO3ErhRvinUhEPiYiG0VkY11dXRLmR9DTDto/ONEMUFQJtVvd84aaQeMxI1FV6tq6Kc/L5FD6LEo690FDDX2STlf2THKC6aycW8KGvTFOoblrRGEhUyY1DGOsScYpvCIiNwJfBP4I4DmIliGPSgJVvVlVFwKfwyWz4+3zY1Vdqaory8vLj+2DuuOI4fksfivse84lmRt2Dhk6aunqo6cvRFleJrXB2eT3N8LBF6lLn0lpoatkWjmvmP1HOznsVRyp6ohWCoZhGONBMk7hWmAFkM3AF/bZwB0jOPYgUBnxera3LRF3AlcmYVtyxNM98qla51YRNX8etoqovs3vOM6kMWuO27jvr+xlRrhqaPV8pxvkT0xr7uylqzdkCWTDMCYkI3IKXqL4GuDDqnqNqtYCqOo9qvq5EZxiA7BYROaLSBDX9PZAzGdEjgZ7OzB6pa7hlUKc8NHM090chI0/h77OIVcK9Z4MRVleJm15Xt4h1EdN/7SwU1g2o4CcYFrYKRz2ylFnFFo3smEYE48ROQVV7Qf+EegZbt8Ex/cBnwTWA1uBu1R1s4h8RUQu93b7pIhsFpFXcInsa47ls0ZEV5wBOz7+XON9z7rXQ6wU6ryVQll+kK68uYS8aaRbeirCyqbpaQFOn1PMhj2NQGTjmo23NAxj4pFM+Oh24Lpj/SBVfVBVq1R1oar+p7ftS6r6gPf8U6p6sqqeqqoXeEns0cF3CvFyCgBVaweeDxU+8gXr8jLJy83loLocx87+GVHhoVXzSth2uIXmzl6OhJ2CrRQMw5h4JCNzsRq4XkT+FVdJFC4ZVdXzUm3YqBJvwE4kCy90pahpQchPPGCmvq2HtIBQnBOkMDuDXaHpVKbVskunR3Uir5pXjCq8tLeRQ81diBC3U9kwDGO8ScYp/MR7TH6GSjT72xdc4M1cSFwWWtfaTUlukEBAKMzJYIvO5czgAeq6iqLkrk+bU0xWhmtmm16YRVleJhlpJ+4kVMMwJi4jdgqqettoGjKmrHi3Uz7NGGL28Lt+Av191Ld1c6CxM67WUL3XowBQmJ3B/+37G/qWfRSea4uSu84OpvHDD5zB9b96mS2HWlgxK8EKxTAMY5xJZqWAiEzDhZHKgPAttKr+LMV2jS6Fs91jKLKLef1AMx+5/Wnq23rYcNPFlORGaxXVt3VT5oWBCrIz6CKTlxqzgbZBctcXnFTBvR8/h4/evpE3VZpTMAxjYjJipyAiVwK/xJWKnozTPloOPANMLqcwAp7YXst1v3yR7Iw0+kPKk9W1vPO02fSHlFue2klTRy+76tu5ZJkT0SvMzgBgR21bXLlrgJOm5/PkZ9cQmpxjiQzDOAFIJrD9H8CHVPU0oN37+THc8J0px/ce3cH0gizWf/o8yvIyeXRrLQCPbj3C1x/ezm3P7qE/pKz2htoXZDmncKCxc8gksoiQNoQQnmEYxniSTPhojqreHbPtNuAw8C+pM2n86esPseVQC+9bPYeKgiwuXFLOQ5sO09sf4s4N+ynPz+TZz18YlSz2VwpgcteGYUxeklkp1Ho5BYA9InI2sBAYHCeZ5Oyqb6erNxROCF+4ZBqtXX384bU3eGJ7LVedMXtQ9VCkU4jNJxiGYUwWknEKPwHe7D3/DvA48Crwg1QbNd68fsA1t/lO4c2LywimBfi3+zcTUrh61ZxBxwTTA+GZyhX5tlIwDGNykkxJ6tcint8uIk8Auaq6dTQMG082vdFMdkYaC8pdEjkvM50zF5Tw9I563ryojDml8UtZC7Mz6Oztt8Y0wzAmLUl1UIlImoicKyJX4VRPq0fHrPFl08Fmls0siEoIX7SkAoCrV1cmOiwcQrKcgmEYk5VkSlJPAe4DsnBDcmYDXSLyTlV9dZTsG3P6Q8rmN1q46ozoPob3rppDdjCNS5cnlr3wnUJFga0UDMOYnCSzUvgZbs7yLFVdjZuc9n2mWI/C7vp2Onr6WR7TdZwdTOO9q+YMWU5akO18rIWPDMOYrCTjFKqA/1FVBfB+fhdYPORRk4xNB70k8+zku44L/JWCJZoNw5ikJOMUHgQuj9n2DrzRnFOFTQebyUwPsMhLMifDvNJcZhdnkx2cclW6hmGcICTTvJYG3CkiL+KksyuBM4D7ReR2fydV/WBqTRxbXj/YzNIZBaQfg4rpdecv5Jpz5qXeKMMwjDEiGaewyXv4bMFNUpsydPX289qBZt6zchixvAQE0wME000S2zCMyUsyTuEpYI+q7haRGcDXgH7gRlU9PCrWjTHP7Wqgs7efNV75qWEYxolGMre1P8A5AYBv4RxKCPhxqo0aLx7bVkt2RhpnLygdb1MMwzDGhWScwixV3Sci6cA6nELqx4FzRsWyMaCutZtP/OolDjd3oao8urWWcxeVkZVhiWLDME5MkgkftXiCeMuBzaraJiJBIGOY4yYsT1bX8cfXDgHwqYsWc7Cpk09euGicrTIMwxg/knEK/wtsAILAp71t5wLbRnKwiKzD9TWkAbeq6n/HvP8Z4CNAH1AHfFhV9yZhX9LsONIKwB9fO0Rnj4uMXXCS5RMMwzhxSUoQT0R+B/Sr6k5v80HcF/mQiEgarhv6EpxExgYReUBVt0Ts9jKwUlU7ROTjwNeB947UvmOh+kgrC8pz6ekL8di2WpbPKmB6oTWeGYZx4pJU/aSqVkc4BP/16yM4dDVQo6q7VLUHuBO4Iubcj6tqh/fyOZy20qhSfaSNFbMK+dJlywA3N8EwDONEZqyK6mfhGt58DnjbEnEt8FC8N0TkYyKyUUQ21tXVHbNBbd19HGzqpGpaPpcsm8atH1zJR94y/5jPZxiGMRWYcJ1WIvIBYCXwjXjvq+qPVXWlqq4sLy8/5s/x8wmLK/IQES5eNi08Z9kwDONEJZlE8/FwECeL4TPb2xaFiFwM3AScr6rdo2nQjiNtAJw0PX80P8YwDGNSMVYrhQ3AYhGZ75WxXg08ELmDiJwG3AJcrqq1o23Q9iOtZGUEqCyOP0XNMAzjRGRMnIKq9gGfxGklbQXuUtXNIvIVEfGVV78B5AF3i8grIvJAgtOlhOojrSyqyCMwxHwEwzCME42xCh+hqg/i5Lcjt30p4vnFY2ULuPDROYtMzsIwDCOSCZdoHguaO3s53NJF1TTLJxiGYURyQjoFv/Koalryg3QMwzCmMiekU6j2Ko9spWAYhhHNCekUyvKCXLJsGrOKssfbFMMwjAnFmCWaJxJvPXk6bz15+nibYRiGMeE4IVcKhmEYRnzMKRiGYRhhzCkYhmEYYcwpGIZhGGHMKRiGYRhhzCkYhmEYYcwpGIZhGGHMKRiGYRhhRFXH24ZjRkTqgL3HeHgZUJ9Cc0Ybs3d0mUz2TiZbwewdbY7F3rmqGnd05aR2CseDiGxU1ZXjbcdIMXtHl8lk72SyFcze0SbV9lr4yDAMwwhjTsEwDMMIcyI7hR+PtwFJYvaOLpPJ3slkK5i9o01K7T1hcwqGYRjGYE7klYJhGIYRgzkFwzAMI8wJ6RREZJ2IbBeRGhH5/HjbE4uIVIrI4yKyRUQ2i8invO0lIvInEdnh/Sweb1t9RCRNRF4WkT94r+eLyPPeNf6NiATH20YfESkSkXtEZJuIbBWRsyf4tf0n7+9gk4j8WkSyJtL1FZGfiUitiGyK2Bb3eorje57dr4nI6RPE3m94fw+vicjvRKQo4r0bPXu3i8jaiWBvxHv/LCIqImXe6+O+viecUxCRNOBm4FJgGfA+EVk2vlYNog/4Z1VdBpwFfMKz8fPAo6q6GHjUez1R+BSwNeL114DvqOoioBG4dlysis93gYdVdQnwJpzdE/Laisgs4AZgpaouB9KAq5lY1/cXwLqYbYmu56XAYu/xMeCHY2RjJL9gsL1/Apar6ilANXAjgPd/dzVwsnfMD7zvkLHkFwy2FxGpBN4K7IvYfNzX94RzCsBqoEZVd6lqD3AncMU42xSFqh5S1Ze85624L61ZODtv83a7DbhyfCyMRkRmA28HbvVeC3AhcI+3y0SytRA4D/gpgKr2qGoTE/TaeqQD2SKSDuQAh5hA11dVnwKOxmxOdD2vAG5Xx3NAkYjMGBtLHfHsVdVHVLXPe/kcMNt7fgVwp6p2q+puoAb3HTJmJLi+AN8B/hWIrBY67ut7IjqFWcD+iNcHvG0TEhGZB5wGPA9MU9VD3luHgWnjZFYs/4P74wx5r0uBpoh/sol0jecDdcDPvXDXrSKSywS9tqp6EPgm7m7wENAMvMjEvb4+ia7nZPj/+zDwkPd8QtorIlcAB1X11Zi3jtveE9EpTBpEJA+4F/i0qrZEvqeulnjc64lF5DKgVlVfHG9bRkg6cDrwQ1U9DWgnJlQ0Ua4tgBeLvwLnzGYCucQJJUxkJtL1HA4RuQkXvr1jvG1JhIjkAF8AvjQa5z8RncJBoDLi9Wxv24RCRDJwDuEOVf2tt/mIvxT0ftaOl30RnAtcLiJ7cKG4C3Ex+yIv3AET6xofAA6o6vPe63twTmIiXluAi4Hdqlqnqr3Ab3HXfKJeX59E13PC/v+JyN8DlwHv14EGrolo70LcTcKr3v/dbOAlEZlOCuw9EZ3CBmCxV70RxCWRHhhnm6LwYvI/Bbaq6rcj3noAuMZ7fg1w/1jbFouq3qiqs1V1Hu5aPqaq7wceB97t7TYhbAVQ1cPAfhE5ydt0EbCFCXhtPfYBZ4lIjvd34ds7Ia9vBImu5wPAB70qmbOA5ogw07ghIutwIdDLVbUj4q0HgKtFJFNE5uMSuC+Mh40+qvq6qlao6jzv/+4AcLr3t33811dVT7gH8DZchcFO4KbxtieOfW/GLbdfA17xHm/DxeofBXYAfwZKxtvWGLvXAH/wni/A/fPUAHcDmeNtX4SdpwIbvet7H1A8ka8t8O/ANmAT8P+AzIl0fYFf4/Idvd4X1LWJricguOq/ncDruKqqiWBvDS4W7/+//Shi/5s8e7cDl04Ee2Pe3wOUper6msyFYRiGEeZEDB8ZhmEYCTCnYBiGYYQxp2AYhmGEMadgGIZhhDGnYBiGYYQxp2AY44yIzPOULtOH39swRhdzCoZhGEYYcwqGYRhGGHMKhhEHEZkpIveKSJ2I7BaRG7ztXxY3oOc3ItIqIi+JyJsijlsqIk+ISJM3GOfyiPeyReRbIrJXRJpF5BkRyY742PeLyD4RqfeE2QxjzDGnYBgxiEgA+D3wKk52+CLg0xFTt67ASUuUAL8C7hORDE/E8PfAI0AFcD1wR4TO0jeBM4BzvGMj5cbByZuc5H3el0Rk6aj9koaRAJO5MIwYRORM4G5VnROx7UagCtgLrFPVs7ztAZwK5Xu8Xe8GZqpqyHv/1zjNnK/gZLrP0hgNfG9mxm6gUlUPeNteAL6tqneO0q9pGHGxagfDGMxcYKaINEVsSwOexjmF8BATVQ2JyAHcrAOA/b5D8NiLW22UAVk4obJEHI543gHkHfNvYBjHiIWPDGMw+3EzDIoiHvmq+jbv/bBevbdSmA284T0qvW0+c3AriXqgC6eFbxgTFnMKhjGYF4BWEfmclxxOE5HlIrLKe/8MEfkbr6/g00A3bq7v87g7/H/1cgxrgHfgZvyGgJ8B3/aS2GkicraIZI75b2cYQ2BOwTBiUNV+3ASuU3Gx/nrgVqDQ2+V+4L1AI/B3wN+oaq+q9uCcwKXeMT8APqiq27zj/gWncb8BN4j9a9j/oDHBsESzYSSBiHwZWKSqHxhvWwxjNLC7FMMwDCOMOQXDMAwjjIWPDMMwjDC2UjAMwzDCmFMwDMMwwphTMAzDMMKYUzAMwzDCmFMwDMMwwvx/lR+X91nxbyYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "metric = \"sparse_categorical_accuracy\"\n",
        "plt.figure()\n",
        "plt.plot(history.history[metric])\n",
        "plt.plot(history.history[\"val_\" + metric])\n",
        "plt.title(\"model \" + metric)\n",
        "plt.ylabel(metric, fontsize=\"large\")\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extras"
      ],
      "metadata": {
        "id": "qEZO4HlzOPrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels=(training_set.class_indices)\n",
        "# labels2=dict((v,k) for k,v in labels.items())\n",
        "import collections \n",
        "for i in range(len(data_kfold)):\n",
        "    co = collections.Counter(data_kfold.loc[i])\n",
        "    co = sorted(co.items(),key=lambda x: x[1],reverse=True)\n",
        "    # ans.Class.loc[i] = labels2[co[0][0]]"
      ],
      "metadata": {
        "id": "xd6-XC8nAuZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxmaWlJVAuR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAoUR_czJsO5"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMW46JTpKQRg"
      },
      "source": [
        "O que alterei do Plotting Time:\n",
        "\n",
        "\n",
        "*   Strides das Conv2D pus o default (1,1) (acho que isto j era suposto ser o default)\n",
        "*   Dropout de 0.7 -> 0.5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OltFsau_Jmv7"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "# model.add(InputLayer(input_shape=(width, height, channels)))\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5)) #Aumentar depois maybe o dropout\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# early stopping\n",
        "callback = EarlyStopping(monitor='loss')\n",
        "# compile model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "history = model.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr50vZdSJtPP"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "print('Test accuracy:')\n",
        "_, acc = model.evaluate(test_iterator, steps=len(test_iterator))\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_61wkrKZKkgV"
      },
      "outputs": [],
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7rNXMGV7GVBd",
        "NI6q1ETnGXBl",
        "dt2FWTLWTpKA",
        "GAct8l7vr3_N",
        "qEZO4HlzOPrP"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}