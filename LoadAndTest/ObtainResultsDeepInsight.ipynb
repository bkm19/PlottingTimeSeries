{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1aJT92Ktdb"
      },
      "source": [
        "# Scrip to load boxplot images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rNXMGV7GVBd"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4ObiYNpMfGW"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install sktime\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4SrxJlTGbj7"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import imageio\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re \n",
        "import math\n",
        "import gc\n",
        "\n",
        "from pathlib import Path \n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "from sktime.datasets import load_from_tsfile_to_dataframe\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI6q1ETnGXBl"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq1ZPiFsGpp9"
      },
      "outputs": [],
      "source": [
        "def pureBlackAndWhiteImageArrayUpdated( imageArray, normalized = True):\n",
        "  aux = imageArray != 0\n",
        "  result = aux.astype(\"uint8\")[:,:,:1]\n",
        "  return result if normalized else (result*255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbfsPGXLOl8h"
      },
      "outputs": [],
      "source": [
        "def array2img ( array, mode = \"L\" ):\n",
        "    \"\"\"\n",
        "    @brief Convert a Matplotlib figure to a PIL Image in RGBA format and return it\n",
        "    @param fig a matplotlib figure\n",
        "    @return a Python Imaging Library ( PIL ) image\n",
        "    \"\"\"\n",
        "    # put the figure pixmap into a numpy array\n",
        "    h, w, d = array.shape\n",
        "    return Image.frombytes( mode, ( w, h ), array.tobytes( ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJBap9i6O2az"
      },
      "outputs": [],
      "source": [
        "def displayImageUniqueValuesMore ( imageArray ):\n",
        "\n",
        "  print(\"ImageArray Shape:\" , imageArray.shape)\n",
        "  img2 = imageArray.reshape(-1, imageArray.shape[2]) # reshape the original image into -1, 3; -1 is placeholder, so lets say you have a \n",
        "                                                    # numpy array with shape (6,2), if you reshape it to (-1, 3), we know the second dim = 3\n",
        "                                                    # first dim = (6*2)/3 = 4, so -1 is replaced with 4\n",
        "  print(\"ImageReshape Shape:\", img2.shape)\n",
        "\n",
        "  counter = np.unique(img2, axis=0) # find unique elemenst\n",
        "  '''\n",
        "  numpy.unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None)[source]\n",
        "  Find the unique elements of an array.\n",
        "\n",
        "  Returns the sorted unique elements of an array. There are three optional outputs in addition to the unique elements:\n",
        "\n",
        "  the indices of the input array that give the unique values\n",
        "  the indices of the unique array that reconstruct the input array\n",
        "  the number of times each unique value comes up in the input array\n",
        "  '''\n",
        "  #print(\"Array of pixels combinations:\\n\", counter)\n",
        "  print(\"Shape of array\", counter.shape) # as, we have separate axis, so the channels are shown in dim 2\n",
        "  print(\"how many pixels:\", counter.shape[0], \"or\", len(set(imageArray.flatten())))\n",
        "  \n",
        "  #binArray=np.bincount(counter.flatten())\n",
        "  count = 0\n",
        "  for value in counter:\n",
        "    print(\"Value: \", value, \"| Occurrences:\", (img2 == value).sum())\n",
        "    count =+ 1\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_order(file):\n",
        "    match = re.compile(r'.*?(\\d+).*?').match(Path(file).name)\n",
        "    if not match:\n",
        "        return math.inf\n",
        "    return int(match.groups()[0])"
      ],
      "metadata": {
        "id": "QZNrzwlgoLuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhSJS8SNL2un"
      },
      "source": [
        "## Run code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XYvQxV91I75"
      },
      "source": [
        "### Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY1TvmGdRJdz",
        "outputId": "d2a0be20-d04b-44ff-c97e-822c4b07585c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ6g7mV3RLaT"
      },
      "outputs": [],
      "source": [
        "DATA_SET_NAMES = [\n",
        "\"ACSF1\",\n",
        "\"Adiac\",\n",
        "\"ArrowHead\",\n",
        "\"Beef\",\n",
        "\"BeetleFly\",\n",
        "\"BirdChicken\",\n",
        "\"BME\",\n",
        "\"Car\",\n",
        "\"CBF\",\n",
        "\"Chinatown\",\n",
        "\"ChlorineConcentration\",\n",
        "\"CinCECGTorso\",\n",
        "\"Coffee\",\n",
        "\"Computers\",\n",
        "\"Crop\",\n",
        "\"DiatomSizeReduction\",\n",
        "\"DistalPhalanxOutlineAgeGroup\",\n",
        "\"DistalPhalanxOutlineCorrect\",\n",
        "\"DistalPhalanxTW\",\n",
        "\"Earthquakes\",\n",
        "\"ECG200\",\n",
        "\"ECG5000\",\n",
        "\"ECGFiveDays\",\n",
        "\"ElectricDevices\",\n",
        "\"EthanolLevel\",\n",
        "\"FaceAll\",\n",
        "\"FaceFour\",\n",
        "\"FacesUCR\",\n",
        "\"FiftyWords\",\n",
        "\"Fish\",\n",
        "\"FordA\",\n",
        "\"FordB\",\n",
        "\"FreezerRegularTrain\",\n",
        "\"FreezerSmallTrain\",\n",
        "\"GunPoint\",\n",
        "\"GunPointAgeSpan\",\n",
        "\"GunPointMaleVersusFemale\",\n",
        "\"GunPointOldVersusYoung\",\n",
        "\"Ham\",\n",
        "\"Haptics\",\n",
        "\"Herring\",\n",
        "\"HouseTwenty\",\n",
        "\"InlineSkate\",\n",
        "\"InsectEPGRegularTrain\",\n",
        "\"InsectEPGSmallTrain\",\n",
        "\"ItalyPowerDemand\",\n",
        "\"LargeKitchenAppliances\",\n",
        "\"Lightning2\",\n",
        "\"Lightning7\",\n",
        "\"Mallat\",\n",
        "\"Meat\",\n",
        "\"MedicalImages\",\n",
        "\"MiddlePhalanxOutlineAgeGroup\",\n",
        "\"MiddlePhalanxOutlineCorrect\",\n",
        "\"MiddlePhalanxTW\",\n",
        "\"MixedShapesRegularTrain\",\n",
        "\"MixedShapesSmallTrain\",\n",
        "\"MoteStrain\",\n",
        "\"OliveOil\",\n",
        "\"OSULeaf\",\n",
        "\"PhalangesOutlinesCorrect\",\n",
        "\"Phoneme\",\n",
        "\"PigAirwayPressure\",\n",
        "\"PigArtPressure\",\n",
        "\"PigCVP\",\n",
        "\"Plane\",\n",
        "\"ProximalPhalanxOutlineAgeGroup\",\n",
        "\"ProximalPhalanxOutlineCorrect\",\n",
        "\"ProximalPhalanxTW\",\n",
        "\"RefrigerationDevices\",\n",
        "\"Rock\",\n",
        "\"ScreenType\",\n",
        "\"SemgHandGenderCh2\",\n",
        "\"SemgHandMovementCh2\",\n",
        "\"SemgHandSubjectCh2\",\n",
        "\"ShapeletSim\",\n",
        "\"ShapesAll\",\n",
        "\"SmallKitchenAppliances\",\n",
        "\"SmoothSubspace\",\n",
        "\"SonyAIBORobotSurface1\",\n",
        "\"SonyAIBORobotSurface2\",\n",
        "\"StarLightCurves\",\n",
        "\"Strawberry\",\n",
        "\"SwedishLeaf\",\n",
        "\"Symbols\",\n",
        "\"SyntheticControl\",\n",
        "\"ToeSegmentation1\",\n",
        "\"ToeSegmentation2\",\n",
        "\"Trace\",\n",
        "\"TwoLeadECG\",\n",
        "\"TwoPatterns\",\n",
        "\"UMD\",\n",
        "\"UWaveGestureLibraryAll\",\n",
        "\"Wafer\",\n",
        "\"Wine\",\n",
        "\"WordSynonyms\",\n",
        "\"Worms\",\n",
        "\"WormsTwoClass\",\n",
        "\"Yoga\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ktgKArfr4CG",
        "outputId": "efcb53ef-921b-4124-f1f9-2668060a5a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "print(len(DATA_SET_NAMES))\n",
        "index = DATA_SET_NAMES.index(\"Herring\")\n",
        "index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns=['Dataset',\n",
        "         'Average: Acc','Average: Loss',\n",
        "         'Standard Deviation',\n",
        "         'batch_size', 'epochs']\n",
        "df_csv = pd.DataFrame(columns=columns)"
      ],
      "metadata": {
        "id": "3wa9PLPgTIvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import some data zipped"
      ],
      "metadata": {
        "id": "dt2FWTLWTpKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/drive/MyDrive/DeepInsight.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y84o_1A2fFMl",
        "outputId": "e8370630-1815-4fea-8de9-f179322ef39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwV3R4M9NRGx"
      },
      "source": [
        "### Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktGGvgCJLrkj"
      },
      "outputs": [],
      "source": [
        "#CHOOSE DATA SET NAME AND PATH OF FOLDER OF IMAGES\n",
        "name = \"ArrowHead\"\n",
        "normalized = False # IF WE WANT 0|1 or 0|255\n",
        "\n",
        "pathName = '/content/' + \"DeepInsight\"+ '/'\n",
        "\n",
        "_, train_y = load_from_tsfile_to_dataframe(\"drive/MyDrive/Tese/Univariate_ts/\" + name + \"/\" + name + \"_TRAIN.ts\")\n",
        "_, test_y = load_from_tsfile_to_dataframe(\"drive/MyDrive/Tese/Univariate_ts/\" + name + \"/\" + name + \"_TEST.ts\")\n",
        "\n",
        "train_x = np.empty((len(train_y), 50, 50, 3), dtype=np.uint8)\n",
        "test_x = np.empty((len(test_y), 50, 50, 3), dtype=np.uint8)\n",
        "\n",
        "trainOrTest = 'TRAIN'\n",
        "path = pathName + name + '/' + trainOrTest + '/' + '*.png*'\n",
        "\n",
        "  \n",
        "for i, img_path in enumerate(sorted(glob.glob(path), key=get_order)):\n",
        "  train_x[i] = cv2.imread(img_path)\n",
        "  #train_x[i] = pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized)\n",
        "\n",
        "trainOrTest = 'TEST'\n",
        "path = pathName + name + '/' + trainOrTest + '/' + '*.png*'\n",
        "\n",
        "for i, img_path in enumerate(sorted(glob.glob(path), key=get_order)):\n",
        "  test_x[i] = cv2.imread(img_path)\n",
        "  #test_x[i] = pureBlackAndWhiteImageArrayUpdated(cv2.imread(img_path), normalized = normalized)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.nbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3dET2vdGOFD",
        "outputId": "b77be798-1152-4813-cb6e-936574326164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "270000"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.nbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eq4jD6EFDQ0",
        "outputId": "4dd4bccf-2358-480f-d1c7-89c4a34aa5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1312500"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 channels:**\n",
        "\n",
        "train_x.nbytes:\n",
        "2.687.385.600\n",
        "\n",
        "test_x.nbytes: \n",
        " 6.270.566.400\n",
        "\n",
        "**1 channels:**\n",
        "\n",
        "train_x.nbytes:\n",
        "895.795.200\n",
        "\n",
        "test_x.nbytes:\n",
        "2.090.188.800"
      ],
      "metadata": {
        "id": "wm21yA9FFF7C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh166gghZ6Y8"
      },
      "source": [
        "#### Details of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKL9KAINyWp4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8232d29c-aa11-4e21-c403-52bfe91cf199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ArrowHead'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X5sdA6a0-7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81089b6-9812-432d-d513-b17f192ee411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageArray Shape: (50, 50, 1)\n",
            "ImageReshape Shape: (2500, 1)\n",
            "Shape of array (2, 1)\n",
            "how many pixels: 2 or 2\n",
            "Value:  [0] | Occurrences: 2308\n",
            "Value:  [255] | Occurrences: 192\n"
          ]
        }
      ],
      "source": [
        "displayImageUniqueValuesMore(train_x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "hzINJk1AKCvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "GDxbmPaDJSx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.imshow(train_x[16])"
      ],
      "metadata": {
        "id": "jgdUSa9jJMwC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "e9cf3b31-48ca-4134-9877-9469ab88fc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb6e9629810>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvcqqM0vU5HV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "03a32a5c-5926-47e8-dd41-6520f0190e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb6e95f4f90>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# image = array2img(train_x[0])\n",
        "# plt.axis('off')\n",
        "# plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRiSqd15wdp7"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TESTE\n",
        "\n"
      ],
      "metadata": {
        "id": "16m0aw2Envey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions"
      ],
      "metadata": {
        "id": "GAct8l7vr3_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(width, height, channels):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, (1, 1), activation='relu', input_shape=(width, height, channels)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (1, 1), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (1, 1), activation='relu'))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.7)) #Aumentar depois maybe o dropout\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.7))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  # early stopping\n",
        "  callback = EarlyStopping(monitor='loss')\n",
        "  # compile model\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "-xcdhMDSqryq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model2(width, height, channels):\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "  # early stopping\n",
        "  callback = EarlyStopping(monitor='loss', patience=3)\n",
        "  # compile model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "6aFfS1CLqLfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgHz3zRbpog2"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCOb2X37pog7"
      },
      "outputs": [],
      "source": [
        "# This cell is used to fix one hot encoding automatic from keras in some datasets\n",
        "train_y = train_y.astype('uint8')\n",
        "test_y = test_y.astype('uint8')\n",
        "while(min(train_y) > 0):\n",
        "  train_y = train_y - 1\n",
        "while(min(test_y) > 0):\n",
        "  test_y = test_y - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9b0123-46b1-4d6a-ae89-a431600b03be",
        "id": "v_xUktQnpog7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (36, 50, 50, 3)  | y =  36\n",
            "Test:   (175, 50, 50, 3)  | y =  175\n",
            "Number of classes:  3\n"
          ]
        }
      ],
      "source": [
        "print(\"Train: \", train_x.shape, \" | y = \", train_y.size)\n",
        "print(\"Test:  \", test_x.shape, \" | y = \", test_y.size)\n",
        "n_classes = np.unique(train_y).size\n",
        "print(\"Number of classes: \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c91b4e0-3f69-4c4e-a5d9-0170b0ea99df",
        "id": "hXFW3tbhpog8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width:  50 | Height:  50 | Channels:  3\n"
          ]
        }
      ],
      "source": [
        "train_length, width, height, channels = train_x.shape[0], train_x.shape[1], train_x.shape[2], train_x.shape[3]\n",
        "print(\"Width: \", width, \"| Height: \", height, \"| Channels: \", channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neJ-11mRpog8"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    # keras.callbacks.ModelCheckpoint(\n",
        "    #     \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    # ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]"
      ],
      "metadata": {
        "id": "3xEdrIXeMyeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "FOuzykNXpqT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configs\n",
        "BATCH_SIZE = 32 if train_length >= 500 else 16 if train_length >= 50 else 8\n",
        "EPOCHS = 100\n",
        "N_SPLIT = 5\n",
        "verbose = 1\n",
        "\n",
        "# Storing the average of all predictions\n",
        "main_pred = []\n",
        "data_kfold = pd.DataFrame()\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "row = []\n",
        "row.append(name)\n",
        "\n",
        "kfold = KFold(n_splits=N_SPLIT, shuffle=True) # , random_state=42)\n",
        "\n",
        "# Variable for keeping count of split we are executing\n",
        "\n",
        "fold_no = 0\n",
        "\n",
        "\n",
        "# K-fold Train and test for each split\n",
        "\n",
        "for train_idx, val_idx in list(kfold.split(train_x, train_y)):\n",
        "\n",
        "    fold_no+=1\n",
        "\n",
        "    # training_set  = datagen.flow(train_idx, train_y, batch_size=64)\n",
        "    training_set  = datagen.flow(train_x[train_idx], train_y[train_idx], batch_size=BATCH_SIZE)\n",
        "    \n",
        "    validation_set = datagen.flow(train_x[val_idx], train_y[val_idx], batch_size=BATCH_SIZE)\n",
        "\n",
        "    model_test = get_model(width, height, channels)\n",
        "    history = model_test.fit( training_set,\n",
        "                              validation_data=validation_set,\n",
        "                              epochs = EPOCHS,\n",
        "                              steps_per_epoch = len(training_set) ,\n",
        "                              callbacks = callbacks,\n",
        "                              verbose = verbose\n",
        "                              )\n",
        "\n",
        "    del(training_set)\n",
        "    del(validation_set)\n",
        "\n",
        "    test_set = datagen.flow(test_x, test_y, batch_size=BATCH_SIZE)\n",
        "\n",
        "    pred = model_test.evaluate(test_set, steps=len(test_set))\n",
        "\n",
        "    del(test_set)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model_test.metrics_names[0]} of {pred[0]}; {model_test.metrics_names[1]} of {pred[1]*100}%')\n",
        "    acc_per_fold.append(pred[1])\n",
        "    loss_per_fold.append(pred[0])\n",
        "\n",
        "    # predicted_class_indices=np.argmax(pred,axis=1)\n",
        "    # data_kfold[fold_no] = predicted_class_indices\n",
        "\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6arV_Kxn0ZU",
        "outputId": "eb4ef21c-207d-4e73-95c2-0407a1d95f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 129ms/step - loss: 1.0741 - accuracy: 0.5000 - val_loss: 1.1012 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0870 - accuracy: 0.4643 - val_loss: 1.1005 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0945 - accuracy: 0.3214 - val_loss: 1.1002 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.1046 - accuracy: 0.3571 - val_loss: 1.1013 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0676 - accuracy: 0.3929 - val_loss: 1.1072 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0757 - accuracy: 0.3929 - val_loss: 1.1132 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0908 - accuracy: 0.3571 - val_loss: 1.1174 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0798 - accuracy: 0.3929 - val_loss: 1.1175 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 1.0797 - accuracy: 0.3571 - val_loss: 1.1183 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 1.0608 - accuracy: 0.5357 - val_loss: 1.1207 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0425 - accuracy: 0.5357 - val_loss: 1.1227 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.1037 - accuracy: 0.3571 - val_loss: 1.1255 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1378 - accuracy: 0.3571 - val_loss: 1.1252 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0752 - accuracy: 0.3929 - val_loss: 1.1236 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0841 - accuracy: 0.3571 - val_loss: 1.1211 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.1110 - accuracy: 0.3929 - val_loss: 1.1207 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.0415 - accuracy: 0.6429 - val_loss: 1.1221 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1020 - accuracy: 0.2143 - val_loss: 1.1215 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.0923 - accuracy: 0.3929 - val_loss: 1.1193 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.0727 - accuracy: 0.4286 - val_loss: 1.1150 - val_accuracy: 0.1250 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.0773 - accuracy: 0.4643 - val_loss: 1.1103 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0892 - accuracy: 0.4643 - val_loss: 1.1071 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0804 - accuracy: 0.4643 - val_loss: 1.1057 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0607 - accuracy: 0.3571 - val_loss: 1.1068 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0610 - accuracy: 0.6071 - val_loss: 1.1067 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.1039 - accuracy: 0.3571 - val_loss: 1.1099 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0534 - accuracy: 0.4286 - val_loss: 1.1121 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0223 - accuracy: 0.6071 - val_loss: 1.1154 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0289 - accuracy: 0.4643 - val_loss: 1.1170 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0460 - accuracy: 0.4286 - val_loss: 1.1188 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0317 - accuracy: 0.5000 - val_loss: 1.1185 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.1213 - accuracy: 0.3214 - val_loss: 1.1192 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0264 - accuracy: 0.6071 - val_loss: 1.1205 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.0968 - accuracy: 0.2857 - val_loss: 1.1214 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0745 - accuracy: 0.3929 - val_loss: 1.1229 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0542 - accuracy: 0.3929 - val_loss: 1.1230 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0413 - accuracy: 0.3929 - val_loss: 1.1220 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0232 - accuracy: 0.5000 - val_loss: 1.1202 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0295 - accuracy: 0.5000 - val_loss: 1.1167 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0693 - accuracy: 0.4643 - val_loss: 1.1121 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.0326 - accuracy: 0.4643 - val_loss: 1.1101 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0332 - accuracy: 0.5000 - val_loss: 1.1089 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0038 - accuracy: 0.4643 - val_loss: 1.1083 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0265 - accuracy: 0.5000 - val_loss: 1.1071 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0411 - accuracy: 0.4286 - val_loss: 1.1083 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0522 - accuracy: 0.3929 - val_loss: 1.1126 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0196 - accuracy: 0.4643 - val_loss: 1.1139 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0395 - accuracy: 0.5357 - val_loss: 1.1128 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.0257 - accuracy: 0.5000 - val_loss: 1.1091 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.9869 - accuracy: 0.5714 - val_loss: 1.1048 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0741 - accuracy: 0.3929 - val_loss: 1.1016 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9576 - accuracy: 0.6429 - val_loss: 1.0937 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0069 - accuracy: 0.6071 - val_loss: 1.0866 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0478 - accuracy: 0.5357 - val_loss: 1.0803 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0198 - accuracy: 0.5000 - val_loss: 1.0768 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.9717 - accuracy: 0.6786 - val_loss: 1.0730 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.9818 - accuracy: 0.5714 - val_loss: 1.0699 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.9675 - accuracy: 0.6071 - val_loss: 1.0666 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.9956 - accuracy: 0.5000 - val_loss: 1.0642 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.9746 - accuracy: 0.5357 - val_loss: 1.0600 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.0101 - accuracy: 0.5357 - val_loss: 1.0584 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9830 - accuracy: 0.5357 - val_loss: 1.0521 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9514 - accuracy: 0.5357 - val_loss: 1.0436 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.9856 - accuracy: 0.6071 - val_loss: 1.0388 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9819 - accuracy: 0.5357 - val_loss: 1.0427 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.0313 - accuracy: 0.5000 - val_loss: 1.0420 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9472 - accuracy: 0.5714 - val_loss: 1.0398 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0395 - accuracy: 0.4643 - val_loss: 1.0389 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.0150 - accuracy: 0.4643 - val_loss: 1.0396 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.8809 - accuracy: 0.6071 - val_loss: 1.0381 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.9260 - accuracy: 0.6786 - val_loss: 1.0372 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.9424 - accuracy: 0.5000 - val_loss: 1.0353 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0044 - accuracy: 0.4643 - val_loss: 1.0300 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.9563 - accuracy: 0.5357 - val_loss: 1.0223 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9330 - accuracy: 0.5357 - val_loss: 1.0156 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.9704 - accuracy: 0.5357 - val_loss: 1.0104 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9725 - accuracy: 0.7143 - val_loss: 1.0066 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.9593 - accuracy: 0.5000 - val_loss: 1.0019 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9011 - accuracy: 0.6071 - val_loss: 1.0040 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9397 - accuracy: 0.6071 - val_loss: 1.0044 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9444 - accuracy: 0.6786 - val_loss: 0.9973 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8225 - accuracy: 0.6071 - val_loss: 0.9907 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0177 - accuracy: 0.5357 - val_loss: 0.9858 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0070 - accuracy: 0.5000 - val_loss: 0.9836 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.9391 - accuracy: 0.6071 - val_loss: 0.9820 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9387 - accuracy: 0.5357 - val_loss: 0.9805 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9338 - accuracy: 0.5357 - val_loss: 0.9786 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8684 - accuracy: 0.6429 - val_loss: 0.9748 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.8908 - accuracy: 0.6429 - val_loss: 0.9700 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.8800 - accuracy: 0.6786 - val_loss: 0.9594 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9076 - accuracy: 0.6429 - val_loss: 0.9511 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.8632 - accuracy: 0.6429 - val_loss: 0.9509 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8367 - accuracy: 0.6071 - val_loss: 0.9504 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.8053 - accuracy: 0.7143 - val_loss: 0.9503 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.8838 - accuracy: 0.6429 - val_loss: 0.9424 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.8299 - accuracy: 0.6429 - val_loss: 0.9355 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9410 - accuracy: 0.5357 - val_loss: 0.9253 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.8688 - accuracy: 0.5714 - val_loss: 0.9220 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.8390 - accuracy: 0.6429 - val_loss: 0.9278 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.8392 - accuracy: 0.6429 - val_loss: 0.9209 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.9410 - accuracy: 0.5314\n",
            "Score for fold 1: loss of 0.9410296678543091; accuracy of 53.14285755157471%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 115ms/step - loss: 1.0930 - accuracy: 0.2414 - val_loss: 1.1220 - val_accuracy: 0.1429 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1035 - accuracy: 0.4138 - val_loss: 1.1202 - val_accuracy: 0.1429 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.1076 - accuracy: 0.3793 - val_loss: 1.1224 - val_accuracy: 0.1429 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0787 - accuracy: 0.4138 - val_loss: 1.1237 - val_accuracy: 0.1429 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0863 - accuracy: 0.2414 - val_loss: 1.1231 - val_accuracy: 0.1429 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0937 - accuracy: 0.2759 - val_loss: 1.1237 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.1063 - accuracy: 0.3103 - val_loss: 1.1192 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0998 - accuracy: 0.2759 - val_loss: 1.1151 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.1161 - accuracy: 0.3448 - val_loss: 1.1109 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0483 - accuracy: 0.4828 - val_loss: 1.1107 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0915 - accuracy: 0.4138 - val_loss: 1.1152 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0728 - accuracy: 0.3448 - val_loss: 1.1196 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.1046 - accuracy: 0.2414 - val_loss: 1.1239 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0794 - accuracy: 0.4828 - val_loss: 1.1207 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0829 - accuracy: 0.3793 - val_loss: 1.1211 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0604 - accuracy: 0.5172 - val_loss: 1.1223 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0636 - accuracy: 0.2069 - val_loss: 1.1210 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0833 - accuracy: 0.4138 - val_loss: 1.1183 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0906 - accuracy: 0.3448 - val_loss: 1.1185 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.0912 - accuracy: 0.4138 - val_loss: 1.1146 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0627 - accuracy: 0.4483 - val_loss: 1.1126 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0755 - accuracy: 0.3793 - val_loss: 1.1090 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0554 - accuracy: 0.4483 - val_loss: 1.1058 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0245 - accuracy: 0.4483 - val_loss: 1.1005 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0280 - accuracy: 0.4828 - val_loss: 1.0981 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.0564 - accuracy: 0.4483 - val_loss: 1.0962 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.0778 - accuracy: 0.4138 - val_loss: 1.0960 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0496 - accuracy: 0.3448 - val_loss: 1.0955 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0327 - accuracy: 0.4828 - val_loss: 1.0962 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0522 - accuracy: 0.5172 - val_loss: 1.0928 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0047 - accuracy: 0.6207 - val_loss: 1.0913 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0578 - accuracy: 0.4483 - val_loss: 1.0909 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0819 - accuracy: 0.5517 - val_loss: 1.0873 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0188 - accuracy: 0.4828 - val_loss: 1.0832 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0430 - accuracy: 0.4483 - val_loss: 1.0821 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0767 - accuracy: 0.3103 - val_loss: 1.0812 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0067 - accuracy: 0.4483 - val_loss: 1.0761 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0891 - accuracy: 0.3103 - val_loss: 1.0674 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0541 - accuracy: 0.5172 - val_loss: 1.0629 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0692 - accuracy: 0.4138 - val_loss: 1.0573 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0110 - accuracy: 0.4828 - val_loss: 1.0507 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0724 - accuracy: 0.4138 - val_loss: 1.0454 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0416 - accuracy: 0.3448 - val_loss: 1.0409 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0428 - accuracy: 0.4138 - val_loss: 1.0381 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 1.0553 - accuracy: 0.4828 - val_loss: 1.0366 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 1.0461 - accuracy: 0.4138 - val_loss: 1.0320 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9987 - accuracy: 0.4138 - val_loss: 1.0282 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9925 - accuracy: 0.5172 - val_loss: 1.0232 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.0195 - accuracy: 0.5172 - val_loss: 1.0191 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0575 - accuracy: 0.4828 - val_loss: 1.0174 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0694 - accuracy: 0.4138 - val_loss: 1.0146 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0416 - accuracy: 0.4828 - val_loss: 1.0145 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9460 - accuracy: 0.5517 - val_loss: 1.0150 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9520 - accuracy: 0.4828 - val_loss: 1.0136 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9610 - accuracy: 0.7241 - val_loss: 1.0099 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0895 - accuracy: 0.3448 - val_loss: 1.0069 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0252 - accuracy: 0.4828 - val_loss: 1.0076 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9765 - accuracy: 0.5172 - val_loss: 1.0062 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0244 - accuracy: 0.5172 - val_loss: 1.0067 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9996 - accuracy: 0.5172 - val_loss: 1.0014 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0520 - accuracy: 0.4483 - val_loss: 0.9980 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9531 - accuracy: 0.6897 - val_loss: 0.9985 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8694 - accuracy: 0.6897 - val_loss: 0.9966 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9690 - accuracy: 0.5517 - val_loss: 0.9909 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.9556 - accuracy: 0.4828 - val_loss: 0.9840 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0129 - accuracy: 0.4483 - val_loss: 0.9801 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9914 - accuracy: 0.5517 - val_loss: 0.9787 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9740 - accuracy: 0.6207 - val_loss: 0.9739 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0422 - accuracy: 0.5172 - val_loss: 0.9654 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9441 - accuracy: 0.4138 - val_loss: 0.9546 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9844 - accuracy: 0.4138 - val_loss: 0.9446 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.0014 - accuracy: 0.4483 - val_loss: 0.9380 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.8947 - accuracy: 0.7241 - val_loss: 0.9252 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8909 - accuracy: 0.6897 - val_loss: 0.9153 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9167 - accuracy: 0.5862 - val_loss: 0.9073 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9694 - accuracy: 0.4828 - val_loss: 0.9031 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9919 - accuracy: 0.5172 - val_loss: 0.9022 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.9994 - accuracy: 0.4828 - val_loss: 0.9006 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0155 - accuracy: 0.4483 - val_loss: 0.8973 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9522 - accuracy: 0.5172 - val_loss: 0.8987 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9886 - accuracy: 0.4483 - val_loss: 0.8967 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.9161 - accuracy: 0.5517 - val_loss: 0.8910 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.8648 - accuracy: 0.5517 - val_loss: 0.8898 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8944 - accuracy: 0.5517 - val_loss: 0.8897 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.9497 - accuracy: 0.5172 - val_loss: 0.8896 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8834 - accuracy: 0.6552 - val_loss: 0.8875 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.8476 - accuracy: 0.5862 - val_loss: 0.8839 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9302 - accuracy: 0.5862 - val_loss: 0.8816 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.8963 - accuracy: 0.4828 - val_loss: 0.8737 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9213 - accuracy: 0.5172 - val_loss: 0.8654 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.8647 - accuracy: 0.5517 - val_loss: 0.8527 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8636 - accuracy: 0.6207 - val_loss: 0.8509 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.8329 - accuracy: 0.6552 - val_loss: 0.8433 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.9515 - accuracy: 0.5172 - val_loss: 0.8413 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.8520 - accuracy: 0.6207 - val_loss: 0.8393 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8112 - accuracy: 0.6897 - val_loss: 0.8295 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.8382 - accuracy: 0.7241 - val_loss: 0.8198 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.8418 - accuracy: 0.6552 - val_loss: 0.8131 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.8616 - accuracy: 0.5172 - val_loss: 0.8114 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8383 - accuracy: 0.5862 - val_loss: 0.8092 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.8979 - accuracy: 0.5657\n",
            "Score for fold 2: loss of 0.8979281187057495; accuracy of 56.57142996788025%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 1.1059 - accuracy: 0.3103 - val_loss: 1.1044 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.1152 - accuracy: 0.3103 - val_loss: 1.0996 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0692 - accuracy: 0.4828 - val_loss: 1.0981 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0507 - accuracy: 0.4138 - val_loss: 1.0970 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0899 - accuracy: 0.3103 - val_loss: 1.0971 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.1122 - accuracy: 0.2414 - val_loss: 1.0971 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0916 - accuracy: 0.3793 - val_loss: 1.0983 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1064 - accuracy: 0.3448 - val_loss: 1.0984 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0893 - accuracy: 0.2759 - val_loss: 1.0979 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.1098 - accuracy: 0.3448 - val_loss: 1.0971 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0387 - accuracy: 0.4138 - val_loss: 1.0943 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1514 - accuracy: 0.2414 - val_loss: 1.0908 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0175 - accuracy: 0.4483 - val_loss: 1.0862 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0505 - accuracy: 0.5172 - val_loss: 1.0827 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0334 - accuracy: 0.5862 - val_loss: 1.0796 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0339 - accuracy: 0.4138 - val_loss: 1.0784 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0481 - accuracy: 0.4828 - val_loss: 1.0775 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0520 - accuracy: 0.4138 - val_loss: 1.0758 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0259 - accuracy: 0.3793 - val_loss: 1.0749 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0645 - accuracy: 0.4828 - val_loss: 1.0727 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0451 - accuracy: 0.4138 - val_loss: 1.0675 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0427 - accuracy: 0.4483 - val_loss: 1.0618 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.1070 - accuracy: 0.3448 - val_loss: 1.0574 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9717 - accuracy: 0.5517 - val_loss: 1.0521 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0856 - accuracy: 0.3793 - val_loss: 1.0481 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0525 - accuracy: 0.4483 - val_loss: 1.0453 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0529 - accuracy: 0.4483 - val_loss: 1.0433 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.0676 - accuracy: 0.4828 - val_loss: 1.0406 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9962 - accuracy: 0.5862 - val_loss: 1.0401 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0313 - accuracy: 0.5172 - val_loss: 1.0415 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.1059 - accuracy: 0.3448 - val_loss: 1.0425 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9978 - accuracy: 0.5172 - val_loss: 1.0403 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9747 - accuracy: 0.5172 - val_loss: 1.0391 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0224 - accuracy: 0.4483 - val_loss: 1.0384 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0531 - accuracy: 0.4138 - val_loss: 1.0368 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0508 - accuracy: 0.4483 - val_loss: 1.0319 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0048 - accuracy: 0.5862 - val_loss: 1.0270 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.1003 - accuracy: 0.3103 - val_loss: 1.0251 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 1.0729 - accuracy: 0.3793 - val_loss: 1.0235 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0042 - accuracy: 0.4138 - val_loss: 1.0223 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9548 - accuracy: 0.6207 - val_loss: 1.0205 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9836 - accuracy: 0.5862 - val_loss: 1.0189 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0294 - accuracy: 0.5172 - val_loss: 1.0145 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9168 - accuracy: 0.5517 - val_loss: 1.0123 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9386 - accuracy: 0.5517 - val_loss: 1.0081 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9581 - accuracy: 0.5517 - val_loss: 1.0043 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9787 - accuracy: 0.5517 - val_loss: 1.0017 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9858 - accuracy: 0.5517 - val_loss: 0.9991 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.9609 - accuracy: 0.5172 - val_loss: 0.9979 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0039 - accuracy: 0.4483 - val_loss: 0.9971 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9206 - accuracy: 0.6207 - val_loss: 0.9938 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9615 - accuracy: 0.5517 - val_loss: 0.9924 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.9906 - accuracy: 0.4828 - val_loss: 0.9861 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9524 - accuracy: 0.5172 - val_loss: 0.9846 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.9560 - accuracy: 0.5862 - val_loss: 0.9810 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0137 - accuracy: 0.4483 - val_loss: 0.9760 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9357 - accuracy: 0.6207 - val_loss: 0.9694 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9458 - accuracy: 0.6207 - val_loss: 0.9657 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9290 - accuracy: 0.6207 - val_loss: 0.9622 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8521 - accuracy: 0.5172 - val_loss: 0.9583 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.8972 - accuracy: 0.5862 - val_loss: 0.9573 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8320 - accuracy: 0.5862 - val_loss: 0.9579 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.8493 - accuracy: 0.6897 - val_loss: 0.9579 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.8382 - accuracy: 0.6207 - val_loss: 0.9550 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.8691 - accuracy: 0.6897 - val_loss: 0.9470 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8962 - accuracy: 0.5172 - val_loss: 0.9354 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.8598 - accuracy: 0.6552 - val_loss: 0.9290 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.8233 - accuracy: 0.5862 - val_loss: 0.9210 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8179 - accuracy: 0.5862 - val_loss: 0.9182 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.8330 - accuracy: 0.4828 - val_loss: 0.9143 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9092 - accuracy: 0.5862 - val_loss: 0.9129 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.8965 - accuracy: 0.5862 - val_loss: 0.9134 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.8514 - accuracy: 0.5862 - val_loss: 0.9103 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.8586 - accuracy: 0.5862 - val_loss: 0.9115 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.7506 - accuracy: 0.7241 - val_loss: 0.9136 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9326 - accuracy: 0.4483 - val_loss: 0.9187 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.7259 - accuracy: 0.7241 - val_loss: 0.9153 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.8866 - accuracy: 0.5517 - val_loss: 0.9067 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8209 - accuracy: 0.6897 - val_loss: 0.8989 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.8180 - accuracy: 0.5862 - val_loss: 0.8960 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.8935 - accuracy: 0.5862 - val_loss: 0.8911 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8678 - accuracy: 0.5862 - val_loss: 0.8919 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.8183 - accuracy: 0.5517 - val_loss: 0.8927 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.7897 - accuracy: 0.6552 - val_loss: 0.8920 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.8066 - accuracy: 0.5862 - val_loss: 0.8988 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.8450 - accuracy: 0.5517 - val_loss: 0.8966 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.8200 - accuracy: 0.7241 - val_loss: 0.8919 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9049 - accuracy: 0.4483 - val_loss: 0.8812 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8136 - accuracy: 0.6207 - val_loss: 0.8761 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.8478 - accuracy: 0.6207 - val_loss: 0.8719 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.7628 - accuracy: 0.7241 - val_loss: 0.8713 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.8319 - accuracy: 0.5517 - val_loss: 0.8678 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.7822 - accuracy: 0.6207 - val_loss: 0.8699 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.8551 - accuracy: 0.6552 - val_loss: 0.8597 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.7972 - accuracy: 0.6552 - val_loss: 0.8510 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.7069 - accuracy: 0.7241 - val_loss: 0.8469 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6767 - accuracy: 0.7931 - val_loss: 0.8369 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.7121 - accuracy: 0.7586 - val_loss: 0.8293 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.7758 - accuracy: 0.6897 - val_loss: 0.8337 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.8304 - accuracy: 0.5517 - val_loss: 0.8424 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.8437 - accuracy: 0.5143\n",
            "Score for fold 3: loss of 0.8437471985816956; accuracy of 51.428574323654175%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 214ms/step - loss: 1.0483 - accuracy: 0.5172 - val_loss: 1.0855 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.1426 - accuracy: 0.3793 - val_loss: 1.0801 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 1.0262 - accuracy: 0.3793 - val_loss: 1.0775 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 1.1118 - accuracy: 0.3448 - val_loss: 1.0737 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 1.0628 - accuracy: 0.3793 - val_loss: 1.0681 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 107ms/step - loss: 1.1175 - accuracy: 0.2759 - val_loss: 1.0663 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.1210 - accuracy: 0.3103 - val_loss: 1.0624 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 1.1565 - accuracy: 0.3448 - val_loss: 1.0611 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0600 - accuracy: 0.4828 - val_loss: 1.0577 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.1977 - accuracy: 0.3448 - val_loss: 1.0591 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0771 - accuracy: 0.3793 - val_loss: 1.0590 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.1486 - accuracy: 0.2414 - val_loss: 1.0603 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0930 - accuracy: 0.3103 - val_loss: 1.0623 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0417 - accuracy: 0.4828 - val_loss: 1.0623 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.1215 - accuracy: 0.3793 - val_loss: 1.0584 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0709 - accuracy: 0.3793 - val_loss: 1.0570 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0376 - accuracy: 0.4483 - val_loss: 1.0541 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.1082 - accuracy: 0.3103 - val_loss: 1.0509 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 1.1470 - accuracy: 0.3448 - val_loss: 1.0487 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.9947 - accuracy: 0.5172 - val_loss: 1.0471 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9963 - accuracy: 0.4138 - val_loss: 1.0450 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9972 - accuracy: 0.5862 - val_loss: 1.0365 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.0694 - accuracy: 0.3448 - val_loss: 1.0319 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0223 - accuracy: 0.4483 - val_loss: 1.0298 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.0562 - accuracy: 0.3793 - val_loss: 1.0263 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.9851 - accuracy: 0.4483 - val_loss: 1.0247 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0579 - accuracy: 0.4483 - val_loss: 1.0237 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0639 - accuracy: 0.4483 - val_loss: 1.0198 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8939 - accuracy: 0.7586 - val_loss: 1.0170 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.9793 - accuracy: 0.5172 - val_loss: 1.0146 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.9756 - accuracy: 0.5172 - val_loss: 1.0085 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9749 - accuracy: 0.4483 - val_loss: 1.0000 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.9828 - accuracy: 0.5517 - val_loss: 0.9940 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9597 - accuracy: 0.5172 - val_loss: 0.9863 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0058 - accuracy: 0.4483 - val_loss: 0.9813 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0395 - accuracy: 0.4483 - val_loss: 0.9771 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0045 - accuracy: 0.4138 - val_loss: 0.9735 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9786 - accuracy: 0.4483 - val_loss: 0.9753 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9864 - accuracy: 0.4828 - val_loss: 0.9775 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9517 - accuracy: 0.5172 - val_loss: 0.9793 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9630 - accuracy: 0.5172 - val_loss: 0.9750 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9276 - accuracy: 0.5517 - val_loss: 0.9670 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9660 - accuracy: 0.4828 - val_loss: 0.9618 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9464 - accuracy: 0.5172 - val_loss: 0.9566 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.9757 - accuracy: 0.5862 - val_loss: 0.9516 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9365 - accuracy: 0.4483 - val_loss: 0.9493 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9214 - accuracy: 0.5862 - val_loss: 0.9489 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8978 - accuracy: 0.5862 - val_loss: 0.9463 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.7899 - accuracy: 0.8276 - val_loss: 0.9438 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.8992 - accuracy: 0.6207 - val_loss: 0.9432 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.0158 - accuracy: 0.4138 - val_loss: 0.9382 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9412 - accuracy: 0.5172 - val_loss: 0.9378 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.8699 - accuracy: 0.6207 - val_loss: 0.9365 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.9234 - accuracy: 0.4828 - val_loss: 0.9320 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.8998 - accuracy: 0.5862 - val_loss: 0.9275 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.8822 - accuracy: 0.6552 - val_loss: 0.9203 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9487 - accuracy: 0.5172 - val_loss: 0.9186 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.9223 - accuracy: 0.5172 - val_loss: 0.9131 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.8294 - accuracy: 0.6207 - val_loss: 0.9107 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.9812 - accuracy: 0.5172 - val_loss: 0.9088 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.8608 - accuracy: 0.5862 - val_loss: 0.9085 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.8166 - accuracy: 0.6207 - val_loss: 0.9067 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8691 - accuracy: 0.6897 - val_loss: 0.9028 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.7824 - accuracy: 0.7241 - val_loss: 0.8984 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9416 - accuracy: 0.5517 - val_loss: 0.8942 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9598 - accuracy: 0.5172 - val_loss: 0.8926 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9151 - accuracy: 0.5517 - val_loss: 0.9010 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.8773 - accuracy: 0.4828 - val_loss: 0.9083 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.9822 - accuracy: 0.4483 - val_loss: 0.9136 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.9007 - accuracy: 0.5517 - val_loss: 0.9209 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.8958 - accuracy: 0.5172 - val_loss: 0.9243 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.9436 - accuracy: 0.4828 - val_loss: 0.9229 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.8592 - accuracy: 0.6552 - val_loss: 0.9222 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.7890 - accuracy: 0.5172 - val_loss: 0.9188 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.8458 - accuracy: 0.5862 - val_loss: 0.9129 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8378 - accuracy: 0.6552 - val_loss: 0.9047 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.7986 - accuracy: 0.6207 - val_loss: 0.8967 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.7585 - accuracy: 0.6552 - val_loss: 0.8907 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.8440 - accuracy: 0.5862 - val_loss: 0.8900 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.7885 - accuracy: 0.6897 - val_loss: 0.8867 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8572 - accuracy: 0.5172 - val_loss: 0.8872 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.7602 - accuracy: 0.5172 - val_loss: 0.8855 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8420 - accuracy: 0.6552 - val_loss: 0.8825 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.8441 - accuracy: 0.5517 - val_loss: 0.8797 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.8547 - accuracy: 0.6207 - val_loss: 0.8747 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.7819 - accuracy: 0.5862 - val_loss: 0.8737 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8726 - accuracy: 0.4483 - val_loss: 0.8729 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.8012 - accuracy: 0.7241 - val_loss: 0.8714 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.7609 - accuracy: 0.7241 - val_loss: 0.8725 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.8145 - accuracy: 0.5862 - val_loss: 0.8704 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.6992 - accuracy: 0.6897 - val_loss: 0.8678 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.7859 - accuracy: 0.6552 - val_loss: 0.8681 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9159 - accuracy: 0.5172 - val_loss: 0.8649 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.7897 - accuracy: 0.5862 - val_loss: 0.8567 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.7262 - accuracy: 0.6897 - val_loss: 0.8578 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.8976 - accuracy: 0.4138 - val_loss: 0.8600 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.8020 - accuracy: 0.5517 - val_loss: 0.8608 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.6616 - accuracy: 0.6552 - val_loss: 0.8588 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.7859 - accuracy: 0.6207 - val_loss: 0.8571 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.6547 - accuracy: 0.7241 - val_loss: 0.8593 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.8824 - accuracy: 0.5771\n",
            "Score for fold 4: loss of 0.8823558688163757; accuracy of 57.71428346633911%\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 1.1038 - accuracy: 0.4138 - val_loss: 1.1013 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.1084 - accuracy: 0.2759 - val_loss: 1.0962 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0820 - accuracy: 0.4483 - val_loss: 1.0927 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0799 - accuracy: 0.4828 - val_loss: 1.0915 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0744 - accuracy: 0.3448 - val_loss: 1.0890 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0982 - accuracy: 0.3793 - val_loss: 1.0864 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0976 - accuracy: 0.3448 - val_loss: 1.0851 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0799 - accuracy: 0.3793 - val_loss: 1.0848 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0489 - accuracy: 0.4483 - val_loss: 1.0826 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0977 - accuracy: 0.4483 - val_loss: 1.0808 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0854 - accuracy: 0.5517 - val_loss: 1.0789 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0643 - accuracy: 0.4828 - val_loss: 1.0762 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0722 - accuracy: 0.3793 - val_loss: 1.0733 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0910 - accuracy: 0.4828 - val_loss: 1.0697 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.1018 - accuracy: 0.4483 - val_loss: 1.0679 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.1186 - accuracy: 0.4138 - val_loss: 1.0660 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0838 - accuracy: 0.4828 - val_loss: 1.0638 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0536 - accuracy: 0.5172 - val_loss: 1.0623 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0723 - accuracy: 0.4138 - val_loss: 1.0602 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.0700 - accuracy: 0.3448 - val_loss: 1.0563 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0930 - accuracy: 0.3793 - val_loss: 1.0524 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.0980 - accuracy: 0.4138 - val_loss: 1.0493 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0714 - accuracy: 0.3793 - val_loss: 1.0463 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0648 - accuracy: 0.3103 - val_loss: 1.0432 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.0722 - accuracy: 0.5517 - val_loss: 1.0400 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.1080 - accuracy: 0.3103 - val_loss: 1.0365 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0853 - accuracy: 0.3793 - val_loss: 1.0336 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0822 - accuracy: 0.3793 - val_loss: 1.0308 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0681 - accuracy: 0.4828 - val_loss: 1.0285 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0777 - accuracy: 0.3448 - val_loss: 1.0266 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.0803 - accuracy: 0.3793 - val_loss: 1.0256 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0958 - accuracy: 0.4138 - val_loss: 1.0256 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0555 - accuracy: 0.5172 - val_loss: 1.0246 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0576 - accuracy: 0.5517 - val_loss: 1.0224 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 1.0914 - accuracy: 0.4483 - val_loss: 1.0197 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0522 - accuracy: 0.4828 - val_loss: 1.0175 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9995 - accuracy: 0.6207 - val_loss: 1.0141 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0530 - accuracy: 0.4138 - val_loss: 1.0105 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0855 - accuracy: 0.4138 - val_loss: 1.0081 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0597 - accuracy: 0.4483 - val_loss: 1.0060 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.0331 - accuracy: 0.4828 - val_loss: 1.0035 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0316 - accuracy: 0.4483 - val_loss: 1.0012 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0451 - accuracy: 0.3448 - val_loss: 0.9986 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0573 - accuracy: 0.3448 - val_loss: 0.9950 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0519 - accuracy: 0.3793 - val_loss: 0.9919 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0105 - accuracy: 0.6207 - val_loss: 0.9901 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0536 - accuracy: 0.4483 - val_loss: 0.9872 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0570 - accuracy: 0.4138 - val_loss: 0.9840 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.0737 - accuracy: 0.3448 - val_loss: 0.9817 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0349 - accuracy: 0.4483 - val_loss: 0.9795 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0452 - accuracy: 0.5172 - val_loss: 0.9766 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0699 - accuracy: 0.4828 - val_loss: 0.9738 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 1.0434 - accuracy: 0.4483 - val_loss: 0.9711 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0096 - accuracy: 0.6207 - val_loss: 0.9677 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9387 - accuracy: 0.7241 - val_loss: 0.9636 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9955 - accuracy: 0.5517 - val_loss: 0.9574 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0085 - accuracy: 0.5172 - val_loss: 0.9507 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0568 - accuracy: 0.5517 - val_loss: 0.9449 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0182 - accuracy: 0.5172 - val_loss: 0.9401 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0323 - accuracy: 0.4828 - val_loss: 0.9348 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.9639 - accuracy: 0.6207 - val_loss: 0.9296 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.9485 - accuracy: 0.6552 - val_loss: 0.9239 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.9919 - accuracy: 0.4828 - val_loss: 0.9178 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.9719 - accuracy: 0.6552 - val_loss: 0.9123 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.0005 - accuracy: 0.4483 - val_loss: 0.9075 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0188 - accuracy: 0.3793 - val_loss: 0.9033 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9294 - accuracy: 0.4828 - val_loss: 0.9002 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.9460 - accuracy: 0.5862 - val_loss: 0.8945 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0050 - accuracy: 0.5517 - val_loss: 0.8895 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9769 - accuracy: 0.6552 - val_loss: 0.8853 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9985 - accuracy: 0.4483 - val_loss: 0.8818 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0651 - accuracy: 0.3793 - val_loss: 0.8793 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9466 - accuracy: 0.5172 - val_loss: 0.8790 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0006 - accuracy: 0.5172 - val_loss: 0.8770 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9455 - accuracy: 0.4483 - val_loss: 0.8740 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9332 - accuracy: 0.5172 - val_loss: 0.8686 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9889 - accuracy: 0.5172 - val_loss: 0.8656 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9192 - accuracy: 0.5862 - val_loss: 0.8603 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9815 - accuracy: 0.3448 - val_loss: 0.8557 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.9352 - accuracy: 0.5862 - val_loss: 0.8474 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0100 - accuracy: 0.4483 - val_loss: 0.8398 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9776 - accuracy: 0.4138 - val_loss: 0.8337 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.8968 - accuracy: 0.5517 - val_loss: 0.8269 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.9155 - accuracy: 0.4828 - val_loss: 0.8222 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.9362 - accuracy: 0.5517 - val_loss: 0.8177 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.9415 - accuracy: 0.4483 - val_loss: 0.8139 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 124ms/step - loss: 0.8958 - accuracy: 0.5172 - val_loss: 0.8096 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.8733 - accuracy: 0.5517 - val_loss: 0.8032 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.8465 - accuracy: 0.6207 - val_loss: 0.7945 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 1.0126 - accuracy: 0.4483 - val_loss: 0.7869 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.8924 - accuracy: 0.5172 - val_loss: 0.7817 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.8933 - accuracy: 0.5517 - val_loss: 0.7776 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.8378 - accuracy: 0.6552 - val_loss: 0.7737 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.9025 - accuracy: 0.5517 - val_loss: 0.7676 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.9517 - accuracy: 0.4483 - val_loss: 0.7640 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.8780 - accuracy: 0.6897 - val_loss: 0.7612 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.8852 - accuracy: 0.6897 - val_loss: 0.7586 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.8722 - accuracy: 0.5172 - val_loss: 0.7516 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.9260 - accuracy: 0.6552 - val_loss: 0.7458 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.8531 - accuracy: 0.6897 - val_loss: 0.7415 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.8958 - accuracy: 0.5829\n",
            "Score for fold 5: loss of 0.8958361148834229; accuracy of 58.28571319580078%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i] * 100}%')\n",
        "  row.append(loss_per_fold[i])\n",
        "  row.append(acc_per_fold[i])\n",
        "\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold) * 100} (+- {np.std(acc_per_fold) * 100})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n",
        "\n",
        "row.append(np.mean(acc_per_fold))\n",
        "row.append(np.std(acc_per_fold))\n",
        "row.append(np.mean(loss_per_fold))\n",
        "row.append(BATCH_SIZE)\n",
        "row.append(EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NruadTK6IZ5d",
        "outputId": "90f7a403-5fa8-4f70-ed41-d0cd04e8e738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.9410296678543091 - Accuracy: 53.14285755157471%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.8979281187057495 - Accuracy: 56.57142996788025%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.8437471985816956 - Accuracy: 51.428574323654175%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.8823558688163757 - Accuracy: 57.71428346633911%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.8958361148834229 - Accuracy: 58.28571319580078%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 55.4285717010498 (+- 2.6802361465122835)\n",
            "> Loss: 0.8921793937683106\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_length = 5000\n",
        "test = "
      ],
      "metadata": {
        "id": "YU4N8BKG8yzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWv1qtA-86Bu",
        "outputId": "d13f917d-8ec6-40a4-bbe5-78d7f07e5c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Data"
      ],
      "metadata": {
        "id": "TUN6bmf8NSl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_iterator = zip(columns, row)\n",
        "a_dictionary = dict(zip_iterator)\n",
        "print(a_dictionary)\n",
        "test = df_csv\n",
        "print(test, \"\\n ------------------------\")\n",
        "test = test.append(a_dictionary, ignore_index=True)\n",
        "\n",
        "print(test)"
      ],
      "metadata": {
        "id": "PysNy9NmNQIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.to_csv('teste.csv', index = False, header= True)"
      ],
      "metadata": {
        "id": "psddAm3KaoZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwDA8if62yKn"
      },
      "source": [
        "### CNN - Small version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOosbeXk-kQ-"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW8V-ze9kKwz"
      },
      "outputs": [],
      "source": [
        "# This cell is used to fix one hot encoding automatic from keras in some datasets\n",
        "train_y = train_y.astype('uint8')\n",
        "test_y = test_y.astype('uint8')\n",
        "while(min(train_y) > 0):\n",
        "  train_y = train_y - 1\n",
        "while(min(test_y) > 0):\n",
        "  test_y = test_y - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_damj87UXQtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8bfc74d-bb38-42c4-be74-1671f48e4a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (36, 50, 50, 3)  | y =  36\n",
            "Test:   (175, 50, 50, 3)  | y =  175\n",
            "Number of classes:  3\n"
          ]
        }
      ],
      "source": [
        "print(\"Train: \", train_x.shape, \" | y = \", train_y.size)\n",
        "print(\"Test:  \", test_x.shape, \" | y = \", test_y.size)\n",
        "n_classes = np.unique(train_y).size\n",
        "print(\"Number of classes: \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZAmtIMU_EvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87505e5d-0b60-46a1-b04f-26c395f16795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width:  50 | Height:  50 | Channels:  3\n"
          ]
        }
      ],
      "source": [
        "width, height, channels = train_x.shape[1], train_x.shape[2], train_x.shape[3]\n",
        "print(\"Width: \", width, \"| Height: \", height, \"| Channels: \", channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paT1-UlA9eNR"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(train_x, train_y, batch_size=64) #DEPOIS SUSBTITUIR AO TRAVEZ POR TRAIN_Y e colocar no modelo aquilo que o nuno disse (ver notes)\n",
        "test_iterator = datagen.flow(test_x, test_y, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# confirm the scaling works\n",
        "batchX, batchy = train_iterator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "CYRTyDDp25nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "metadata": {
        "id": "yLQJK8vNIy0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "# early stopping\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "history = model.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=30)"
      ],
      "metadata": {
        "id": "Ti48E_tq25nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "print('Test accuracy:')\n",
        "_, acc = model.evaluate(test_iterator, steps=len(test_iterator))\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "metadata": {
        "id": "Nr7iZmHa25nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### History"
      ],
      "metadata": {
        "id": "Rn2gyM0925nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F4KM2iSJ25nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN - Plotting Time - Test"
      ],
      "metadata": {
        "id": "iHTw4UuMTRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare Date TEST\n"
      ],
      "metadata": {
        "id": "tBbhg5qmwKjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is used to fix one hot encoding automatic from keras in some datasets\n",
        "train_y = train_y.astype('uint8')\n",
        "test_y = test_y.astype('uint8')\n",
        "while(min(train_y) > 0):\n",
        "  train_y = train_y - 1\n",
        "while(min(test_y) > 0):\n",
        "  test_y = test_y - 1"
      ],
      "metadata": {
        "id": "jTFMlo-8wUxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train: \", train_x.shape, \" | y = \", train_y.size)\n",
        "print(\"Test:  \", test_x.shape, \" | y = \", test_y.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRpMmVW3xn9L",
        "outputId": "e6fe41fb-9729-4e36-e6bc-420b9cbf1506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (36, 50, 50, 3)  | y =  36\n",
            "Test:   (175, 50, 50, 3)  | y =  175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], train_x.shape[2], 1))\n",
        "# test_x = test_x.reshape((test_x.shape[0], test_x.shape[1], test_x.shape[2], 1))\n",
        "train_x = train_x[:,:,:,:1]\n",
        "test_x = test_x[:,:,:,:1]\n",
        "n_classes = np.unique(train_y).size\n",
        "print(\"Number of classes: \", n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RevEgQHAwJRL",
        "outputId": "6c26224f-e7e7-43ec-d25a-70edebafcbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.permutation(len(train_x))\n",
        "train_x = train_x[idx]\n",
        "train_y = train_y[idx]"
      ],
      "metadata": {
        "id": "RWrL_8TUwhV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width, height, channels = train_x.shape[1], train_x.shape[2], train_x.shape[3]\n",
        "print(\"Width: \", width, \"| Height: \", height, \"| Channels: \", channels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN7ngSZQyPEC",
        "outputId": "37d9be57-cf79-48e0-e04d-e96b76f28053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width:  288 | Height:  432 | Channels:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myXVzoM8ADUn"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUaLJI1YD5aR"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH1j1jG29MCx",
        "outputId": "13e3ac80-8f73-44e1-93cd-032c2d32cc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.9241 - sparse_categorical_accuracy: 0.1688 - val_loss: 1.7594 - val_sparse_categorical_accuracy: 0.2750 - lr: 1.0000e-04\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.8415 - sparse_categorical_accuracy: 0.2125 - val_loss: 1.7454 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.8245 - sparse_categorical_accuracy: 0.2000 - val_loss: 1.7352 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.7676 - sparse_categorical_accuracy: 0.2250 - val_loss: 1.7303 - val_sparse_categorical_accuracy: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 1.7345 - sparse_categorical_accuracy: 0.2625 - val_loss: 1.7310 - val_sparse_categorical_accuracy: 0.2750 - lr: 1.0000e-04\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.7637 - sparse_categorical_accuracy: 0.2688 - val_loss: 1.7241 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.7160 - sparse_categorical_accuracy: 0.2438 - val_loss: 1.7240 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.7132 - sparse_categorical_accuracy: 0.2625 - val_loss: 1.7228 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.7182 - sparse_categorical_accuracy: 0.2625 - val_loss: 1.7126 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.6352 - sparse_categorical_accuracy: 0.3438 - val_loss: 1.6958 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6727 - sparse_categorical_accuracy: 0.2313 - val_loss: 1.6802 - val_sparse_categorical_accuracy: 0.2750 - lr: 1.0000e-04\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.6415 - sparse_categorical_accuracy: 0.3063 - val_loss: 1.6734 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 1.6628 - sparse_categorical_accuracy: 0.3063 - val_loss: 1.6836 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 1.6440 - sparse_categorical_accuracy: 0.2750 - val_loss: 1.6887 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 1.6472 - sparse_categorical_accuracy: 0.2688 - val_loss: 1.6813 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6138 - sparse_categorical_accuracy: 0.3375 - val_loss: 1.6668 - val_sparse_categorical_accuracy: 0.3250 - lr: 1.0000e-04\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.6227 - sparse_categorical_accuracy: 0.3250 - val_loss: 1.6561 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6270 - sparse_categorical_accuracy: 0.3250 - val_loss: 1.6532 - val_sparse_categorical_accuracy: 0.3500 - lr: 1.0000e-04\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.6468 - sparse_categorical_accuracy: 0.3187 - val_loss: 1.6496 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5920 - sparse_categorical_accuracy: 0.3063 - val_loss: 1.6458 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5191 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.6408 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5135 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.6309 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.5831 - sparse_categorical_accuracy: 0.3187 - val_loss: 1.6162 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5021 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.6014 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.5033 - sparse_categorical_accuracy: 0.3875 - val_loss: 1.5775 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.5141 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.5690 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.4511 - sparse_categorical_accuracy: 0.4563 - val_loss: 1.5662 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.4494 - sparse_categorical_accuracy: 0.3750 - val_loss: 1.5476 - val_sparse_categorical_accuracy: 0.3500 - lr: 1.0000e-04\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 8s 2s/step - loss: 1.4655 - sparse_categorical_accuracy: 0.3875 - val_loss: 1.5335 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 1.5088 - sparse_categorical_accuracy: 0.3688 - val_loss: 1.5510 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 1.4694 - sparse_categorical_accuracy: 0.4187 - val_loss: 1.5464 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 1.4579 - sparse_categorical_accuracy: 0.3688 - val_loss: 1.5351 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.3448 - sparse_categorical_accuracy: 0.5188 - val_loss: 1.5055 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 7s 2s/step - loss: 1.4025 - sparse_categorical_accuracy: 0.4313 - val_loss: 1.4875 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 27s 7s/step - loss: 1.4793 - sparse_categorical_accuracy: 0.3375 - val_loss: 1.4867 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 1.3287 - sparse_categorical_accuracy: 0.3938 - val_loss: 1.4947 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.4727 - sparse_categorical_accuracy: 0.3625 - val_loss: 1.4951 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 1.3839 - sparse_categorical_accuracy: 0.4125 - val_loss: 1.4979 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 29s 7s/step - loss: 1.3453 - sparse_categorical_accuracy: 0.4938 - val_loss: 1.4780 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 35s 9s/step - loss: 1.3167 - sparse_categorical_accuracy: 0.4750 - val_loss: 1.4457 - val_sparse_categorical_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 35s 9s/step - loss: 1.3951 - sparse_categorical_accuracy: 0.4437 - val_loss: 1.4378 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 1.2821 - sparse_categorical_accuracy: 0.4812 - val_loss: 1.4425 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 29s 7s/step - loss: 1.3096 - sparse_categorical_accuracy: 0.4938 - val_loss: 1.4216 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 1.2583 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.4294 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.2812 - sparse_categorical_accuracy: 0.4812 - val_loss: 1.4568 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.2505 - sparse_categorical_accuracy: 0.4563 - val_loss: 1.4259 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.2624 - sparse_categorical_accuracy: 0.4750 - val_loss: 1.4172 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 33s 8s/step - loss: 1.2154 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.4145 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 1.1342 - sparse_categorical_accuracy: 0.5688 - val_loss: 1.4284 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 33s 8s/step - loss: 1.1032 - sparse_categorical_accuracy: 0.5750 - val_loss: 1.4025 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 1.0604 - sparse_categorical_accuracy: 0.6000 - val_loss: 1.4139 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 1.1611 - sparse_categorical_accuracy: 0.5188 - val_loss: 1.4113 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.1869 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.4140 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 1.2136 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.4173 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 27s 7s/step - loss: 1.0664 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.4016 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 36s 9s/step - loss: 1.0145 - sparse_categorical_accuracy: 0.6438 - val_loss: 1.3896 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.1318 - sparse_categorical_accuracy: 0.5625 - val_loss: 1.3892 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 35s 9s/step - loss: 1.1228 - sparse_categorical_accuracy: 0.5688 - val_loss: 1.3796 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 36s 9s/step - loss: 1.0267 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.3524 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 34s 8s/step - loss: 1.0836 - sparse_categorical_accuracy: 0.5938 - val_loss: 1.3317 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.9577 - sparse_categorical_accuracy: 0.6000 - val_loss: 1.3641 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.0716 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.3962 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 1.0361 - sparse_categorical_accuracy: 0.6000 - val_loss: 1.3738 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.9706 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3337 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.1014 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.3262 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.9086 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3485 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 1.0086 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3603 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 1.0156 - sparse_categorical_accuracy: 0.5437 - val_loss: 1.3619 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.9425 - sparse_categorical_accuracy: 0.6562 - val_loss: 1.3623 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.9341 - sparse_categorical_accuracy: 0.6187 - val_loss: 1.3699 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.9600 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3453 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 26s 6s/step - loss: 0.9424 - sparse_categorical_accuracy: 0.6625 - val_loss: 1.3175 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 32s 8s/step - loss: 1.0018 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.3081 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.9420 - sparse_categorical_accuracy: 0.6125 - val_loss: 1.3193 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.9182 - sparse_categorical_accuracy: 0.6187 - val_loss: 1.3483 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8678 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3570 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8885 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.3571 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.9167 - sparse_categorical_accuracy: 0.6250 - val_loss: 1.3349 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.9097 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3445 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 29s 7s/step - loss: 0.8593 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.3049 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 33s 8s/step - loss: 0.8662 - sparse_categorical_accuracy: 0.6562 - val_loss: 1.3007 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.8913 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3305 - val_sparse_categorical_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.8868 - sparse_categorical_accuracy: 0.6187 - val_loss: 1.3175 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.9068 - sparse_categorical_accuracy: 0.6313 - val_loss: 1.3150 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8793 - sparse_categorical_accuracy: 0.6125 - val_loss: 1.3198 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.7014 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.3507 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8270 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3683 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7734 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.3474 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8736 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.3059 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.7952 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.2685 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8509 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.3118 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8002 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3988 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8350 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.4247 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7009 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.4373 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.8135 - sparse_categorical_accuracy: 0.6938 - val_loss: 1.3635 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7216 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3086 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7627 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.2981 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7379 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.3289 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.6605 - sparse_categorical_accuracy: 0.7812 - val_loss: 1.3270 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8579 - sparse_categorical_accuracy: 0.6313 - val_loss: 1.2982 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.8002 - sparse_categorical_accuracy: 0.6938 - val_loss: 1.3041 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3436 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.7307 - sparse_categorical_accuracy: 0.7125 - val_loss: 1.3157 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8221 - sparse_categorical_accuracy: 0.6750 - val_loss: 1.3204 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6794 - sparse_categorical_accuracy: 0.6875 - val_loss: 1.3537 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6419 - sparse_categorical_accuracy: 0.7500 - val_loss: 1.3997 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7412 - sparse_categorical_accuracy: 0.7125 - val_loss: 1.4253 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7196 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.4171 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.3913 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7688 - val_loss: 1.4075 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.7859 - sparse_categorical_accuracy: 0.6812 - val_loss: 1.3455 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.6875 - val_loss: 1.3273 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8062 - val_loss: 1.3361 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.5929 - sparse_categorical_accuracy: 0.7688 - val_loss: 1.3606 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7944 - sparse_categorical_accuracy: 0.6625 - val_loss: 1.3715 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6829 - sparse_categorical_accuracy: 0.7500 - val_loss: 1.4011 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6832 - sparse_categorical_accuracy: 0.7500 - val_loss: 1.3791 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.7250 - val_loss: 1.3599 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7221 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.4168 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.8161 - sparse_categorical_accuracy: 0.6438 - val_loss: 1.3251 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.5804 - sparse_categorical_accuracy: 0.8000 - val_loss: 1.3252 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.7142 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.3972 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.7083 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.4381 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6407 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.3889 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3857 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.3924 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.5894 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.4147 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.7265 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.4179 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6501 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.4335 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6178 - sparse_categorical_accuracy: 0.7750 - val_loss: 1.3844 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.5697 - sparse_categorical_accuracy: 0.7375 - val_loss: 1.3489 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6627 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.3600 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.8375 - val_loss: 1.4064 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.6975 - sparse_categorical_accuracy: 0.7125 - val_loss: 1.4406 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.4955 - sparse_categorical_accuracy: 0.7875 - val_loss: 1.4709 - val_sparse_categorical_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.6435 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.4614 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6692 - sparse_categorical_accuracy: 0.7625 - val_loss: 1.4565 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.6017 - sparse_categorical_accuracy: 0.7563 - val_loss: 1.3905 - val_sparse_categorical_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.7750 - val_loss: 1.3579 - val_sparse_categorical_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.5258 - sparse_categorical_accuracy: 0.8188 - val_loss: 1.4181 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 140: early stopping\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "# model.add(InputLayer(input_shape=(width, height, channels)))\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.7)) #Aumentar depois maybe o dropout\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer = opt,\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    metrics = [\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_x,\n",
        "    train_y,\n",
        "    batch_size=32,\n",
        "    # batch_size=64,\n",
        "    epochs=500,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wi2UZZbQXTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5816c36c-9979-49fd-858b-b2f13b31b5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6227 - sparse_categorical_accuracy: 0.4545\n",
            "Test accuracy 0.4545454680919647\n",
            "Test loss 1.622735619544983\n"
          ]
        }
      ],
      "source": [
        "# model = keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkZ9FkeRFIFn"
      },
      "source": [
        "#### History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "D6TZROKLCyug",
        "outputId": "ccc99b71-1318-43e5-a61b-3024e468bae7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "metric = \"sparse_categorical_accuracy\"\n",
        "plt.figure()\n",
        "plt.plot(history.history[metric])\n",
        "plt.plot(history.history[\"val_\" + metric])\n",
        "plt.title(\"model \" + metric)\n",
        "plt.ylabel(metric, fontsize=\"large\")\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extras"
      ],
      "metadata": {
        "id": "qEZO4HlzOPrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels=(training_set.class_indices)\n",
        "# labels2=dict((v,k) for k,v in labels.items())\n",
        "import collections \n",
        "for i in range(len(data_kfold)):\n",
        "    co = collections.Counter(data_kfold.loc[i])\n",
        "    co = sorted(co.items(),key=lambda x: x[1],reverse=True)\n",
        "    # ans.Class.loc[i] = labels2[co[0][0]]"
      ],
      "metadata": {
        "id": "xd6-XC8nAuZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxmaWlJVAuR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAoUR_czJsO5"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMW46JTpKQRg"
      },
      "source": [
        "O que alterei do Plotting Time:\n",
        "\n",
        "\n",
        "*   Strides das Conv2D pus o default (1,1) (acho que isto já era suposto ser o default)\n",
        "*   Dropout de 0.7 -> 0.5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OltFsau_Jmv7"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "# model.add(InputLayer(input_shape=(width, height, channels)))\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5)) #Aumentar depois maybe o dropout\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# early stopping\n",
        "callback = EarlyStopping(monitor='loss')\n",
        "# compile model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "history = model.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr50vZdSJtPP"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "print('Test accuracy:')\n",
        "_, acc = model.evaluate(test_iterator, steps=len(test_iterator))\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_61wkrKZKkgV"
      },
      "outputs": [],
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ]
}